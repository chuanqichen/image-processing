<!DOCTYPE html>
<!-- saved from url=(0057)https://datacarpentry.org/image-processing/aio/index.html -->
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta http-equiv="last-modified" content="2022-09-14 18:27:43 +0000">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- meta "search-domain" used for google site search function google_search() -->
    <meta name="search-domain" value="https://datacarpentry.org/image-processing">
    <style class="anchorjs"></style><link rel="stylesheet" type="text/css" href="./Image Processing with Python_files/bootstrap.css">
    <link rel="stylesheet" type="text/css" href="./Image Processing with Python_files/bootstrap-theme.css">
    <link rel="stylesheet" type="text/css" href="./Image Processing with Python_files/lesson.css">
    <link rel="stylesheet" type="text/css" href="./Image Processing with Python_files/syntax.css">
     <link rel="stylesheet" type="text/css" href="./Image Processing with Python_files/fonts.css">
    
    <link rel="license" href="https://datacarpentry.org/image-processing/aio/index.html#license-info">

    



    <!-- Favicons for everyone -->
    <link rel="apple-touch-icon-precomposed" sizes="57x57" href="https://datacarpentry.org/image-processing/assets/favicons/dc/apple-touch-icon-57x57.png">
    <link rel="apple-touch-icon-precomposed" sizes="114x114" href="https://datacarpentry.org/image-processing/assets/favicons/dc/apple-touch-icon-114x114.png">
    <link rel="apple-touch-icon-precomposed" sizes="72x72" href="https://datacarpentry.org/image-processing/assets/favicons/dc/apple-touch-icon-72x72.png">
    <link rel="apple-touch-icon-precomposed" sizes="144x144" href="https://datacarpentry.org/image-processing/assets/favicons/dc/apple-touch-icon-144x144.png">
    <link rel="apple-touch-icon-precomposed" sizes="60x60" href="https://datacarpentry.org/image-processing/assets/favicons/dc/apple-touch-icon-60x60.png">
    <link rel="apple-touch-icon-precomposed" sizes="120x120" href="https://datacarpentry.org/image-processing/assets/favicons/dc/apple-touch-icon-120x120.png">
    <link rel="apple-touch-icon-precomposed" sizes="76x76" href="https://datacarpentry.org/image-processing/assets/favicons/dc/apple-touch-icon-76x76.png">
    <link rel="apple-touch-icon-precomposed" sizes="152x152" href="https://datacarpentry.org/image-processing/assets/favicons/dc/apple-touch-icon-152x152.png">
    <link rel="icon" type="image/png" href="https://datacarpentry.org/image-processing/assets/favicons/dc/favicon-196x196.png" sizes="196x196">
    <link rel="icon" type="image/png" href="https://datacarpentry.org/image-processing/assets/favicons/dc/favicon-96x96.png" sizes="96x96">
    <link rel="icon" type="image/png" href="https://datacarpentry.org/image-processing/assets/favicons/dc/favicon-32x32.png" sizes="32x32">
    <link rel="icon" type="image/png" href="https://datacarpentry.org/image-processing/assets/favicons/dc/favicon-16x16.png" sizes="16x16">
    <link rel="icon" type="image/png" href="https://datacarpentry.org/image-processing/assets/favicons/dc/favicon-128.png" sizes="128x128">
    <meta name="application-name" content="Data Carpentry - Image Processing with Python">
    <meta name="msapplication-TileColor" content="#FFFFFF">
    <meta name="msapplication-TileImage" content="/image-processing/assets/favicons/dc/mstile-144x144.png">
    <meta name="msapplication-square70x70logo" content="/image-processing/assets/favicons/dc/mstile-70x70.png">
    <meta name="msapplication-square150x150logo" content="/image-processing/assets/favicons/dc/mstile-150x150.png">
    <meta name="msapplication-wide310x150logo" content="/image-processing/assets/favicons/dc/mstile-310x150.png">
    <meta name="msapplication-square310x310logo" content="/image-processing/assets/favicons/dc/mstile-310x310.png">


    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
	<script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
	<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
	<![endif]-->
  <title>
  Image Processing with Python
  </title>

  </head>
  <body data-new-gr-c-s-check-loaded="14.1080.0" data-gr-ext-installed="">
    


<div class="panel panel-default life-cycle">
  <div id="life-cycle" class="panel-body beta" style="padding: 5px;">
    This lesson is being piloted (Beta version)
    
  </div>
</div>




    <div class="container">
      
















  
  










<nav class="navbar navbar-default">
  <div class="container-fluid">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>

      
      
      <a href="https://datacarpentry.org/" class="pull-left">
        <img class="navbar-logo" src="./Image Processing with Python_files/dc-icon-black.svg" alt="Data Carpentry logo">
      </a>
      

      
      <a class="navbar-brand" href="https://datacarpentry.org/image-processing/">Home</a>

    </div>
    <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
      <ul class="nav navbar-nav">

	
        <li><a href="https://datacarpentry.org/image-processing/CODE_OF_CONDUCT.html">Code of Conduct</a></li>

        
	
        <li><a href="https://datacarpentry.org/image-processing/setup/">Setup</a></li>

        
        
        <li class="dropdown">
          <a href="https://datacarpentry.org/image-processing/" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-haspopup="true" aria-expanded="false">Episodes <span class="caret"></span></a>
          <ul class="dropdown-menu">
            
            
            <li><a href="https://datacarpentry.org/image-processing/01-introduction/index.html">Introduction</a></li>
            
            
            <li><a href="https://datacarpentry.org/image-processing/02-image-basics/index.html">Image Basics</a></li>
            
            
            <li><a href="https://datacarpentry.org/image-processing/03-skimage-images/index.html">Working with skimage</a></li>
            
            
            <li><a href="https://datacarpentry.org/image-processing/04-drawing/index.html">Drawing and Bitwise Operations</a></li>
            
            
            <li><a href="https://datacarpentry.org/image-processing/05-creating-histograms/index.html">Creating Histograms</a></li>
            
            
            <li><a href="https://datacarpentry.org/image-processing/06-blurring/index.html">Blurring Images</a></li>
            
            
            <li><a href="https://datacarpentry.org/image-processing/07-thresholding/index.html">Thresholding</a></li>
            
            
            <li><a href="https://datacarpentry.org/image-processing/08-connected-components/index.html">Connected Component Analysis</a></li>
            
            
            <li><a href="https://datacarpentry.org/image-processing/09-challenges/index.html">Capstone Challenge</a></li>
            
	    <li role="separator" class="divider"></li>
            <li><a href="https://datacarpentry.org/image-processing/aio/index.html">All in one page (Beta)</a></li>
          </ul>
        </li>
        
	

	
	
        <li class="dropdown">
          <a href="https://datacarpentry.org/image-processing/" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-haspopup="true" aria-expanded="false">Extras <span class="caret"></span></a>
          <ul class="dropdown-menu">
            <li><a href="https://datacarpentry.org/image-processing/reference.html">Reference</a></li>
            
            
            
              <li><a href="https://datacarpentry.org/image-processing/about/index.html">About</a></li>
            
            
            
            
              <li><a href="https://datacarpentry.org/image-processing/discuss/index.html">Discussion</a></li>
            
            
            
            
              <li><a href="https://datacarpentry.org/image-processing/edge-detection/index.html">Extra Episode: Edge Detection</a></li>
            
            
            
            
              <li><a href="https://datacarpentry.org/image-processing/figures/index.html">Figures</a></li>
            
            
            
            
              <li><a href="https://datacarpentry.org/image-processing/guide/index.html">Instructor Notes</a></li>
            
            
            
            
              <li><a href="https://datacarpentry.org/image-processing/prereqs/index.html">Prerequisites</a></li>
            
            
          </ul>
        </li>
	

	
        <li><a href="https://datacarpentry.org/image-processing/LICENSE.html">License</a></li>
	
	<li><a href="https://github.com/datacarpentry/image-processing/edit/gh-pages/aio.md" data-checker-ignore="">Improve this page <span class="glyphicon glyphicon-pencil" aria-hidden="true"></span></a></li>
	
      </ul>
      <form class="navbar-form navbar-right" role="search" id="search" onsubmit="google_search(); return false;">
        <div class="form-group">
          <input type="text" id="google-search" placeholder="Search..." aria-label="Google site search">
        </div>
      </form>
    </div>
  </div>
</nav>

      






      





<h1 class="maintitle"><a href="https://datacarpentry.org/image-processing/">Image Processing with Python</a></h1>



<article>

<h1 id="introduction" class="maintitle">Introduction</h1>

<blockquote class="objectives">
  <h2 id="overview">Overview<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#overview" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>

  <div class="row">
    <div class="col-md-3">
      <strong>Teaching:</strong> 5 min
      <br>
      <strong>Exercises:</strong> 0 min
    </div>
    <div class="col-md-9">
      <strong>Questions</strong>
      <ul>
	
	<li><p>What sort of scientific questions can we answer with image processing / computer vision?</p>
</li>
	
	<li><p>What are morphometric problems?</p>
</li>
	
      </ul>
    </div>
  </div>

  <div class="row">
    <div class="col-md-3">
    </div>
    <div class="col-md-9">
      <strong>Objectives</strong>
      <ul>
	
	<li><p>Recognise scientific questions that could be solved with image processing / computer vision.</p>
</li>
	
	<li><p>Recognise morphometric problems (those dealing with the number, size, or shape of the objects in an image).</p>
</li>
	
      </ul>
    </div>
  </div>

</blockquote>

<p>As computer systems have become faster and more powerful,
and cameras and other imaging systems have become commonplace
in many other areas of life,
the need has grown for researchers to be able to
process and analyse image data.
Considering the large volumes of data that can be involved -
high-resolution images that take up a lot of disk space/virtual memory,
and/or collections of many images that must be processed together -
and the time-consuming and error-prone nature of manual processing,
it can be advantageous or even necessary for this processing and analysis
to be automated as a computer program.</p>

<p>This lesson introduces an open source toolkit for processing image data:
the Python programming language
and <a href="https://scikit-image.org/">the <em>scikit-image</em> (<code class="language-plaintext highlighter-rouge">skimage</code>) library</a>.
With careful experimental design, 
Python code can be a powerful instrument in answering many different kinds of questions.</p>

<h2 id="uses-of-image-processing-in-research">Uses of Image Processing in Research<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#uses-of-image-processing-in-research" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>

<p>Automated processing can be used to analyse many different properties of an image,
including the distribution and change in colours in the image,
the number, size, position, orientation, and shape of objects in the image,
and even - when combined with machine learning techniques for object recognition -
the type of objects in the image.</p>

<p>Some examples of image processing methods applied in research include:</p>

<ul>
  <li><a href="https://iopscience.iop.org/article/10.3847/2041-8213/ab0e85">imaging a Black Hole</a></li>
  <li><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3325796/">estimating the population of Emperor Penguins</a></li>
  <li><a href="https://www.cell.com/cell/fulltext/S0092-8674(19)31124-9">the global-scale analysis of marine plankton diversity</a></li>
  <li><a href="https://doi.org/10.1016/j.cmpb.2017.12.008">segmentation of liver and vessels from CT images</a></li>
</ul>

<p>With this lesson,
we aim to provide a thorough grounding in the fundamental concepts and skills
of working with image data in Python.
Most of the examples used in this lesson focus on
one particular class of image processing technique, <em>morphometrics</em>,
but what you will learn can be used to solve a much wider range of problems.</p>

<h2 id="morphometrics">Morphometrics<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#morphometrics" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>

<p>Morphometrics involves counting the number of objects in an image,
analyzing the size of the objects,
or analyzing the shape of the objects.
For example, we might be interested in automatically counting
the number of bacterial colonies growing in a Petri dish,
as shown in this image:</p>

<p><img src="./Image Processing with Python_files/colonies-01.jpg" alt="Bacteria colony"></p>

<p>We could use image processing to find the colonies, count them,
and then highlight their locations on the original image,
resulting in an image like this:</p>

<p><img src="./Image Processing with Python_files/colony-mask.png" alt="Colonies counted"></p>

<blockquote class="callout">
  <h2 id="why-write-a-program-to-do-that">Why write a program to do that?<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#why-write-a-program-to-do-that" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>

  <p>Note that you can easily manually count the number of bacteria colonies
shown in the morphometric example above.
Why should we learn how to write a Python program to do a task
we could easily perform with our own eyes?
There are at least two reasons to learn how to perform tasks like these
with Python and skimage:</p>

  <ol>
    <li>
      <p>What if there are many more bacteria colonies in the Petri dish?
  For example, suppose the image looked like this:</p>

      <p><img src="./Image Processing with Python_files/colonies-03.jpg" alt="Bacteria colony"></p>

      <p>Manually counting the colonies in that image would present more of a challenge.
  A Python program using skimage could count the number of colonies more accurately,
  and much more quickly, than a human could.</p>
    </li>
    <li>
      <p>What if you have hundreds, or thousands, of images to consider?
  Imagine having to manually count colonies on several thousand images
  like those above.
  A Python program using skimage could move through all of the images in seconds;
  how long would a graduate student require to do the task?
  Which process would be more accurate and repeatable?</p>
    </li>
  </ol>

  <p>As you can see, the simple image processing / computer vision techniques you
will learn during this workshop can be very valuable tools for scientific
research.</p>
</blockquote>

<p>As we move through this workshop, 
we will learn image analysis methods useful for many different scientific problems. 
These will be linked together
and applied to a real problem in the final end-of-workshop
<a href="https://datacarpentry.org/image-processing/09-challenges/index.html">capstone challenge</a>.</p>

<p>Let’s get started,
by learning some basics about how images are represented and stored digitally.</p>

<blockquote class="keypoints">
  <h2 id="key-points">Key Points<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#key-points" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>
  <ul>
    
    <li><p>Simple Python and skimage (scikit-image) techniques can be used to solve genuine image analysis problems.</p>
</li>
    
    <li><p>Morphometric problems involve the number, shape, and / or size of the objects in an image.</p>
</li>
    
  </ul>
</blockquote>

<hr>

<h1 id="image-basics" class="maintitle">Image Basics</h1>

<blockquote class="objectives">
  <h2 id="overview-1">Overview<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#overview-1" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>

  <div class="row">
    <div class="col-md-3">
      <strong>Teaching:</strong> 20 min
      <br>
      <strong>Exercises:</strong> 5 min
    </div>
    <div class="col-md-9">
      <strong>Questions</strong>
      <ul>
	
	<li><p>How are images represented in digital format?</p>
</li>
	
      </ul>
    </div>
  </div>

  <div class="row">
    <div class="col-md-3">
    </div>
    <div class="col-md-9">
      <strong>Objectives</strong>
      <ul>
	
	<li><p>Define the terms bit, byte, kilobyte, megabyte, etc.</p>
</li>
	
	<li><p>Explain how a digital image is composed of pixels.</p>
</li>
	
	<li><p>Explain how images are stored in NumPy arrays.</p>
</li>
	
	<li><p>Explain the left-hand coordinate system used in digital images.</p>
</li>
	
	<li><p>Explain the RGB additive colour model used in digital images.</p>
</li>
	
	<li><p>Explain the order of the three colour values in skimage images.</p>
</li>
	
	<li><p>Explain the characteristics of the BMP, JPEG, and TIFF image formats.</p>
</li>
	
	<li><p>Explain the difference between lossy and lossless compression.</p>
</li>
	
	<li><p>Explain the advantages and disadvantages of compressed image formats.</p>
</li>
	
	<li><p>Explain what information could be contained in image metadata.</p>
</li>
	
      </ul>
    </div>
  </div>

</blockquote>

<p>The images we see on hard copy, view with our electronic devices,
or process with our programs are represented and stored in the computer
as numeric abstractions, approximations of what we see with our eyes in the real world.
Before we begin to learn how to process images with Python programs,
we need to spend some time understanding how these abstractions work.</p>

<h2 id="pixels">Pixels<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#pixels" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>

<p>It is important to realise that images are stored as rectangular arrays
of hundreds, thousands, or millions of discrete “picture elements,”
otherwise known as <em>pixels</em>.
Each pixel can be thought of as a single square point of coloured light.</p>

<p>For example, consider this image of a maize seedling,
with a square area designated by a red box:</p>

<p><img src="./Image Processing with Python_files/maize-seedling-original.jpg" alt="Original size image"></p>

<p>Now, if we zoomed in close enough to see the pixels in the red box,
we would see something like this:</p>

<p><img src="./Image Processing with Python_files/maize-seedling-enlarged.jpg" alt="Enlarged image area"></p>

<p>Note that each square in the enlarged image area - each pixel -
is all one colour,
but that each pixel can have a different colour from its neighbors.
Viewed from a distance,
these pixels seem to blend together to form the image we see.</p>

<h2 id="working-with-pixels">Working with Pixels<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#working-with-pixels" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>
<p>As noted, in practice,
real world images will typically be made up of a vast number of pixels,
and each of these pixels will be one of potentially millions of colours.
While we will deal with pictures of such complexity shortly,
let’s start our exploration with 15 pixels in a 5 X 3 matrix with 2 colours and
work our way up to that complexity.</p>

<blockquote class="callout">
  <h2 id="matrices-arrays-images-and-pixels">Matrices, arrays, images and pixels<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#matrices-arrays-images-and-pixels" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>
  <p>The <strong>matrix</strong> is mathematical concept - numbers evenly arranged in a rectangle. This can be a two dimensional rectangle, 
like the shape of the screen you’re looking at now. Or it could be a three dimensional equivalent, a cuboid, or have 
even more dimensions, but always keeping the evenly spaced arrangement of numbers. In computing, <strong>array</strong> refers 
to a structure in the computer’s memory where data is stored in evenly-spaced <strong>elements</strong>. This is strongly analogous 
to a matrix. A <code class="language-plaintext highlighter-rouge">numpy</code> array is a <strong>type</strong> of variable (a simpler example of a type is an integer). For our purposes, 
the distinction between matrices and arrays is not important, we don’t really care how the computer arranges our data 
in its memory. The important thing is that the computer stores values describing the pixels in images, as arrays. And 
the terms matrix and array can be used interchangeably.</p>
</blockquote>

<p>First, the necessary imports:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="s">"""
 * Python libraries for learning and performing image processing.*
"""</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">skimage.io</span>
<span class="kn">import</span> <span class="nn">skimage.viewer</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="nn">ipympl</span>
</code></pre></div></div>

<blockquote class="callout">
  <h2 id="import-statements-in-python">Import Statements in Python<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#import-statements-in-python" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>

  <p>In Python, the <code class="language-plaintext highlighter-rouge">import</code> statement is used to
load additional functionality into a program.
This is necessary when we want our code to do something more specialised,
which cannot easily be achieved with the limited set of basic tools and
data structures available in the default Python environment.</p>

  <p>Additional functionality can be loaded as a single function or object,
a module defining several of these, or a library containing many modules.
You will encounter several different forms of <code class="language-plaintext highlighter-rouge">import</code> statement.</p>

  <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">skimage</span>                 <span class="c1"># form 1, load whole skimage library
</span><span class="kn">import</span> <span class="nn">skimage.io</span>              <span class="c1"># form 2, load skimage.io module only
</span><span class="kn">from</span> <span class="nn">skimage.io</span> <span class="kn">import</span> <span class="n">imread</span>  <span class="c1"># form 3, load only the imread function
</span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>             <span class="c1"># form 4, load all of numpy into an object called np
</span></code></pre></div>  </div>

  <blockquote class="solution">
    <h2 id="further-explanation">Further Explanation<span class="fold-unfold glyphicon glyphicon-collapse-down"></span><a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#further-explanation" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>

    <p style="display: none;">In the example above, form 1 loads the entire <code class="language-plaintext highlighter-rouge">skimage</code> library into the
program as an object.
Individual modules of the library are then available within that object,
e.g. to access the <code class="language-plaintext highlighter-rouge">imread</code> function used in the example above,
you would write <code class="language-plaintext highlighter-rouge">skimage.io.imread()</code>.</p>

    <p style="display: none;">Form 2 loads only the <code class="language-plaintext highlighter-rouge">io</code> module of <code class="language-plaintext highlighter-rouge">skimage</code> into the program.
When we run the code,
the program will take less time and use less memory
because we will not load the whole <code class="language-plaintext highlighter-rouge">skimage</code> library.
The syntax needed to use the module remains unchanged:
to access the <code class="language-plaintext highlighter-rouge">imread</code> function,
we would use the same function call as given for form 1.</p>

    <p style="display: none;">To further reduce the time and memory requirements for your program,
form 3 can be used to import only a specific function/class from a library/module.
Unlike the other forms, when this approach is used,
the imported function or class can be called by its name only,
without prefacing it with the name of the module/library from which it was loaded,
i.e., <code class="language-plaintext highlighter-rouge">imread()</code> instead of <code class="language-plaintext highlighter-rouge">skimage.io.imread()</code> using the example above.
One hazard of this form is that importing like this will overwrite any
object with the same name that was defined/imported earlier in the program,
i.e., the example above would replace any existing object called <code class="language-plaintext highlighter-rouge">imread</code>
with the <code class="language-plaintext highlighter-rouge">imread</code> function from <code class="language-plaintext highlighter-rouge">skimage.io</code>.</p>

    <p style="display: none;">Finally, the <code class="language-plaintext highlighter-rouge">as</code> keyword can be used when importing,
to define a name to be used as shorthand for the library/module being imported.
You may see <code class="language-plaintext highlighter-rouge">as</code> combined with any of the other first three forms of <code class="language-plaintext highlighter-rouge">import</code> statement.</p>

    <p style="display: none;">Which form is used often depends on
the size and number of additional tools being loaded into the program.</p>

  </blockquote>
</blockquote>

<p>Now that we have our libraries loaded,
we will run a Jupyter Magic Command that will ensure our images display
in our Jupyter document with pixel information that will help us
more efficiently run commands later in the session.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">%</span><span class="n">matplotlib</span> <span class="n">widget</span>
</code></pre></div></div>

<p>With that taken care of,
let’s load our image data from disk using
the <code class="language-plaintext highlighter-rouge">imread</code> function from the <code class="language-plaintext highlighter-rouge">skimage.io</code> library and display it using
the <code class="language-plaintext highlighter-rouge">imshow</code> function from the <code class="language-plaintext highlighter-rouge">matplotlib</code> library.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">image</span> <span class="o">=</span> <span class="n">skimage</span><span class="p">.</span><span class="n">io</span><span class="p">.</span><span class="n">imread</span><span class="p">(</span><span class="n">fname</span><span class="o">=</span><span class="s">"data/eight.tif"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="./Image Processing with Python_files/eight.png" alt="Image of 8"></p>

<p>You might be thinking,
“That does look vaguely like an eight,
and I see two colours but how can that be only 15 pixels”.
The display of the eight you see does use a lot more screen pixels to
display our eight so large, but that does not mean there is information
for all those screen pixels in the file.
All those extra pixels are a consequence of our viewer creating
additional pixels through interpolation.
It could have just displayed it as a tiny image using only 15 screen pixels if
the viewer was designed differently.</p>

<p>While many image file formats contain descriptive metadata that can be essential,
the bulk of a picture file is just arrays of numeric information that,
when interpreted according to a certain rule set,
become recognizable as an image to us.
Our image of an eight is no exception,
and <code class="language-plaintext highlighter-rouge">skimage.io</code> stored that image data in an array of arrays making
a 5 x 3 matrix of 15 pixels.
We can demonstrate that by calling on the shape property of our image variable
and see the matrix by printing our image variable to the screen.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="n">image</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext output highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(5, 3)
[[0. 0. 0.]
 [0. 1. 0.]
 [0. 0. 0.]
 [0. 1. 0.]
 [0. 0. 0.]]
</code></pre></div></div>

<p>Thus if we have tools that will allow us to manipulate these arrays of numbers,
we can manipulate the image.
The <code class="language-plaintext highlighter-rouge">numpy</code> library can be particularly useful here,
so let’s try that out using <code class="language-plaintext highlighter-rouge">numpy</code> array slicing.
Notice that the default behavior of the <code class="language-plaintext highlighter-rouge">imshow</code> function appended row and
column numbers that will be helpful to us as we try to address individual or
groups of pixels.
First let’s load another copy of our eight, and then make it look like a zero.</p>

<p>To make it look like a zero,
we need to change the number underlying the centremost pixel to be 1.
With the help of those row and column headers,
at this small scale we can determine the centre pixel is in row labeled 2 and
column labeled 1.
Using array slicing, we can then address and assign a new value to that position.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">zero</span> <span class="o">=</span> <span class="n">skimage</span><span class="p">.</span><span class="n">io</span><span class="p">.</span><span class="n">imread</span><span class="p">(</span><span class="n">fname</span><span class="o">=</span><span class="s">"data/eight.tif"</span><span class="p">)</span>
<span class="n">zero</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span><span class="o">=</span> <span class="mf">1.0</span>
<span class="s">"""
The follwing line of code creates a new figure for imshow to use in displaying our output. Without it, plt.imshow() would overwrite our previous image in the cell above
"""</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">zero</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">zero</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext output highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[[0. 0. 0.]
 [0. 1. 0.]
 [0. 1. 0.]
 [0. 1. 0.]
 [0. 0. 0.]]
</code></pre></div></div>

<p><img src="./Image Processing with Python_files/zero.png" alt="Image of 0"></p>

<blockquote class="callout">
  <h2 id="coordinate-system">Coordinate system<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#coordinate-system" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>

  <p>When we process images, we can access, examine, and / or change
the colour of any pixel we wish.
To do this, we need some convention on how to access pixels
individually; a way to give each one a name, or an address of a sort.</p>

  <p>The most common manner to do this, and the one we will use in our programs,
is to assign a modified Cartesian coordinate system to the image.
The coordinate system we usually see in mathematics has
a horizontal x-axis and a vertical y-axis, like this:</p>

  <p><img src="./Image Processing with Python_files/cartesian-coordinates.png" alt="Cartesian coordinate system"></p>

  <p>The modified coordinate system used for our images will have only positive
coordinates, the origin will be in the upper left corner instead of the
centre, and y coordinate values will get larger as they go down instead of up,
like this:</p>

  <p><img src="./Image Processing with Python_files/image-coordinates.png" alt="Image coordinate system"></p>

  <p>This is called a <em>left-hand coordinate system</em>.
If you hold your left hand in front of your face and point your thumb at the floor,
your extended index finger will correspond to the x-axis
while your thumb represents the y-axis.</p>

  <p><img src="./Image Processing with Python_files/left-hand-coordinates.png" alt="Left-hand coordinate system"></p>

  <p>Until you have worked with images for a while,
the most common mistake that you will make with coordinates is to forget
that y coordinates get larger as they go down instead of up
as in a normal Cartesian coordinate system. Consequently, it may be helpful to think
in terms of counting down rows (r) for the y-axis and across columns (c) for the x-axis. This
can be especially helpful in cases where you need to transpose image viewer data
provided in <em>x,y</em> format to <em>y,x</em> format.  Thus, we will use <em>cx</em> and <em>ry</em> where appropriate
to help bridge these two approaches.</p>
</blockquote>

<blockquote class="challenge">
  <h2 id="changing-pixel-values-5-min">Changing Pixel Values (5 min)<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#changing-pixel-values-5-min" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>

  <p>Load another copy of eight named five,
and then change the value of pixels so you have what looks like a 5 instead of an 8.
Display the image and print out the matrix as well.</p>

  <blockquote class="solution">
    <h2 id="solution">Solution<span class="fold-unfold glyphicon glyphicon-collapse-down"></span><a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#solution" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>
    <p style="display: none;">There are many possible solutions, but one method would be . . .</p>

    <div class="language-python highlighter-rouge" style="display: none;"><div class="highlight"><pre class="highlight"><code><span class="n">five</span> <span class="o">=</span> <span class="n">skimage</span><span class="p">.</span><span class="n">io</span><span class="p">.</span><span class="n">imread</span><span class="p">(</span><span class="n">fname</span><span class="o">=</span><span class="s">"data/eight.tif"</span><span class="p">)</span>
<span class="n">five</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">]</span><span class="o">=</span> <span class="mf">1.0</span>
<span class="n">five</span><span class="p">[</span><span class="mi">3</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="o">=</span> <span class="mf">1.0</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">five</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">five</span><span class="p">)</span>
</code></pre></div>    </div>

    <div class="language-plaintext output highlighter-rouge" style="display: none;"><div class="highlight"><pre class="highlight"><code>[[0. 0. 0.]
 [0. 1. 1.]
 [0. 0. 0.]
 [1. 1. 0.]
 [0. 0. 0.]]
</code></pre></div>    </div>

    <p style="display: none;"><img src="./Image Processing with Python_files/five.png" alt="Image of 5"></p>
  </blockquote>
</blockquote>

<h2 id="more-colours">More colours<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#more-colours" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>

<p>Up to now, we only had a 2 colour matrix,
but we can have more if we use other numbers or fractions.
One common way is to use the numbers between 0 and 255 to allow for
256 different colours or 256 different levels of grey.
Let’s try that out.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#make a copy of eight
</span><span class="n">three_colours</span> <span class="o">=</span> <span class="n">skimage</span><span class="p">.</span><span class="n">io</span><span class="p">.</span><span class="n">imread</span><span class="p">(</span><span class="n">fname</span><span class="o">=</span><span class="s">"data/eight.tif"</span><span class="p">)</span>

<span class="c1">#multiply the whole matrix by 128
</span><span class="n">three_colours</span> <span class="o">=</span> <span class="n">three_colours</span> <span class="o">*</span> <span class="mi">128</span>

<span class="c1"># set the middle row (index 2) to the value of 255., so you end up with the values 0.,128.,and 255
</span><span class="n">three_colours</span><span class="p">[</span><span class="mi">2</span><span class="p">,:]</span> <span class="o">=</span> <span class="mf">255.</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">three_colours</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">three_colours</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="./Image Processing with Python_files/three-colours.png" alt="Image of three colours"></p>

<p>We now have 3 colours, but are they the three colours you expected?
They all appear to be on a continuum of dark purple on the low end and
yellow on the high end.
This is a consequence of the default colour map (cmap) in this library.
You can think of a colour map as an association or mapping of numbers
to a specific colour.
However, the goal here is not to have one number for every possible colour,
but rather to have a continuum of colours that demonstrate relative intensity.
In our specific case here for example,
255 or the highest intensity is mapped to yellow,
and 0 or the lowest intensity is mapped to a dark purple.
The best colour map for your data will vary and there are many options built in,
but this default selection was not arbitrary.
A lot of science went into making this the default due to its robustness
when it comes to how the human mind interprets relative colour values,
grey-scale printability,
and colour-blind friendliness
(You can read more about this default colour map in
<a href="https://matplotlib.org/stable/tutorials/colors/colormaps.html">a Matplotlib tutorial</a>
and <a href="https://bids.github.io/colormap/">an explanatory article by the authors</a>).
Thus it is a good place to start,
and you should change it only with purpose and forethought.
For now, let’s see how you can do that using an alternative map
you have likely seen before where it will be even easier to see it as
a mapped continuum of intensities: greyscale.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">three_colours</span><span class="p">,</span><span class="n">cmap</span><span class="o">=</span><span class="n">plt</span><span class="p">.</span><span class="n">cm</span><span class="p">.</span><span class="n">gray</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="./Image Processing with Python_files/grayscale.png" alt="Image in greyscale"></p>

<p>Above we have exactly the same underying data matrix, but in greyscale.
Zero maps to black, 255 maps to white, and 128 maps to medium grey.
Here we only have a single channel in the data and utilize a grayscale color map
to represent the luminance, or intensity of the data and correspondingly
this channel is referred to as the luminance channel.</p>

<h2 id="even-more-colours">Even More Colours<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#even-more-colours" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>

<p>This is all well and good at this scale,
but what happens when we instead have a picture of a natural landscape that
contains millions of colours.
Having a one to one mapping of number to colour like this would be inefficient
and make adjustments and building tools to do so very difficult.
Rather than larger numbers, the solution is to have more numbers in more dimensions.
Storing the numbers in a multi-dimensional matrix where each colour or
property like transparency is associated with its own dimension allows
for individual contributions to a pixel to be adjusted independently.
This ability to manipulate properties of groups of pixels separately will be
key to certain techniques explored in later chapters of this lesson.
To get started let’s see an example of how different dimensions of information
combine to produce a set of pixels using a 4 X 4 matrix with 3 dimensions
for the colours red, green, and blue.
Rather than loading it from a file, we will generate this example using numpy.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#set the random seed so we all get the same matrix
</span><span class="n">pseudorandomizer</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">RandomState</span><span class="p">(</span><span class="mi">2021</span><span class="p">)</span>
<span class="c1">#create a 4 X 4 checkerboard of random colours
</span><span class="n">checkerboard</span> <span class="o">=</span> <span class="n">pseudorandomizer</span><span class="p">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">255</span><span class="p">,</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>
                                       <span class="p">)</span>
<span class="c1">#restore the default map as you show the image
</span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">checkerboard</span><span class="p">)</span>
<span class="c1">#display the arrays
</span><span class="k">print</span><span class="p">(</span><span class="n">checkerboard</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext output highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[[[116  85  57]
  [128 109  94]
  [214  44  62]
  [219 157  21]]

 [[ 93 152 140]
  [246 198 102]
  [ 70  33 101]
  [  7   1 110]]

 [[225 124 229]
  [154 194 176]
  [227  63  49]
  [144 178  54]]

 [[123 180  93]
  [120   5  49]
  [166 234 142]
  [ 71  85  70]]]
</code></pre></div></div>

<p><img src="./Image Processing with Python_files/checkerboard.png" alt="Image of checkerboard"></p>

<p>Previously we had one number being mapped to one colour or intensity.
Now we are combining the effect of 3 numbers to arrive at a single colour value.
Let’s see an example of that using the blue square at the end of the second row,
which has the index [1,3].</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># extract all the colour information for the blue square
</span><span class="n">upper_right_square</span> <span class="o">=</span> <span class="n">checkerboard</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">,:]</span>
<span class="n">upper_right_square</span>
</code></pre></div></div>

<p>This outputs: array([  7,   1, 110])
The integers in order represent Red, Green, and Blue.
Looking at the 3 values and knowing how they map,
can help us understand why it is blue.
If we divide each value by 255, which is the maximum,
we can determine how much it is contributing relative to its maximum potential.
Effectively, the red is at 7/255 or 2.8 percent of its potential,
the green is at 1/255 or 0.4 percent,
and blue is 110/255 or 43.1 percent of its potential.
So when you mix those three intensities of colour,
blue is winning by a wide margin,
but the red and green still contribute to make it a slightly different
shade of blue than 0,0,110 would be on its own.</p>

<p>These colours mapped to dimensions of the matrix may be referred to as channels.
It may be helpful to display each of these channels independently,
to help us understand what is happening.
We can do that by multiplying our image array representation with
a 1d matrix that has a one for the channel we want to keep and zeros for the rest.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">red_channel</span> <span class="o">=</span> <span class="n">checkerboard</span> <span class="o">*</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">red_channel</span><span class="p">)</span>
</code></pre></div></div>
<p><img src="./Image Processing with Python_files/checkerboard-red-channel.png" alt="Image of red channel"></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">green_channel</span> <span class="o">=</span> <span class="n">checkerboard</span> <span class="o">*</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">green_channel</span><span class="p">)</span>
</code></pre></div></div>
<p><img src="./Image Processing with Python_files/checkerboard-green-channel.png" alt="Image of green channel"></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">blue_channel</span> <span class="o">=</span> <span class="n">checkerboard</span> <span class="o">*</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">blue_channel</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="./Image Processing with Python_files/checkerboard-blue-channel.png" alt="Image of blue channel"></p>

<p>If we look at the upper [1,3] square in all three figures,
we can see each of those colour contributions in action.
Notice that there are several squares in the blue figure that look
even more intensely blue than square [1,3].
When all three channels are combined though,
the blue light of those squares is being diluted by the relative strength
of red and green being mixed in with them.</p>

<h2 id="24-bit-rgb-colour">24 bit RGB Colour<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#24-bit-rgb-colour" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>

<p>This last colour model we used,
known as the <em>RGB (Red, Green, Blue)</em> model, is the most common.</p>

<p>As we saw, the RGB model is an <em>additive</em> colour model, which means that the primary
colours are mixed together to form other colours.
Most frequently, the amount of the primary colour added is represented as
an integer in the closed range [0, 255] as seen in the example.
Therefore, there are 256 discrete amounts of each primary colour that can be
added to produce another colour.
The number of discrete amounts of each colour, 256, corresponds to the number of
bits used to hold the colour channel value, which is eight (2<sup>8</sup>=256).
Since we have three channels with 8 bits for each (8+8+8=24),
this is called 24-bit colour depth.</p>

<p>Any particular colour in the RGB model can be expressed by a triplet of
integers in [0, 255], representing the red, green, and blue channels,
respectively.
A larger number in a channel means that more of that primary colour is present.</p>

<blockquote class="challenge">
  <h2 id="thinking-about-rgb-colours-5-min">Thinking about RGB colours (5 min)<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#thinking-about-rgb-colours-5-min" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>

  <p>Suppose that we represent colours as triples (r, g, b), where each of r, g,
and b is an integer in [0, 255].
What colours are represented by each of these triples?
(Try to answer these questions without reading further.)</p>

  <ol>
    <li>(255, 0, 0)</li>
    <li>(0, 255, 0)</li>
    <li>(0, 0, 255)</li>
    <li>(255, 255, 255)</li>
    <li>(0, 0, 0)</li>
    <li>(128, 128, 128)</li>
  </ol>

  <blockquote class="solution">
    <h2 id="solution-1">Solution<span class="fold-unfold glyphicon glyphicon-collapse-down"></span><a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#solution-1" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>

    <ol style="display: none;">
      <li>(255, 0, 0) represents red, because the red channel is maximised, while
 the other two channels have the minimum values.</li>
      <li>(0, 255, 0) represents green.</li>
      <li>(0, 0, 255) represents blue.</li>
      <li>(255, 255, 255) is a little harder. When we mix the maximum value of all
 three colour channels, we see the colour white.</li>
      <li>(0, 0, 0) represents the absence of all colour, or black.</li>
      <li>(128, 128, 128) represents a medium shade of gray.
  Note that the 24-bit RGB colour model provides at least 254 shades of gray,
  rather than only fifty.</li>
    </ol>

    <p style="display: none;">Note that the RGB colour model may run contrary to your experience,
especially if you have mixed primary colours of paint to create new colours.
In the RGB model, the <em>lack of</em> any colour is black,
while the <em>maximum amount</em> of each of the primary colours is white.
With physical paint, we might start with a white base,
and then add differing amounts of other paints to produce a darker shade.</p>

  </blockquote>
</blockquote>

<p>After completing the previous challenge,
we can look at some further examples of 24-bit RGB colours, in a visual way.
The image in the next challenge shows some colour names,
their 24-bit RGB triplet values, and the colour itself.</p>

<blockquote class="challenge">
  <h2 id="rgb-colour-table-optional-not-included-in-timing">RGB colour table (optional, not included in timing)<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#rgb-colour-table-optional-not-included-in-timing" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>

  <p><img src="./Image Processing with Python_files/colour-table.png" alt="RGB colour table"></p>

  <p>We cannot really provide a complete table.
To see why, answer this question:
How many possible colours can be represented with the 24-bit RGB model?</p>

  <blockquote class="solution">
    <h2 id="solution-2">Solution<span class="fold-unfold glyphicon glyphicon-collapse-down"></span><a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#solution-2" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>

    <p style="display: none;">There are 24 total bits in an RGB colour of this type,
and each bit can be on or off,
and so there are 2<sup>24</sup> = 16,777,216
possible colours with our additive, 24-bit RGB colour model.</p>

  </blockquote>
</blockquote>

<p>Although 24-bit colour depth is common, there are other options.
We might have 8-bit colour
(3 bits for red and green, but only 2 for blue, providing 8 × 8 × 4 = 256 colours)
or 16-bit colour
(4 bits for red, green, and blue, plus 4 more for transparency,
providing 16 × 16 × 16 = 4096 colours), for example.
There are colour depths with more than eight bits per channel,
but as the human eye can only discern approximately 10 million different colours,
these are not often used.</p>

<p>If you are using an older or inexpensive laptop screen or LCD monitor to view images,
it may only support 18-bit colour, capable of displaying
64 × 64 × 64 = 262,144 colours.
24-bit colour images will be converted in some manner to 18-bit,
and thus the colour quality you see will not match what is actually in the image.</p>

<p>We can combine our coordinate system with the 24-bit RGB colour model to gain a
conceptual understanding of the images we will be working with.
An image is a rectangular array of pixels,
each with its own coordinate.
Each pixel in the image is a square point of coloured light,
where the colour is specified by a 24-bit RGB triplet.
Such an image is an example of <em>raster graphics</em>.</p>

<h2 id="image-formats">Image formats<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#image-formats" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>

<p>Although the images we will manipulate in our programs are conceptualised as
rectangular arrays of RGB triplets,
they are not necessarily created, stored, or transmitted in that format.
There are several image formats we might encounter,
and we should know the basics of at least of few of them.
Some formats we might encounter, and their file extensions, are shown in this table:</p>

<table class="table table-striped">
  <thead>
    <tr>
      <th style="text-align: left">Format</th>
      <th style="text-align: left">Extension</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: left">Device-Independent Bitmap (BMP)</td>
      <td style="text-align: left">.bmp</td>
    </tr>
    <tr>
      <td style="text-align: left">Joint Photographic Experts Group (JPEG)</td>
      <td style="text-align: left">.jpg or .jpeg</td>
    </tr>
    <tr>
      <td style="text-align: left">Tagged Image File Format (TIFF)</td>
      <td style="text-align: left">.tif or .tiff</td>
    </tr>
  </tbody>
</table>

<h2 id="bmp">BMP<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#bmp" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>

<p>The file format that comes closest to our preceding conceptualisation of images
is the Device-Independent Bitmap, or BMP, file format.
BMP files store raster graphics images as long sequences of binary-encoded numbers
that specify the colour of each pixel in the image.
Since computer files are one-dimensional structures,
the pixel colours are stored one row at a time.
That is, the first row of pixels (those with y-coordinate 0) are stored first,
followed by the second row (those with y-coordinate 1), and so on.
Depending on how it was created,
a BMP image might have 8-bit, 16-bit, or 24-bit colour depth.</p>

<p>24-bit BMP images have a relatively simple file format,
can be viewed and loaded across a wide variety of operating systems,
and have high quality.
However, BMP images are not <em>compressed</em>,
resulting in very large file sizes for any useful image resolutions.</p>

<p>The idea of image compression is important to us for two reasons:
first, compressed images have smaller file sizes,
and are therefore easier to store and transmit;
and second,
compressed images may not have as much detail as their uncompressed counterparts,
and so our programs may not be able to detect some important aspect
if we are working with compressed images.
Since compression is important to us,
we should take a brief detour and discuss the concept.</p>

<h2 id="image-compression">Image compression<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#image-compression" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>

<p>Before discussing additional formats,
familiarity with image compression will be helpful.
Let’s delve into that subject with a challenge.
For this challenge,
you will need to know about bits / bytes and
how those are used to express computer storage capacities.
If you already know, you can skip to the challenge below.</p>

<blockquote class="callout">
  <h2 id="bits-and-bytes">Bits and bytes<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#bits-and-bytes" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>

  <p>Before we talk specifically about images,
we first need to understand how numbers are stored in a modern digital computer.
When we think of a number,
we do so using a <em>decimal</em>, or <em>base-10</em> place-value number system.
For example, a number like 659 is
6 × 10<sup>2</sup> + 5 × 10<sup>1</sup> + 9 × 10<sup>0</sup>.
Each digit in the number is multiplied by a power of 10,
based on where it occurs,
and there are 10 digits that can occur in each position
(0, 1, 2, 3, 4, 5, 6, 7, 8, 9).</p>

  <p>In principle,
computers could be constructed to represent numbers in exactly the same way.
But, the electronic circuits inside a computer are much easier to construct
if we restrict the numeric base to only two, instead of 10.
(It is easier for circuitry to tell the difference between
two voltage levels than it is to differentiate among 10 levels.)
So, values in a computer are stored using a <em>binary</em>,
or <em>base-2</em> place-value number system.</p>

  <p>In this system, each symbol in a number is called a <em>bit</em> instead of a digit,
and there are only two values for each bit (0 and 1).
We might imagine a four-bit binary number, 1101.
Using the same kind of place-value expansion as we did above for 659,
we see that
1101 = 1 × 2<sup>3</sup> + 1 × 2<sup>2</sup> + 0 × 2<sup>1</sup> + 1 × 2<sup>0</sup>,
which if we do the math is 8 + 4 + 0 + 1, or 13 in decimal.</p>

  <p>Internally,
computers have a minimum number of bits that they work with at a given time: eight.
A group of eight bits is called a <em>byte</em>.
The amount of memory (RAM) and drive space our computers have is quantified
by terms like Megabytes (MB), Gigabytes (GB), and Terabytes (TB).
The following table provides more formal definitions for these terms.</p>

  <table class="table table-striped">
    <thead>
      <tr>
        <th style="text-align: left">Unit</th>
        <th>Abbreviation</th>
        <th style="text-align: left">Size</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td style="text-align: left">Kilobyte</td>
        <td>KB</td>
        <td style="text-align: left">1024 bytes</td>
      </tr>
      <tr>
        <td style="text-align: left">Megabyte</td>
        <td>MB</td>
        <td style="text-align: left">1024 KB</td>
      </tr>
      <tr>
        <td style="text-align: left">Gigabyte</td>
        <td>GB</td>
        <td style="text-align: left">1024 MB</td>
      </tr>
      <tr>
        <td style="text-align: left">Terabyte</td>
        <td>TB</td>
        <td style="text-align: left">1024 GB</td>
      </tr>
    </tbody>
  </table>
</blockquote>

<blockquote class="challenge">
  <h2 id="bmp-image-size-optional-not-included-in-timing">BMP image size (optional, not included in timing)<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#bmp-image-size-optional-not-included-in-timing" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>

  <p>Imagine that we have a fairly large, but very boring image:
a 5,000 × 5,000 pixel image composed of nothing but white pixels.
If we used an uncompressed image format such as BMP,
with the 24-bit RGB colour model,
how much storage would be required for the file?</p>

  <blockquote class="solution">
    <h2 id="solution-3">Solution<span class="fold-unfold glyphicon glyphicon-collapse-down"></span><a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#solution-3" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>
    <p style="display: none;">In such an image, there are 5,000 × 5,000 = 25,000,000 pixels,
and 24 bits for each pixel,
leading to 25,000,000 × 24 = 600,000,000 bits,
or 75,000,000 bytes (71.5MB).
That is quite a lot of space for a very uninteresting image!</p>

  </blockquote>
</blockquote>

<p>Since image files can be very large,
various <em>compression</em> schemes exist for saving
(approximately) the same information while using less space.
These compression techniques can be categorised as <em>lossless</em> or <em>lossy</em>.</p>

<h3 id="lossless-compression">Lossless compression<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#lossless-compression" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h3>

<p>In lossless image compression,
we apply some algorithm (i.e., a computerised procedure) to the image,
resulting in a file that is significantly smaller than
the uncompressed BMP file equivalent would be.
Then, when we wish to load and view or process the image,
our program reads the compressed file, and reverses the compression process,
resulting in an image that is <em>identical</em> to the original.
Nothing is lost in the process – hence the term “lossless.”</p>

<p>The general idea of lossless compression is to somehow detect
long patterns of bytes in a file that are repeated over and over,
and then assign a smaller bit pattern to represent the longer sample.
Then, the compressed file is made up of the smaller patterns,
rather than the larger ones,
thus reducing the number of bytes required to save the file.
The compressed file also contains
a table of the substituted patterns and the originals,
so when the file is decompressed it can be
made identical to the original before compression.</p>

<p>To provide you with a concrete example,
consider the 71.5 MB white BMP image discussed above.
When put through the zip compression utility on Microsoft Windows,
the resulting .zip file is only 72 KB in size!
That is, the .zip version of the image is
three orders of magnitude smaller than the original,
and it can be decompressed into a file that is
byte-for-byte the same as the original.
Since the original is so repetitious -
simply the same colour triplet repeated 25,000,000 times -
the compression algorithm can dramatically reduce the size of the file.</p>

<p>If you work with .zip or .gz archives, you are dealing with lossless
compression.</p>

<h3 id="lossy-compression">Lossy compression<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#lossy-compression" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h3>

<p>Lossy compression takes the original image and discards some of the detail in it,
resulting in a smaller file format.
The goal is to only throw away detail that someone viewing the image would not notice.
Many lossy compression schemes have adjustable levels of compression,
so that the image creator can choose the amount of detail that is lost.
The more detail that is sacrificed,
the smaller the image files will be -
but of course, the detail and richness of the image will be lower as well.</p>

<p>This is probably fine for images that are shown on Web pages
or printed off on 4 × 6 photo paper,
but may or may not be fine for scientific work.
You will have to decide whether the loss of image quality and detail are
important to your work,
versus the space savings afforded by a lossy compression format.</p>

<p>It is important to understand that
once an image is saved in a lossy compression format,
the lost detail is just that - lost.
I.e., unlike lossless formats,
given an image saved in a lossy format,
there is no way to reconstruct the original image in a byte-by-byte manner.</p>

<h2 id="jpeg">JPEG<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#jpeg" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>

<p>JPEG images are perhaps the most commonly encountered digital images today.
JPEG uses lossy compression,
and the degree of compression can be tuned to your liking.
It supports 24-bit colour depth,
and since the format is so widely used,
JPEG images can be viewed and manipulated easily on all computing platforms.</p>

<blockquote class="challenge">
  <h2 id="examining-actual-image-sizes-optional-not-included-in-timing">Examining actual image sizes (optional, not included in timing)<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#examining-actual-image-sizes-optional-not-included-in-timing" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>

  <p>Let us see the effects of image compression on image size with actual images.
The following script creates a square white image 5000 X 5000 pixels,
and then saves it as a BMP and as a JPEG image.</p>

  <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">skimage.io</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="n">dim</span> <span class="o">=</span> <span class="mi">5000</span>

<span class="n">img</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">dim</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="s">"uint8"</span><span class="p">)</span>
<span class="n">img</span><span class="p">.</span><span class="n">fill</span><span class="p">(</span><span class="mi">255</span><span class="p">)</span>

<span class="n">skimage</span><span class="p">.</span><span class="n">io</span><span class="p">.</span><span class="n">imsave</span><span class="p">(</span><span class="n">fname</span><span class="o">=</span><span class="s">"data/ws.bmp"</span><span class="p">,</span> <span class="n">arr</span><span class="o">=</span><span class="n">img</span><span class="p">)</span>
<span class="n">skimage</span><span class="p">.</span><span class="n">io</span><span class="p">.</span><span class="n">imsave</span><span class="p">(</span><span class="n">fname</span><span class="o">=</span><span class="s">"data/ws.jpg"</span><span class="p">,</span> <span class="n">arr</span><span class="o">=</span><span class="n">img</span><span class="p">)</span>
</code></pre></div>  </div>

  <p>Examine the file sizes of the two output files, <code class="language-plaintext highlighter-rouge">ws.bmp</code> and <code class="language-plaintext highlighter-rouge">ws.jpg</code>.
Does the BMP image size match our previous prediction?
How about the JPEG?</p>

  <blockquote class="solution">
    <h2 id="solution-4">Solution<span class="fold-unfold glyphicon glyphicon-collapse-down"></span><a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#solution-4" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>

    <p style="display: none;">The BMP file, <code class="language-plaintext highlighter-rouge">ws.bmp</code>, is 75,000,054 bytes,
which matches our prediction very nicely.
The JPEG file, <code class="language-plaintext highlighter-rouge">ws.jpg</code>, is 392,503 bytes,
two orders of magnitude smaller than the bitmap version.</p>

  </blockquote>
</blockquote>

<blockquote class="challenge">
  <h2 id="comparing-lossless-versus-lossy-compression-optional-not-included-in-timing">Comparing lossless versus lossy compression (optional, not included in timing)<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#comparing-lossless-versus-lossy-compression-optional-not-included-in-timing" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>

  <p>Let us see a hands-on example of lossless versus lossy compression.
Once again, open a terminal and navigate to the <code class="language-plaintext highlighter-rouge">data/</code> directory.
The two output images, <code class="language-plaintext highlighter-rouge">ws.bmp</code> and <code class="language-plaintext highlighter-rouge">ws.jpg</code>, should still be in the directory,
along with another image, <code class="language-plaintext highlighter-rouge">tree.jpg</code>.</p>

  <p>We can apply lossless compression to any file by using the <code class="language-plaintext highlighter-rouge">zip</code> command.
Recall that the <code class="language-plaintext highlighter-rouge">ws.bmp</code> file contains 75,000,054 bytes.
Apply lossless compression to this image by executing the following command:
<code class="language-plaintext highlighter-rouge">zip ws.zip ws.bmp</code>.
This command tells the computer to create a new compressed file,
<code class="language-plaintext highlighter-rouge">ws.zip</code>, from the original bitmap image.
Execute a similar command on the tree JPEG file: <code class="language-plaintext highlighter-rouge">zip tree.zip tree.jpg</code>.</p>

  <p>Having created the compressed file,
use the <code class="language-plaintext highlighter-rouge">ls -al</code> command to display the contents of the directory.
How big are the compressed files?
How do those compare to the size of <code class="language-plaintext highlighter-rouge">ws.bmp</code> and <code class="language-plaintext highlighter-rouge">tree.jpg</code>?
What can you conclude from the relative sizes?</p>

  <blockquote class="solution">
    <h2 id="solution-5">Solution<span class="fold-unfold glyphicon glyphicon-collapse-down"></span><a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#solution-5" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>

    <p style="display: none;">Here is a partial directory listing, showing the sizes of the relevant files there:</p>

    <div class="language-plaintext output highlighter-rouge" style="display: none;"><div class="highlight"><pre class="highlight"><code>-rw-rw-r--  1 diva diva   154344 Jun 18 08:32 tree.jpg
-rw-rw-r--  1 diva diva   146049 Jun 18 08:53 tree.zip
-rw-rw-r--  1 diva diva 75000054 Jun 18 08:51 ws.bmp
-rw-rw-r--  1 diva diva    72986 Jun 18 08:53 ws.zip
</code></pre></div>    </div>

    <p style="display: none;">We can see that the regularity of the bitmap image
(remember, it is a 5,000 x 5,000 pixel image containing only white pixels)
allows the lossless compression scheme to compress the file quite effectively.
On the other hand, compressing <code class="language-plaintext highlighter-rouge">tree.jpg</code> does not create a much smaller file;
this is because the JPEG image was already in a compressed format.</p>

  </blockquote>
</blockquote>

<p>Here is an example showing how JPEG compression might impact image quality.
Consider this image of several maize seedlings
(scaled down here from 11,339 × 11,336 pixels in order to fit the display).</p>

<p><img src="./Image Processing with Python_files/quality-original.jpg" alt="Original image"></p>

<p>Now, let us zoom in and look at a small section of the label in the original,
first in the uncompressed format:</p>

<p><img src="./Image Processing with Python_files/quality-tif.jpg" alt="Enlarged, uncompressed"></p>

<p>Here is the same area of the image, but in JPEG format.
We used a fairly aggressive compression parameter to make the JPEG,
in order to illustrate the problems you might encounter with the format.</p>

<p><img src="./Image Processing with Python_files/quality-jpg.jpg" alt="Enlarged, compressed"></p>

<p>The JPEG image is of clearly inferior quality.
It has less colour variation and noticeable pixelation.
Quality differences become even more marked when one examines
the colour histograms for each image.
A histogram shows how often each colour value appears in an image.
The histograms for the uncompressed (left) and compressed (right) images
are shown below:</p>

<p><img src="./Image Processing with Python_files/quality-histogram.jpg" alt="Uncompressed histogram"></p>

<p>We we learn how to make histograms such as these later on in the workshop.
The differences in the colour histograms are even more apparent than in the
images themselves;
clearly the colours in the JPEG image are different from the uncompressed version.</p>

<p>If the quality settings for your JPEG images are high
(and the compression rate therefore relatively low),
the images may be of sufficient quality for your work.
It all depends on how much quality you need,
and what restrictions you have on image storage space.
Another consideration may be <em>where</em> the images are stored.
For example,if your images are stored in the cloud and therefore
must be downloaded to your system before you use them,
you may wish to use a compressed image format to speed up file transfer time.</p>

<h2 id="png">PNG<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#png" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>

<p>PNG images are well suited for storing diagrams. It uses a lossless compression and is hence often used 
in web applications for non-photographic images. The format is able to store RGB and plain luminance (single channel, without an associated color) data, among others. Image data is stored row-wise and then, per row, a simple filter, like taking the difference of adjacent pixels, can be applied to
increase the compressability of the data. The filtered data is then compressed in the next step and written out to the disk.</p>

<h2 id="tiff">TIFF<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#tiff" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>

<p>TIFF images are popular with publishers, graphics designers, and photographers.
TIFF images can be uncompressed,
or compressed using either lossless or lossy compression schemes,
depending on the settings used,
and so TIFF images seem to have the benefits of both the BMP and JPEG formats.
The main disadvantage of TIFF images
(other than the size of images in the uncompressed version of the format)
is that they are not universally readable by image viewing and manipulation software.</p>

<h2 id="metadata">Metadata<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#metadata" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>

<p>JPEG and TIFF images support the inclusion of <em>metadata</em> in images.
Metadata is textual information that is contained within an image file.
Metadata holds information about the image itself,
such as when the image was captured,
where it was captured,
what type of camera was used and with what settings, etc.
We normally don’t see this metadata when we view an image,
but programs exist that can allow us to view it if we wish to
(see <a href="https://datacarpentry.org/image-processing/aio/index.html#viewing-metadata"><em>Accessing Metadata</em></a>, below).
The important thing to be aware of at this stage is that
you cannot rely on the metadata of an image being preserved
when you use software to process that image.
The image processing library that we will use in the rest of this lesson,
<code class="language-plaintext highlighter-rouge">skimage</code>, <em>does not</em> include metadata when saving new images.
So remember: <strong>if metadata is important to you,
take precautions to always preserve the original files</strong>.</p>

<blockquote class="callout">
  <h2 id="accessing-metadata">Accessing Metadata<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#accessing-metadata" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>

  <p>Although <code class="language-plaintext highlighter-rouge">skimage</code> does not provide a way to display or explore the metadata
associated with an image (and subsequently cannot preserve that metadata
when modifying an image file),
other software exists that can help you to do so,
e.g. <a href="https://imagej.net/Fiji">Fiji</a>
and <a href="https://imagemagick.org/index.php">ImageMagick</a>.
We recommend you explore these options if you need to work with
the metadata of your images.</p>
</blockquote>

<h2 id="summary-of-image-formats-used-in-this-lesson">Summary of image formats used in this lesson<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#summary-of-image-formats-used-in-this-lesson" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>

<p>The following table summarises the characteristics of the BMP, JPEG, and TIFF
image formats:</p>

<table class="table table-striped">
  <thead>
    <tr>
      <th style="text-align: left">Format</th>
      <th style="text-align: left">Compression</th>
      <th style="text-align: left">Metadata</th>
      <th style="text-align: left">Advantages</th>
      <th style="text-align: left">Disadvantages</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: left">BMP</td>
      <td style="text-align: left">None</td>
      <td style="text-align: left">None</td>
      <td style="text-align: left">Universally viewable,</td>
      <td style="text-align: left">Large file sizes</td>
    </tr>
    <tr>
      <td style="text-align: left">&nbsp;</td>
      <td style="text-align: left">&nbsp;</td>
      <td style="text-align: left">&nbsp;</td>
      <td style="text-align: left">high quality</td>
      <td style="text-align: left">&nbsp;</td>
    </tr>
    <tr>
      <td style="text-align: left">JPEG</td>
      <td style="text-align: left">Lossy</td>
      <td style="text-align: left">Yes</td>
      <td style="text-align: left">Universally viewable,</td>
      <td style="text-align: left">Detail may be lost</td>
    </tr>
    <tr>
      <td style="text-align: left">&nbsp;</td>
      <td style="text-align: left">&nbsp;</td>
      <td style="text-align: left">&nbsp;</td>
      <td style="text-align: left">smaller file size</td>
      <td style="text-align: left">&nbsp;</td>
    </tr>
    <tr>
      <td style="text-align: left">PNG</td>
      <td style="text-align: left">Lossless</td>
      <td style="text-align: left"><a href="https://www.w3.org/TR/PNG/#11keywords">Yes</a></td>
      <td style="text-align: left">Universally viewable, <a href="https://www.w3.org/TR/PNG/">open standard</a>, smaller file size</td>
      <td style="text-align: left">Metadata less flexible than TIFF, RGB only</td>
    </tr>
    <tr>
      <td style="text-align: left">TIFF</td>
      <td style="text-align: left">None, lossy,</td>
      <td style="text-align: left">Yes</td>
      <td style="text-align: left">High quality or</td>
      <td style="text-align: left">Not universally viewable</td>
    </tr>
    <tr>
      <td style="text-align: left">&nbsp;</td>
      <td style="text-align: left">or lossless</td>
      <td style="text-align: left">&nbsp;</td>
      <td style="text-align: left">smaller file size</td>
      <td style="text-align: left">&nbsp;</td>
    </tr>
  </tbody>
</table>

<blockquote class="keypoints">
  <h2 id="key-points-1">Key Points<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#key-points-1" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>
  <ul>
    
    <li><p>Digital images are represented as rectangular arrays of square pixels.</p>
</li>
    
    <li><p>Digital images use a left-hand coordinate system, with the origin in the upper left corner, the x-axis running to the right, and the y-axis running down. Some learners may prefer to think in terms of counting down rows for the y-axis and across columns for the x-axis.  Thus, we will make an effort to allow for both approaches in our lesson presentation.</p>
</li>
    
    <li><p>Most frequently, digital images use an additive RGB model, with eight bits for the red, green, and blue channels.</p>
</li>
    
    <li><p>skimage images are stored as multi-dimensional NumPy arrays.</p>
</li>
    
    <li><p>In skimage images, the red channel is specified first, then the green, then the blue, i.e., RGB.</p>
</li>
    
    <li><p>Lossless compression retains all the details in an image, but lossy compression results in loss of some of the original image detail.</p>
</li>
    
    <li><p>BMP images are uncompressed, meaning they have high quality but also that their file sizes are large.</p>
</li>
    
    <li><p>JPEG images use lossy compression, meaning that their file sizes are smaller, but image quality may suffer.</p>
</li>
    
    <li><p>TIFF images can be uncompressed or compressed with lossy or lossless compression.</p>
</li>
    
    <li><p>Depending on the camera or sensor, various useful pieces of information may be stored in an image file, in the image metadata.</p>
</li>
    
  </ul>
</blockquote>

<hr>

<h1 id="working-with-skimage" class="maintitle">Working with skimage</h1>

<blockquote class="objectives">
  <h2 id="overview-2">Overview<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#overview-2" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>

  <div class="row">
    <div class="col-md-3">
      <strong>Teaching:</strong> 70 min
      <br>
      <strong>Exercises:</strong> 50 min
    </div>
    <div class="col-md-9">
      <strong>Questions</strong>
      <ul>
	
	<li><p>How can the skimage Python computer vision library be used to work with images?</p>
</li>
	
      </ul>
    </div>
  </div>

  <div class="row">
    <div class="col-md-3">
    </div>
    <div class="col-md-9">
      <strong>Objectives</strong>
      <ul>
	
	<li><p>Read, display, and save images.</p>
</li>
	
	<li><p>Resize images with skimage.</p>
</li>
	
	<li><p>Perform simple image thresholding with NumPy array operations.</p>
</li>
	
	<li><p>Extract sub-images using array slicing.</p>
</li>
	
      </ul>
    </div>
  </div>

</blockquote>

<p>We have covered much of how images are represented in computer software. In this episode we will learn some more methods
 for accessing and changing digital images.</p>

<h2 id="reading-displaying-and-saving-images">Reading, displaying, and saving images<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#reading-displaying-and-saving-images" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>

<p>Skimage provides easy-to-use functions for reading, displaying, and saving images.
All of the popular image formats, such as BMP, PNG, JPEG, and TIFF are supported,
along with several more esoteric formats.
<a href="http://scikit-image.org/docs/stable/">The skimage documentation</a>
has more information about supported file formats.</p>

<p>Let us examine a simple Python program to load, display,
and save an image to a different format.
Here are the first few lines:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="s">"""
 * Python program to open, display, and save an image.
 *
"""</span>
<span class="kn">import</span> <span class="nn">skimage.io</span>

<span class="c1"># read image
</span><span class="n">image</span> <span class="o">=</span> <span class="n">skimage</span><span class="p">.</span><span class="n">io</span><span class="p">.</span><span class="n">imread</span><span class="p">(</span><span class="n">fname</span><span class="o">=</span><span class="s">"data/chair.jpg"</span><span class="p">)</span>
</code></pre></div></div>

<p>First, we import the <code class="language-plaintext highlighter-rouge">io</code> module of skimage (<code class="language-plaintext highlighter-rouge">skimage.io</code>) so
we can read and write images.
Then, we use the <code class="language-plaintext highlighter-rouge">skimage.io.imread()</code> function to read a JPEG image entitled <strong>chair.jpg</strong>.
Skimage reads the image, converts it from JPEG into a NumPy array,
and returns the array; we save the array in a variable named <code class="language-plaintext highlighter-rouge">image</code>.</p>

<p>Next, we will do something with the image:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
</code></pre></div></div>

<p>Once we have the image in the program,
we first call <code class="language-plaintext highlighter-rouge">plt.subplots()</code> so that we will have
a fresh figure with a set of axis independent from our previous calls.
Next we call <code class="language-plaintext highlighter-rouge">plt.imshow()</code> in order to display the image.</p>

<blockquote class="callout">
  <h2 id="why-not-use-skimageioimshow">Why not use <code class="language-plaintext highlighter-rouge">skimage.io.imshow()</code><a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#why-not-use-skimageioimshow" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>

  <p>The <em>skimage</em> library has its own function to display an image,
so you might be asking why we don’t use it here.
It is certainly something you should be aware of and
may use as you see fit in your own code,
but the details of what it will do to display the image are
currently in the process of change.
Thus, calling <code class="language-plaintext highlighter-rouge">imshow()</code> off the <em>matplotlib.pyplot</em> library at this time
ensures participants have the experience we need across platforms for this lesson,
so we will be doing that instead.</p>

</blockquote>

<p>Now, we will save the image in another format:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># save a new version in .tif format
</span><span class="n">skimage</span><span class="p">.</span><span class="n">io</span><span class="p">.</span><span class="n">imsave</span><span class="p">(</span><span class="n">fname</span><span class="o">=</span><span class="s">"data/chair.tif"</span><span class="p">,</span> <span class="n">arr</span><span class="o">=</span><span class="n">image</span><span class="p">)</span>
</code></pre></div></div>

<p>The final statement in the program, <code class="language-plaintext highlighter-rouge">skimage.io.imsave(fname="chair.tif", arr=image)</code>,
writes the image to a file named <code class="language-plaintext highlighter-rouge">chair.tif</code> in the <code class="language-plaintext highlighter-rouge">data/</code> directory.
The <code class="language-plaintext highlighter-rouge">imsave()</code> function automatically determines the type of the file,
based on the file extension we provide.
In this case, the <code class="language-plaintext highlighter-rouge">.tif</code> extension causes the image to be saved as a TIFF.</p>

<blockquote class="callout">
  <h2 id="metadata-revisited">Metadata, revisited<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#metadata-revisited" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>

  <p>Remember, as mentioned in the previous section, <em>images saved with <code class="language-plaintext highlighter-rouge">imsave</code>
will not retain any metadata associated with the original image
that was loaded into Python!</em>
If the image metadata is important to you, be sure to <strong>always keep an unchanged
copy of the original image!</strong></p>
</blockquote>

<blockquote class="callout">
  <h2 id="extensions-do-not-always-dictate-file-type">Extensions do not always dictate file type<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#extensions-do-not-always-dictate-file-type" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>

  <p>The skimage <code class="language-plaintext highlighter-rouge">imsave()</code> function automatically uses the file type we specify in
the file name parameter’s extension.
Note that this is not always the case.
For example, if we are editing a document in Microsoft Word,
and we save the document as <code class="language-plaintext highlighter-rouge">paper.pdf</code> instead of <code class="language-plaintext highlighter-rouge">paper.docx</code>,
the file <em>is not</em> saved as a PDF document.</p>
</blockquote>

<blockquote class="callout">
  <h2 id="named-versus-positional-arguments">Named versus positional arguments<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#named-versus-positional-arguments" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>

  <p>When we call functions in Python,
there are two ways we can specify the necessary arguments.
We can specify the arguments <em>positionally</em>, i.e.,
in the order the parameters appear in the function definition,
or we can use <em>named arguments</em>.</p>

  <p>For example, the <code class="language-plaintext highlighter-rouge">skimage.io.imread()</code> function definition specifies two parameters,
the file name to read and an optional flag value.
So, we could load in the chair image in the sample code above
using positional parameters like this:</p>

  <p><code class="language-plaintext highlighter-rouge">image = skimage.io.imread("data/chair.jpg")</code></p>

  <p>Since the function expects the first argument to be the file name,
there is no confusion about what <code class="language-plaintext highlighter-rouge">"data/chair.jpg"</code> means.</p>

  <p>The style we will use in this workshop is to name each parameters, like this:</p>

  <p><code class="language-plaintext highlighter-rouge">image = skimage.io.imsave(fname="data/chair.jpg")</code></p>

  <p>This style will make it easier for you to learn how to use the variety of
functions we will cover in this workshop.</p>
</blockquote>

<blockquote class="challenge">
  <h2 id="resizing-an-image-10-min">Resizing an image (10 min)<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#resizing-an-image-10-min" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>

  <p>Add <code class="language-plaintext highlighter-rouge">import skimage.transform</code> to your list of imports.
Using chair.jpg image located in the data folder,
write a Python script to read your image into a variable named <code class="language-plaintext highlighter-rouge">image</code>.
Then, resize the image to 10 percent of its current size using these lines of code:</p>

  <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">new_shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">image</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">//</span> <span class="mi">10</span><span class="p">,</span> <span class="n">image</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">//</span> <span class="mi">10</span><span class="p">,</span> <span class="n">image</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
<span class="n">small</span> <span class="o">=</span> <span class="n">skimage</span><span class="p">.</span><span class="n">transform</span><span class="p">.</span><span class="n">resize</span><span class="p">(</span><span class="n">image</span><span class="o">=</span><span class="n">image</span><span class="p">,</span> <span class="n">output_shape</span><span class="o">=</span><span class="n">new_shape</span><span class="p">)</span>
<span class="n">small</span> <span class="o">=</span> <span class="n">skimage</span><span class="p">.</span><span class="n">img_as_ubyte</span><span class="p">(</span><span class="n">small</span><span class="p">)</span>
</code></pre></div>  </div>

  <p>As it is used here,
the parameters to the <code class="language-plaintext highlighter-rouge">skimage.transform.resize()</code> function are
the image to transform, <code class="language-plaintext highlighter-rouge">image</code>,
the dimensions we want the new image to have, <code class="language-plaintext highlighter-rouge">new_shape</code>.</p>

  <p>Image files on disk are normally stored as whole numbers for space efficiency,
but transformations and other math operations often result in
conversion to floating point numbers.
Using the <code class="language-plaintext highlighter-rouge">skimage.img_as_ubyte()</code> method converts it back to whole numbers
before we save it back to disk.
If we don’t convert it before saving,
<code class="language-plaintext highlighter-rouge">skimage.io.imsave()</code> will do so regardless and generate a
warning that can safely be ignored in this instance.</p>

  <p>Next, write the resized image out to a new file named <code class="language-plaintext highlighter-rouge">resized.jpg</code>
in your data directory.
Finally, use plt.imshow() with each of your image variables to display
both images in your notebook.
Don’t forget to use <code class="language-plaintext highlighter-rouge">fig, ax = plt.subplots()</code> so you don’t overwrite
the first image with the second.
Images may appear the same size in jupyter,
but you can see the size difference by comparing the scales for each.
You can also see the differnce in file storage size on disk by
hovering your mouse cursor over the original
and the new file in the jupyter file browser, using <code class="language-plaintext highlighter-rouge">ls -l</code> in your shell,
or the OS file browser if it is configured to show file sizes.</p>

  <blockquote class="solution">
    <h2 id="solution">Solution<span class="fold-unfold glyphicon glyphicon-collapse-down"></span><a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#solution" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>

    <p style="display: none;">Here is what your Python script might look like.</p>

    <div class="language-python highlighter-rouge" style="display: none;"><div class="highlight"><pre class="highlight"><code><span class="s">"""
 * Python script to read an image, resize it, and save it
 * under a different name.
"""</span>
<span class="kn">import</span> <span class="nn">skimage.io</span>
<span class="kn">import</span> <span class="nn">skimage.transform</span>

<span class="c1"># read in image
</span><span class="n">image</span> <span class="o">=</span> <span class="n">skimage</span><span class="p">.</span><span class="n">io</span><span class="p">.</span><span class="n">imread</span><span class="p">(</span><span class="s">"data/chair.jpg"</span><span class="p">)</span>

<span class="c1"># resize the image
</span><span class="n">new_shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">image</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">//</span> <span class="mi">10</span><span class="p">,</span> <span class="n">image</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">//</span> <span class="mi">10</span><span class="p">,</span> <span class="n">image</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
<span class="n">small</span> <span class="o">=</span> <span class="n">skimage</span><span class="p">.</span><span class="n">transform</span><span class="p">.</span><span class="n">resize</span><span class="p">(</span><span class="n">image</span><span class="o">=</span><span class="n">image</span><span class="p">,</span> <span class="n">output_shape</span><span class="o">=</span><span class="n">new_shape</span><span class="p">)</span>
<span class="n">small</span> <span class="o">=</span> <span class="n">skimage</span><span class="p">.</span><span class="n">img_as_ubyte</span><span class="p">(</span><span class="n">small</span><span class="p">)</span>

<span class="c1"># write out image
</span><span class="n">skimage</span><span class="p">.</span><span class="n">io</span><span class="p">.</span><span class="n">imsave</span><span class="p">(</span><span class="n">fname</span><span class="o">=</span><span class="s">"data/resized.jpg"</span><span class="p">,</span> <span class="n">arr</span><span class="o">=</span><span class="n">small</span><span class="p">)</span>

<span class="c1"># display images
</span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">small</span><span class="p">)</span>
</code></pre></div>    </div>

    <p style="display: none;">The script resizes the <code class="language-plaintext highlighter-rouge">data/chair.jpg</code> image by a factor of 10 in both dimensions,
saves the result to the <code class="language-plaintext highlighter-rouge">data/resized.jpg</code> file,
and displays original and resized for comparision.</p>
  </blockquote>
</blockquote>

<h2 id="manipulating-pixels">Manipulating pixels<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#manipulating-pixels" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>

<p>In <a href="https://datacarpentry.org/image-processing/02-image-basics/index.html">the <em>Image Basics</em> episode</a>,
we individually manipulated the colours of pixels by changing the numbers stored
in the image’s NumPy array. Let’s apply the principles learned there
along with some new principles to a real world example.</p>

<p>Suppose we are interested in this maize root cluster image.
We want to be able to focus our program’s attention on the roots themselves,
while ignoring the black background.</p>

<p><img src="./Image Processing with Python_files/maize-root-cluster.jpg" alt="Root cluster image"></p>

<p>Since the image is stored as an array of numbers,
we can simply look through the array for pixel colour values that are
less than some threshold value.
This process is called <em>thresholding</em>,
and we will see more powerful methods to perform the thresholding task in
<a href="https://datacarpentry.org/image-processing/07-thresholding/index.html">the <em>Thresholding</em> episode</a>.
Here, though, we will look at a simple and elegant NumPy method for thresholding.
Let us develop a program that keeps only the pixel colour values in an image
that have value greater than or equal to 128.
This will keep the pixels that are brighter than half of “full brightness”,
i.e., pixels that do not belong to the black background.
We will start by reading the image and displaying it.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="s">"""
* Python script to ignore low intensity pixels in an image.
"""</span>
<span class="kn">import</span> <span class="nn">skimage.io</span>

<span class="c1"># read input image
</span><span class="n">image</span> <span class="o">=</span> <span class="n">skimage</span><span class="p">.</span><span class="n">io</span><span class="p">.</span><span class="n">imread</span><span class="p">(</span><span class="s">"data/maize-root-cluster.jpg"</span><span class="p">)</span>

<span class="c1"># display original image
</span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
</code></pre></div></div>

<p>Now we can threshold the image and display the result.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># keep only high-intensity pixels
</span><span class="n">image</span><span class="p">[</span><span class="n">image</span> <span class="o">&lt;</span> <span class="mi">128</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>

<span class="c1"># display modified image
</span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
</code></pre></div></div>

<p>The NumPy command to ignore all low-intensity pixels is <code class="language-plaintext highlighter-rouge">image[image &lt; 128] = 0</code>.
Every pixel colour value in the whole 3-dimensional array with a value less
that 128 is set to zero.
In this case,
the result is an image in which the extraneous background detail has been removed.</p>

<p><img src="./Image Processing with Python_files/maize-root-cluster-threshold.jpg" alt="Thresholded root image"></p>

<h2 id="converting-colour-images-to-grayscale">Converting colour images to grayscale<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#converting-colour-images-to-grayscale" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>

<p>It is often easier to work with grayscale images, which have a single channel,
instead of colour images, which have three channels.
Skimage offers the function <code class="language-plaintext highlighter-rouge">skimage.color.rgb2gray()</code> to achieve this.
This function adds up the three colour channels in a way that matches
human colour perception,
see <a href="https://scikit-image.org/docs/dev/api/skimage.color.html#skimage.color.rgb2gray">the skimage documentation for details</a>.
It returns a grayscale image with floating point values in the range from 0 to 1.
We can use the function <code class="language-plaintext highlighter-rouge">skimage.util.img_as_ubyte()</code> in order to convert it back to the
original data type and the data range back 0 to 255.
Note that it is often better to use image values represented by floating point values,
because using floating point numbers is numerically more stable.</p>

<blockquote class="callout">
  <h2 id="colour-and-color">Colour and <code class="language-plaintext highlighter-rouge">color</code><a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#colour-and-color" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>

  <p>The Carpentries generally prefers UK English spelling,
which is why we use “colour” in the explanatory text of this lesson.
However, <code class="language-plaintext highlighter-rouge">skimage</code> contains many modules and functions that include
the US English spelling, <code class="language-plaintext highlighter-rouge">color</code>.
The exact spelling matters here,
e.g. you will encounter an error if you try to run <code class="language-plaintext highlighter-rouge">skimage.colour.rgb2gray()</code>.
To account for this, we will use the US English spelling, <code class="language-plaintext highlighter-rouge">color</code>,
in example Python code throughout the lesson.
You will encounter a similar approach with “centre” and <code class="language-plaintext highlighter-rouge">center</code>.</p>
</blockquote>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="s">"""
* Python script to load a color image as grayscale.
"""</span>
<span class="kn">import</span> <span class="nn">skimage.io</span>
<span class="kn">import</span> <span class="nn">skimage.color</span>

<span class="c1"># read input image
</span><span class="n">image</span> <span class="o">=</span> <span class="n">skimage</span><span class="p">.</span><span class="n">io</span><span class="p">.</span><span class="n">imread</span><span class="p">(</span><span class="n">fname</span><span class="o">=</span><span class="s">"data/chair.jpg"</span><span class="p">)</span>

<span class="c1"># display original image
</span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>

<span class="c1"># convert to grayscale and display
</span><span class="n">gray_image</span> <span class="o">=</span> <span class="n">skimage</span><span class="p">.</span><span class="n">color</span><span class="p">.</span><span class="n">rgb2gray</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">gray_image</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s">"gray"</span><span class="p">)</span>
</code></pre></div></div>

<p>We can also load colour images as grayscale directly by
passing the argument <code class="language-plaintext highlighter-rouge">as_gray=True</code> to <code class="language-plaintext highlighter-rouge">skimage.io.imread()</code>.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="s">"""
* Python script to load a color image as grayscale.
"""</span>
<span class="kn">import</span> <span class="nn">skimage.io</span>
<span class="kn">import</span> <span class="nn">skimage.color</span>

<span class="c1"># read input image, based on filename parameter
</span><span class="n">image</span> <span class="o">=</span> <span class="n">skimage</span><span class="p">.</span><span class="n">io</span><span class="p">.</span><span class="n">imread</span><span class="p">(</span><span class="n">fname</span><span class="o">=</span><span class="s">"data/chair.jpg"</span><span class="p">,</span> <span class="n">as_gray</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="c1"># display grayscale image
</span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s">"gray"</span><span class="p">)</span>
</code></pre></div></div>

<blockquote class="challenge">
  <h2 id="keeping-only-low-intensity-pixels-10-min">Keeping only low intensity pixels (10 min)<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#keeping-only-low-intensity-pixels-10-min" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>

  <p>A little earlier, we showed how we could use Python and skimage to turn
on only the high intensity pixels from an image, while turning all the low
intensity pixels off.
Now, you can practice doing the opposite - keeping all
the low intensity pixels while changing the high intensity ones.</p>

  <p>The file <code class="language-plaintext highlighter-rouge">data/sudoku.png</code> is an RGB image of a sudoku puzzle:</p>

  <p><img src="./Image Processing with Python_files/sudoku.png" alt="Su-Do-Ku puzzle"></p>

  <p>Your task is to turn all of the white pixels in the image to a light gray colour,
say with the intensity of each formerly white pixel set to 64.
The results should look like this:</p>

  <p><img src="./Image Processing with Python_files/sudoku-gray.png" alt="Modified Su-Do-Ku puzzle"></p>

  <p><em>Hint: this is an instance where it is helpful to convert the image from RGB to grayscale.</em></p>

  <blockquote class="solution">
    <h2 id="solution-1">Solution<span class="fold-unfold glyphicon glyphicon-collapse-down"></span><a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#solution-1" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>

    <p style="display: none;">First, load the image file in and convert it to grayscale:</p>

    <div class="language-python highlighter-rouge" style="display: none;"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">skimage.io</span>

<span class="n">image</span> <span class="o">=</span> <span class="n">skimage</span><span class="p">.</span><span class="n">io</span><span class="p">.</span><span class="n">imread</span><span class="p">(</span><span class="n">fname</span><span class="o">=</span><span class="s">"data/sudoku.png"</span><span class="p">,</span> <span class="n">as_gray</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div>    </div>

    <p style="display: none;">Then, change all high intensity pixel values to &gt; 0.78 to 0.25:</p>

    <div class="language-python highlighter-rouge" style="display: none;"><div class="highlight"><pre class="highlight"><code><span class="n">image</span><span class="p">[</span><span class="n">image</span> <span class="o">&gt;</span> <span class="mf">0.78</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.25</span>
</code></pre></div>    </div>

    <p style="display: none;">Finally, display modified image:</p>

    <div class="language-python highlighter-rouge" style="display: none;"><div class="highlight"><pre class="highlight"><code><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s">"gray"</span><span class="p">)</span>
</code></pre></div>    </div>
  </blockquote>
</blockquote>

<h2 id="access-via-slicing">Access via slicing<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#access-via-slicing" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>

<p>As noted in the previous lesson skimage images are stored as NumPy arrays,
so we can use array slicing to select rectangular areas of an image.
Then, we can save the selection as a new image, change the pixels in the image,
and so on.
It is important to
remember that coordinates are specified in <em>(ry, cx)</em> order and that colour values
are specified in <em>(r, g, b)</em> order when doing these manipulations.</p>

<p>Consider this image of a whiteboard, and suppose that we want to create a
sub-image with just the portion that says “odd + even = odd,” along with the
red box that is drawn around the words.</p>

<p><img src="./Image Processing with Python_files/board.jpg" alt="Whiteboard image"></p>

<p>Using the same display technique we have used throughout this course,
we can determine the coordinates of the corners of the area we wish to extract
by hovering the mouse near the points of interest and noting the coordinates.
If we do that, we might settle on a rectangular
area with an upper-left coordinate of <em>(135, 60)</em>
and a lower-right coordinate of <em>(480, 150)</em>,
as shown in this version of the whiteboard picture:</p>

<p><img src="./Image Processing with Python_files/board-coordinates.jpg" alt="Whiteboard coordinates"></p>

<p>Note that the coordinates in the preceding image are specified in <em>(cx, ry)</em> order.
Now if our entire whiteboard image is stored as an skimage image named <code class="language-plaintext highlighter-rouge">image</code>,
we can create a new image of the selected region with a statement like this:</p>

<p><code class="language-plaintext highlighter-rouge">clip = image[60:151, 135:481, :]</code></p>

<p>Our array slicing specifies the range of y-coordinates or rows first, <code class="language-plaintext highlighter-rouge">60:151</code>,
and then the range of x-coordinates or columns, <code class="language-plaintext highlighter-rouge">135:481</code>.
Note we go one beyond the maximum value in each dimension,
so that the entire desired area is selected.
The third part of the slice, <code class="language-plaintext highlighter-rouge">:</code>,
indicates that we want all three colour channels in our new image.</p>

<p>A script to create the subimage would start by loading the image:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="s">"""
 * Python script demonstrating image modification and creation via
 * NumPy array slicing.
"""</span>
<span class="kn">import</span> <span class="nn">skimage.io</span>

<span class="c1"># load and display original image
</span><span class="n">image</span> <span class="o">=</span> <span class="n">skimage</span><span class="p">.</span><span class="n">io</span><span class="p">.</span><span class="n">imread</span><span class="p">(</span><span class="n">fname</span><span class="o">=</span><span class="s">"data/board.jpg"</span><span class="p">)</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
</code></pre></div></div>

<p>Then we use array slicing to
create a new image with our selected area and then display the new image.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># extract, display, and save sub-image
</span><span class="n">clip</span> <span class="o">=</span> <span class="n">image</span><span class="p">[</span><span class="mi">60</span><span class="p">:</span><span class="mi">151</span><span class="p">,</span> <span class="mi">135</span><span class="p">:</span><span class="mi">481</span><span class="p">,</span> <span class="p">:]</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">clip</span><span class="p">)</span>
<span class="n">skimage</span><span class="p">.</span><span class="n">io</span><span class="p">.</span><span class="n">imsave</span><span class="p">(</span><span class="n">fname</span><span class="o">=</span><span class="s">"data/clip.tif"</span><span class="p">,</span> <span class="n">arr</span><span class="o">=</span><span class="n">clip</span><span class="p">)</span>
</code></pre></div></div>

<p>We can also change the values in an image, as shown next.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># replace clipped area with sampled color
</span><span class="n">color</span> <span class="o">=</span> <span class="n">image</span><span class="p">[</span><span class="mi">330</span><span class="p">,</span> <span class="mi">90</span><span class="p">]</span>
<span class="n">image</span><span class="p">[</span><span class="mi">60</span><span class="p">:</span><span class="mi">151</span><span class="p">,</span> <span class="mi">135</span><span class="p">:</span><span class="mi">481</span><span class="p">]</span> <span class="o">=</span> <span class="n">color</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
</code></pre></div></div>

<p>First, we sample a single pixel’s colour at a particular location of the
image, saving it in a variable named <code class="language-plaintext highlighter-rouge">color</code>,
which creates a 1 × 1 × 3 NumPy array with the blue, green, and red colour values
for the pixel located at <em>(ry = 330, cx = 90)</em>.
Then, with the <code class="language-plaintext highlighter-rouge">img[60:151, 135:481] = color</code> command,
we modify the image in the specified area.
From a NumPy perspective,
this changes all the pixel values within that range to array saved in
the <code class="language-plaintext highlighter-rouge">color</code> variable.
In this case, the command “erases” that area of the whiteboard,
replacing the words with a beige colour,
as shown in the final image produced by the program:</p>

<p><img src="./Image Processing with Python_files/board-final.jpg" alt="&quot;Erased&quot; whiteboard"></p>

<blockquote class="challenge">
  <h2 id="practicing-with-slices-10-min---optional-not-included-in-timing">Practicing with slices (10 min - optional, not included in timing)<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#practicing-with-slices-10-min---optional-not-included-in-timing" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>

  <p>Using the techniques you just learned, write a script that
creates, displays, and saves a sub-image containing
only the plant and its roots from “data/maize-root-cluster.jpg”</p>

  <blockquote class="solution">
    <h2 id="solution-2">Solution<span class="fold-unfold glyphicon glyphicon-collapse-down"></span><a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#solution-2" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>

    <p style="display: none;">Here is the completed Python program to select only the plant and roots
in the image.</p>

    <div class="language-python highlighter-rouge" style="display: none;"><div class="highlight"><pre class="highlight"><code><span class="s">"""
 * Python script to extract a sub-image containing only the plant and
 * roots in an existing image.
"""</span>
<span class="kn">import</span> <span class="nn">skimage.io</span>

<span class="c1"># load and display original image
</span><span class="n">image</span> <span class="o">=</span> <span class="n">skimage</span><span class="p">.</span><span class="n">io</span><span class="p">.</span><span class="n">imread</span><span class="p">(</span><span class="n">fname</span><span class="o">=</span><span class="s">"data/maize-root-cluster.jpg"</span><span class="p">)</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>

<span class="c1"># extract, display, and save sub-image
# WRITE YOUR CODE TO SELECT THE SUBIMAGE NAME clip HERE:
</span><span class="n">clip</span> <span class="o">=</span> <span class="n">image</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">400</span><span class="p">,</span> <span class="mi">275</span><span class="p">:</span><span class="mi">550</span><span class="p">,</span> <span class="p">:]</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">clip</span><span class="p">)</span>


<span class="c1"># WRITE YOUR CODE TO SAVE clip HERE
</span><span class="n">skimage</span><span class="p">.</span><span class="n">io</span><span class="p">.</span><span class="n">imsave</span><span class="p">(</span><span class="n">fname</span><span class="o">=</span><span class="s">"data/clip.jpg"</span><span class="p">,</span> <span class="n">arr</span><span class="o">=</span><span class="n">clip</span><span class="p">)</span>
</code></pre></div>    </div>
  </blockquote>
</blockquote>

<blockquote class="keypoints">
  <h2 id="key-points-2">Key Points<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#key-points-2" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>
  <ul>
    
    <li><p>Images are read from disk with the <code class="language-plaintext highlighter-rouge">skimage.io.imread()</code> function.</p>
</li>
    
    <li><p>We create a window that automatically scales the displayed image with matplotlib and calling <code class="language-plaintext highlighter-rouge">show()</code> on the global figure object.</p>
</li>
    
    <li><p>colour images can be transformed to grayscale using <code class="language-plaintext highlighter-rouge">skimage.color.rgb2gray()</code> or be read as grayscale directly by passing the argument <code class="language-plaintext highlighter-rouge">as_gray=True</code> to <code class="language-plaintext highlighter-rouge">skimage.io.imread()</code>.</p>
</li>
    
    <li><p>We can resize images with the <code class="language-plaintext highlighter-rouge">skimage.transform.resize()</code> function.</p>
</li>
    
    <li><p>NumPy array commands, like <code class="language-plaintext highlighter-rouge">image[image &lt; 128] = 0</code>, and be used to manipulate the pixels of an image.</p>
</li>
    
    <li><p>Array slicing can be used to extract sub-images or modify areas of images, e.g., <code class="language-plaintext highlighter-rouge">clip = image[60:150, 135:480, :]</code>.</p>
</li>
    
    <li><p>Metadata is not retained when images are loaded as skimage images.</p>
</li>
    
  </ul>
</blockquote>

<hr>

<h1 id="drawing-and-bitwise-operations" class="maintitle">Drawing and Bitwise Operations</h1>

<blockquote class="objectives">
  <h2 id="overview-3">Overview<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#overview-3" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>

  <div class="row">
    <div class="col-md-3">
      <strong>Teaching:</strong> 45 min
      <br>
      <strong>Exercises:</strong> 45 min
    </div>
    <div class="col-md-9">
      <strong>Questions</strong>
      <ul>
	
	<li><p>How can we draw on skimage images and use bitwise operations and masks to select certain parts of an image?</p>
</li>
	
      </ul>
    </div>
  </div>

  <div class="row">
    <div class="col-md-3">
    </div>
    <div class="col-md-9">
      <strong>Objectives</strong>
      <ul>
	
	<li><p>Create a blank, black skimage image.</p>
</li>
	
	<li><p>Draw rectangles and other shapes on skimage images.</p>
</li>
	
	<li><p>Explain how a white shape on a black background can be used as a mask to select specific parts of an image.</p>
</li>
	
	<li><p>Use bitwise operations to apply a mask to an image.</p>
</li>
	
      </ul>
    </div>
  </div>

</blockquote>

<p>The next series of episodes covers a basic toolkit of skimage operators.
With these tools,
we will be able to create programs to perform simple analyses of images
based on changes in colour or shape.</p>

<h2 id="drawing-on-images">Drawing on images<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#drawing-on-images" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>

<p>Often we wish to select only a portion of an image to analyze,
and ignore the rest.
Creating a rectangular sub-image with slicing,
as we did in <a href="https://datacarpentry.org/image-processing/03-skimage-images/index.html">the <em>Image Representation in skimage</em> episode</a>
is one option for simple cases.
Another option is to create another special image,
of the same size as the original,
with white pixels indicating the region to save and black pixels everywhere else.
Such an image is called a <em>mask</em>.
In preparing a mask, we sometimes need to be able to draw a shape -
a circle or a rectangle, say -
on a black image.
skimage provides tools to do that.</p>

<p>Consider this image of maize seedlings:</p>

<p><img src="./Image Processing with Python_files/maize-seedlings.jpg" alt="Maize seedlings"></p>

<p>Now, suppose we want to analyze only the area of the image containing the roots
themselves;
we do not care to look at the kernels,
or anything else about the plants.
Further, we wish to exclude the frame of the container holding the seedlings as well.
Hovering over the image with our mouse, could tell us that
the upper-left coordinate of the sub-area we are interested in is <em>(44, 357)</em>,
while the lower-right coordinate is <em>(720, 740)</em>.
These coordinates are shown in <em>(x, y)</em> order.</p>

<p>A Python program to create a mask to select only that area of the image would
start with a now-familiar section of code to open and display the original
image:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">skimage.io</span>
<span class="kn">import</span> <span class="nn">skimage.draw</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">widget</span>

<span class="c1"># Load and display the original image
</span><span class="n">image</span> <span class="o">=</span> <span class="n">skimage</span><span class="p">.</span><span class="n">io</span><span class="p">.</span><span class="n">imread</span><span class="p">(</span><span class="n">fname</span><span class="o">=</span><span class="s">"data/maize-seedlings.tif"</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
</code></pre></div></div>

<p>As before, we first import the <code class="language-plaintext highlighter-rouge">io</code> submodule of <code class="language-plaintext highlighter-rouge">skimage</code> (<code class="language-plaintext highlighter-rouge">skimage.io</code>).
This time, we will also import the <code class="language-plaintext highlighter-rouge">draw</code> submodule.
We also import the NumPy library, and give it an alias of <code class="language-plaintext highlighter-rouge">np</code>.
NumPy is necessary when we create the initial mask image,
and the alias saves us a little typing.
Then, we load and display the initial image in the same way we have done before.</p>

<p>NumPy allows indexing of images/arrays with “boolean” arrays of the same size.
Indexing with a boolean array is also called mask indexing.
The “pixels” in such a mask array can only take two values: <code class="language-plaintext highlighter-rouge">True</code> or <code class="language-plaintext highlighter-rouge">False</code>.
When indexing an image with such a mask,
only pixel values at positions where the mask is <code class="language-plaintext highlighter-rouge">True</code> are accessed.
But first, we need to generate a mask array of the same size as the image.
Luckily, the NumPy library provides a function to create just such an array.
The next section of code shows how:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Create the basic mask
</span><span class="n">mask</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">ones</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="n">image</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">2</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="s">"bool"</span><span class="p">)</span>
</code></pre></div></div>

<p>The first argument to the <code class="language-plaintext highlighter-rouge">ones()</code> function is the shape of the original image,
so that our mask will be exactly the same size as the original.
Notice, that we have only used the first two indices of our shape.
We omitted the channel dimension.
Indexing with such a mask will change all channel values simultaneously.
The second argument, <code class="language-plaintext highlighter-rouge">dtype = "bool"</code>,
indicates that the elements in the array should be booleans -
i.e., values are either <code class="language-plaintext highlighter-rouge">True</code> or <code class="language-plaintext highlighter-rouge">False</code>.
Thus, even though we use <code class="language-plaintext highlighter-rouge">np.ones()</code> to create the mask,
its pixel values are in fact not <code class="language-plaintext highlighter-rouge">1</code> but <code class="language-plaintext highlighter-rouge">True</code>.
You could check this, e.g., by <code class="language-plaintext highlighter-rouge">print(mask[0, 0])</code>.</p>

<p>Next, we draw a filled, rectangle on the mask:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Draw filled rectangle on the mask image
</span><span class="n">rr</span><span class="p">,</span> <span class="n">cc</span> <span class="o">=</span> <span class="n">skimage</span><span class="p">.</span><span class="n">draw</span><span class="p">.</span><span class="n">rectangle</span><span class="p">(</span><span class="n">start</span><span class="o">=</span><span class="p">(</span><span class="mi">357</span><span class="p">,</span> <span class="mi">44</span><span class="p">),</span> <span class="n">end</span><span class="o">=</span><span class="p">(</span><span class="mi">740</span><span class="p">,</span> <span class="mi">720</span><span class="p">))</span>
<span class="n">mask</span><span class="p">[</span><span class="n">rr</span><span class="p">,</span> <span class="n">cc</span><span class="p">]</span> <span class="o">=</span> <span class="bp">False</span>

<span class="c1"># Display mask image
</span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">mask</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s">"gray"</span><span class="p">)</span>
</code></pre></div></div>

<p>Here is what our constructed mask looks like:
<img src="./Image Processing with Python_files/maize-seedlings-mask.png" alt="Maize image mask" class="image-with-shadow"></p>

<p>The parameters of the <code class="language-plaintext highlighter-rouge">rectangle()</code> function <code class="language-plaintext highlighter-rouge">(357, 44)</code> and <code class="language-plaintext highlighter-rouge">(740, 720)</code>,
are the coordinates of the upper-left (<code class="language-plaintext highlighter-rouge">start</code>) and lower-right (<code class="language-plaintext highlighter-rouge">end</code>) corners
of a rectangle in <em>(ry, cx)</em> order.
The function returns the rectangle as row (<code class="language-plaintext highlighter-rouge">rr</code>) and column (<code class="language-plaintext highlighter-rouge">cc</code>) coordinate arrays.</p>

<blockquote class="callout">
  <h2 id="check-the-documentation">Check the documentation!<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#check-the-documentation" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>

  <p>When using an skimage function for the first time - or the fifth time -
it is wise to check how the function is used, via
<a href="https://scikit-image.org/docs/dev/user_guide">the skimage documentation</a>
or other usage examples on programming-related sites such as
<a href="https://stackoverflow.com/">Stack Overflow</a>.
Basic information about skimage functions can be found interactively in Python,
via commands like <code class="language-plaintext highlighter-rouge">help(skimage)</code> or <code class="language-plaintext highlighter-rouge">help(skimage.draw.rectangle)</code>.
Take notes in your lab notebook.
And, it is always wise to run some test code to verify
that the functions your program uses are behaving in the manner you intend.</p>
</blockquote>

<blockquote class="callout">
  <h2 id="variable-naming-conventions">Variable naming conventions!<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#variable-naming-conventions" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>

  <p>You may have wondered why we called the return values of the rectangle function
<code class="language-plaintext highlighter-rouge">rr</code> and <code class="language-plaintext highlighter-rouge">cc</code>?!
You may have guessed that <code class="language-plaintext highlighter-rouge">r</code> is short for <code class="language-plaintext highlighter-rouge">row</code> and <code class="language-plaintext highlighter-rouge">c</code> is short for <code class="language-plaintext highlighter-rouge">column</code>.
However, the rectangle function returns mutiple rows and columns;
thus we used a convention of doubling the letter <code class="language-plaintext highlighter-rouge">r</code> to <code class="language-plaintext highlighter-rouge">rr</code> (and <code class="language-plaintext highlighter-rouge">c</code> to <code class="language-plaintext highlighter-rouge">cc</code>)
to indicate that those are multiple values.
In fact it may have even been clearer to name those variables <code class="language-plaintext highlighter-rouge">rows</code> and <code class="language-plaintext highlighter-rouge">columns</code>;
however this would have been also much longer.
Whatever you decide to do, try to stick to some already existing conventions,
such that it is easier for other people to understand your code.</p>
</blockquote>

<blockquote class="challenge">
  <h2 id="other-drawing-operations-15-min">Other drawing operations (15 min)<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#other-drawing-operations-15-min" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>

  <p>There are other functions for drawing on images,
in addition to the <code class="language-plaintext highlighter-rouge">skimage.draw.rectangle()</code> function.
We can draw circles, lines, text, and other shapes as well.
These drawing functions may be useful later on, to help annotate images
that our programs produce.
Practice some of these functions here.</p>

  <p>Circles can be drawn with the <code class="language-plaintext highlighter-rouge">skimage.draw.disk()</code> function,
which takes two parameters:
the (ry, cx) point of the centre of the circle,
and the radius of the circle.
There is an optional <code class="language-plaintext highlighter-rouge">shape</code> parameter that can be supplied to this function.
It will limit the output coordinates for cases where the circle
dimensions exceed the ones of the image.</p>

  <p>Lines can be drawn with the <code class="language-plaintext highlighter-rouge">skimage.draw.line()</code> function,
which takes four parameters:
the (ry, cx) coordinate of one end of the line,
and the (ry, cx) coordinate of the other end of the line.</p>

  <p>Other drawing functions supported by skimage can be found in
<a href="https://scikit-image.org/docs/dev/api/skimage.draw.html?highlight=draw#module-skimage.draw">the skimage reference pages</a>.</p>

  <p>First let’s make an empty, black image with a size of 800x600 pixels:</p>

  <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># create the black canvas
</span><span class="n">image</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">600</span><span class="p">,</span> <span class="mi">800</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="s">"uint8"</span><span class="p">)</span>
</code></pre></div>  </div>

  <p>Now your task is to draw some other coloured shapes and lines on the image,
perhaps something like this:</p>

  <p><img src="./Image Processing with Python_files/drawing-practice.jpg" alt="Sample shapes"></p>

  <blockquote class="solution">
    <h2 id="solution">Solution<span class="fold-unfold glyphicon glyphicon-collapse-down"></span><a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#solution" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>
    <p style="display: none;">Drawing a circle:</p>

    <div class="language-python highlighter-rouge" style="display: none;"><div class="highlight"><pre class="highlight"><code><span class="c1"># Draw a blue circle with centre (200, 300) in (ry, cx) coordinates, and radius 100
</span><span class="n">rr</span><span class="p">,</span> <span class="n">cc</span> <span class="o">=</span> <span class="n">skimage</span><span class="p">.</span><span class="n">draw</span><span class="p">.</span><span class="n">disk</span><span class="p">(</span><span class="n">center</span><span class="o">=</span><span class="p">(</span><span class="mi">200</span><span class="p">,</span> <span class="mi">300</span><span class="p">),</span> <span class="n">radius</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">image</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">2</span><span class="p">])</span>
<span class="n">image</span><span class="p">[</span><span class="n">rr</span><span class="p">,</span> <span class="n">cc</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">255</span><span class="p">)</span>
</code></pre></div>    </div>

    <p style="display: none;">Drawing a line:</p>

    <div class="language-python highlighter-rouge" style="display: none;"><div class="highlight"><pre class="highlight"><code><span class="c1"># Draw a green line from (400, 200) to (500, 700) in (ry, cx) coordinates
</span><span class="n">rr</span><span class="p">,</span> <span class="n">cc</span> <span class="o">=</span> <span class="n">skimage</span><span class="p">.</span><span class="n">draw</span><span class="p">.</span><span class="n">line</span><span class="p">(</span><span class="n">r0</span><span class="o">=</span><span class="mi">400</span><span class="p">,</span> <span class="n">c0</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">r1</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">c1</span><span class="o">=</span><span class="mi">700</span><span class="p">)</span>
<span class="n">image</span><span class="p">[</span><span class="n">rr</span><span class="p">,</span> <span class="n">cc</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
</code></pre></div>    </div>

    <div class="language-python highlighter-rouge" style="display: none;"><div class="highlight"><pre class="highlight"><code><span class="c1"># Display the image
</span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
</code></pre></div>    </div>

    <p style="display: none;">We could expand this solution, if we wanted,
to draw rectangles, circles and lines at random positions within our black canvas.
To do this, we could use the <code class="language-plaintext highlighter-rouge">random</code> python module,
and the function <code class="language-plaintext highlighter-rouge">random.randrange</code>,
which can produce random numbers within a certain range.</p>

    <p style="display: none;">Let’s draw 15 randomly placed circles:</p>

    <div class="language-python highlighter-rouge" style="display: none;"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">random</span>

<span class="c1"># create the black canvas
</span><span class="n">image</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">600</span><span class="p">,</span> <span class="mi">800</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="s">"uint8"</span><span class="p">)</span>

<span class="c1"># draw a blue circle at a random location 15 times
</span><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">15</span><span class="p">):</span>
    <span class="n">rr</span><span class="p">,</span> <span class="n">cc</span> <span class="o">=</span> <span class="n">skimage</span><span class="p">.</span><span class="n">draw</span><span class="p">.</span><span class="n">disk</span><span class="p">(</span><span class="n">center</span><span class="o">=</span><span class="p">(</span>
         <span class="n">random</span><span class="p">.</span><span class="n">randrange</span><span class="p">(</span><span class="mi">600</span><span class="p">),</span>
         <span class="n">random</span><span class="p">.</span><span class="n">randrange</span><span class="p">(</span><span class="mi">800</span><span class="p">)),</span>
         <span class="n">radius</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
         <span class="n">shape</span><span class="o">=</span><span class="n">image</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">2</span><span class="p">],</span>
        <span class="p">)</span>
    <span class="n">image</span><span class="p">[</span><span class="n">rr</span><span class="p">,</span> <span class="n">cc</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">255</span><span class="p">)</span>

<span class="c1"># display the results
</span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
</code></pre></div>    </div>

    <p style="display: none;">We could expand this even further to also
randomly choose whether to plot a rectangle, a circle, or a square.
Again, we do this with the <code class="language-plaintext highlighter-rouge">random</code> module,
now using the function <code class="language-plaintext highlighter-rouge">random.random</code>
that returns a random number between 0.0 and 1.0.</p>

    <div class="language-python highlighter-rouge" style="display: none;"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">random</span>

<span class="c1"># Draw 15 random shapes (rectangle, circle or line) at random positions
</span><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">15</span><span class="p">):</span>
    <span class="c1"># generate a random number between 0.0 and 1.0 and use this to decide if we
</span>    <span class="c1"># want a circle, a line or a sphere
</span>    <span class="n">x</span> <span class="o">=</span> <span class="n">random</span><span class="p">.</span><span class="n">random</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">x</span> <span class="o">&lt;</span> <span class="mf">0.33</span><span class="p">:</span>
        <span class="c1"># draw a blue circle at a random location
</span>        <span class="n">rr</span><span class="p">,</span> <span class="n">cc</span> <span class="o">=</span> <span class="n">skimage</span><span class="p">.</span><span class="n">draw</span><span class="p">.</span><span class="n">disk</span><span class="p">(</span><span class="n">center</span><span class="o">=</span><span class="p">(</span>
            <span class="n">random</span><span class="p">.</span><span class="n">randrange</span><span class="p">(</span><span class="mi">600</span><span class="p">),</span>
            <span class="n">random</span><span class="p">.</span><span class="n">randrange</span><span class="p">(</span><span class="mi">800</span><span class="p">)),</span>
            <span class="n">radius</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
            <span class="n">shape</span><span class="o">=</span><span class="n">image</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">2</span><span class="p">],</span>
        <span class="p">)</span>
        <span class="n">color</span> <span class="o">=</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">255</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">x</span> <span class="o">&lt;</span> <span class="mf">0.66</span><span class="p">:</span>
        <span class="c1"># draw a green line at a random location
</span>        <span class="n">rr</span><span class="p">,</span> <span class="n">cc</span> <span class="o">=</span> <span class="n">skimage</span><span class="p">.</span><span class="n">draw</span><span class="p">.</span><span class="n">line</span><span class="p">(</span>
            <span class="n">r0</span><span class="o">=</span><span class="n">random</span><span class="p">.</span><span class="n">randrange</span><span class="p">(</span><span class="mi">600</span><span class="p">),</span>
            <span class="n">c0</span><span class="o">=</span><span class="n">random</span><span class="p">.</span><span class="n">randrange</span><span class="p">(</span><span class="mi">800</span><span class="p">),</span>
            <span class="n">r1</span><span class="o">=</span><span class="n">random</span><span class="p">.</span><span class="n">randrange</span><span class="p">(</span><span class="mi">600</span><span class="p">),</span>
            <span class="n">c1</span><span class="o">=</span><span class="n">random</span><span class="p">.</span><span class="n">randrange</span><span class="p">(</span><span class="mi">800</span><span class="p">),</span>
        <span class="p">)</span>
        <span class="n">color</span> <span class="o">=</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># draw a red rectangle at a random location
</span>        <span class="n">rr</span><span class="p">,</span> <span class="n">cc</span> <span class="o">=</span> <span class="n">skimage</span><span class="p">.</span><span class="n">draw</span><span class="p">.</span><span class="n">rectangle</span><span class="p">(</span>
            <span class="n">start</span><span class="o">=</span><span class="p">(</span><span class="n">random</span><span class="p">.</span><span class="n">randrange</span><span class="p">(</span><span class="mi">600</span><span class="p">),</span> <span class="n">random</span><span class="p">.</span><span class="n">randrange</span><span class="p">(</span><span class="mi">800</span><span class="p">)),</span>
            <span class="n">extent</span><span class="o">=</span><span class="p">(</span><span class="mi">50</span><span class="p">,</span> <span class="mi">50</span><span class="p">),</span>
            <span class="n">shape</span><span class="o">=</span><span class="n">image</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">2</span><span class="p">],</span>
        <span class="p">)</span>
        <span class="n">color</span> <span class="o">=</span> <span class="p">(</span><span class="mi">255</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>

    <span class="n">image</span><span class="p">[</span><span class="n">rr</span><span class="p">,</span> <span class="n">cc</span><span class="p">]</span> <span class="o">=</span> <span class="n">color</span>

<span class="c1"># display the results
</span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
</code></pre></div>    </div>
  </blockquote>
</blockquote>

<h2 id="image-modification">Image modification<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#image-modification" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>

<p>All that remains is the task of modifying the image using our mask in such a
way that the areas with <code class="language-plaintext highlighter-rouge">True</code> pixels in the mask are not shown in the image
any more.</p>

<blockquote class="challenge">
  <h2 id="how-does-a-mask-work-optional-not-included-in-timing">How does a mask work? (optional, not included in timing)<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#how-does-a-mask-work-optional-not-included-in-timing" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>

  <p>Now, consider the mask image we created above.
The values of the mask that corresponds to the portion of the image
we are interested in are all <code class="language-plaintext highlighter-rouge">False</code>,
while the values of the mask that corresponds to the portion of the image we
want to remove are all <code class="language-plaintext highlighter-rouge">True</code>.</p>

  <p>How do we change the original image using the mask?</p>

  <blockquote class="solution">
    <h2 id="solution-1">Solution<span class="fold-unfold glyphicon glyphicon-collapse-down"></span><a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#solution-1" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>

    <p style="display: none;">When indexing the image using the mask, we access only those pixels at
positions where the mask is <code class="language-plaintext highlighter-rouge">True</code>.
So, when indexing with the mask,
one can set those values to 0, and effectively remove them from the image.</p>
  </blockquote>
</blockquote>

<p>Now we can write a Python program to use a mask to retain only the portions
of our maize roots image that actually contains the seedling roots.
We load the original image and create the mask in the same way as before:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Load the original image
</span><span class="n">image</span> <span class="o">=</span> <span class="n">skimage</span><span class="p">.</span><span class="n">io</span><span class="p">.</span><span class="n">imread</span><span class="p">(</span><span class="s">"data/maize-seedlings.tif"</span><span class="p">)</span>

<span class="c1"># Create the basic mask
</span><span class="n">mask</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">ones</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="n">image</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">2</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="s">"bool"</span><span class="p">)</span>

<span class="c1"># Draw a filled rectangle on the mask image
</span><span class="n">rr</span><span class="p">,</span> <span class="n">cc</span> <span class="o">=</span> <span class="n">skimage</span><span class="p">.</span><span class="n">draw</span><span class="p">.</span><span class="n">rectangle</span><span class="p">(</span><span class="n">start</span><span class="o">=</span><span class="p">(</span><span class="mi">357</span><span class="p">,</span> <span class="mi">44</span><span class="p">),</span> <span class="n">end</span><span class="o">=</span><span class="p">(</span><span class="mi">740</span><span class="p">,</span> <span class="mi">720</span><span class="p">))</span>
<span class="n">mask</span><span class="p">[</span><span class="n">rr</span><span class="p">,</span> <span class="n">cc</span><span class="p">]</span> <span class="o">=</span> <span class="bp">False</span>
</code></pre></div></div>

<p>Then, we use numpy indexing to remove the portions of the image,
where the mask is <code class="language-plaintext highlighter-rouge">True</code>:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Apply the mask
</span><span class="n">image</span><span class="p">[</span><span class="n">mask</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
</code></pre></div></div>

<p>Then, we display the masked image.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
</code></pre></div></div>

<p>The resulting masked image should look like this:</p>

<p><img src="./Image Processing with Python_files/maize-seedlings-masked.jpg" alt="Applied mask"></p>

<blockquote class="challenge">
  <h2 id="masking-an-image-of-your-own-optional-not-included-in-timing">Masking an image of your own (optional, not included in timing)<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#masking-an-image-of-your-own-optional-not-included-in-timing" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>

  <p>Now, it is your turn to practice.
Using your mobile phone, tablet, webcam, or digital camera,
take an image of an object with a simple overall geometric shape
(think rectangular or circular).
Copy that image to your computer, write some code to make a mask,
and apply it to select the part of the image containing your object.
For example, here is an image of a remote control:</p>

  <p><img src="./Image Processing with Python_files/remote-control.jpg" alt="Remote control image"></p>

  <p>And, here is the end result of a program masking out everything but the remote:</p>

  <p><img src="./Image Processing with Python_files/remote-control-masked.jpg" alt="Remote control masked"></p>

  <blockquote class="solution">
    <h2 id="solution-2">Solution<span class="fold-unfold glyphicon glyphicon-collapse-down"></span><a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#solution-2" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>

    <p style="display: none;">Here is a Python program to produce the cropped remote control image shown above.
Of course, your program should be tailored to your image.</p>

    <div class="language-python highlighter-rouge" style="display: none;"><div class="highlight"><pre class="highlight"><code><span class="c1"># Load the image
</span><span class="n">image</span> <span class="o">=</span> <span class="n">skimage</span><span class="p">.</span><span class="n">io</span><span class="p">.</span><span class="n">imread</span><span class="p">(</span><span class="n">fname</span><span class="o">=</span><span class="s">"data/remote-control.jpg"</span><span class="p">)</span>

<span class="c1"># Create the basic mask
</span><span class="n">mask</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">ones</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="n">image</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">2</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="s">"bool"</span><span class="p">)</span>

<span class="c1"># Draw a filled rectangle on the mask image
</span><span class="n">rr</span><span class="p">,</span> <span class="n">cc</span> <span class="o">=</span> <span class="n">skimage</span><span class="p">.</span><span class="n">draw</span><span class="p">.</span><span class="n">rectangle</span><span class="p">(</span><span class="n">start</span><span class="o">=</span><span class="p">(</span><span class="mi">93</span><span class="p">,</span> <span class="mi">1107</span><span class="p">),</span> <span class="n">end</span><span class="o">=</span><span class="p">(</span><span class="mi">1821</span><span class="p">,</span> <span class="mi">1668</span><span class="p">))</span>
<span class="n">mask</span><span class="p">[</span><span class="n">rr</span><span class="p">,</span> <span class="n">cc</span><span class="p">]</span> <span class="o">=</span> <span class="bp">False</span>

<span class="c1"># Apply the mask
</span><span class="n">image</span><span class="p">[</span><span class="n">mask</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>

<span class="c1"># Display the result
</span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
</code></pre></div>    </div>
  </blockquote>
</blockquote>

<blockquote class="challenge">
  <h2 id="masking-a-96-well-plate-image-30-min">Masking a 96-well plate image (30 min)<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#masking-a-96-well-plate-image-30-min" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>

  <p>Consider this image of a 96-well plate that has been scanned on a flatbed scanner.</p>

  <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Load the image
</span><span class="n">image</span> <span class="o">=</span> <span class="n">skimage</span><span class="p">.</span><span class="n">io</span><span class="p">.</span><span class="n">imread</span><span class="p">(</span><span class="n">fname</span><span class="o">=</span><span class="s">"data/wellplate-01.jpg"</span><span class="p">)</span>

<span class="c1"># Display the image
</span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
</code></pre></div>  </div>

  <p><img src="./Image Processing with Python_files/wellplate-01.jpg" alt="96-well plate"></p>

  <p>Suppose that we are interested in the colours of the solutions in each of the wells.
We <em>do not</em> care about the colour of the rest of the image,
i.e., the plastic that makes up the well plate itself.</p>

  <p>Your task is to write some code that will produce a mask that will
mask out everything except for the wells.
To help with this, you should use the text file <code class="language-plaintext highlighter-rouge">data/centers.txt</code> that contains
the (cx, ry) coordinates of the centre of each of the 96 wells in this image.
You may assume that each of the wells has a radius of 16 pixels.</p>

  <p>Your program should produce output that looks like this:</p>

  <p><img src="./Image Processing with Python_files/wellplate-01-masked.jpg" alt="Masked 96-well plate"></p>

  <blockquote class="solution">
    <h2 id="solution-3">Solution<span class="fold-unfold glyphicon glyphicon-collapse-down"></span><a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#solution-3" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>

    <div class="language-python highlighter-rouge" style="display: none;"><div class="highlight"><pre class="highlight"><code><span class="c1"># read in original image
</span><span class="n">image</span> <span class="o">=</span> <span class="n">skimage</span><span class="p">.</span><span class="n">io</span><span class="p">.</span><span class="n">imread</span><span class="p">(</span><span class="n">fname</span><span class="o">=</span><span class="s">"data/wellplate-01.jpg"</span><span class="p">)</span>

<span class="c1"># create the mask image
</span><span class="n">mask</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">ones</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="n">image</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">2</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="s">"bool"</span><span class="p">)</span>

<span class="c1"># open and iterate through the centers file...
</span><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s">"data/centers.txt"</span><span class="p">,</span> <span class="s">"r"</span><span class="p">)</span> <span class="k">as</span> <span class="n">center_file</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">center_file</span><span class="p">:</span>
        <span class="c1"># ... getting the coordinates of each well...
</span>        <span class="n">coordinates</span> <span class="o">=</span> <span class="n">line</span><span class="p">.</span><span class="n">split</span><span class="p">()</span>
        <span class="n">cx</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">coordinates</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="n">ry</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">coordinates</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>

        <span class="c1"># ... and drawing a circle on the mask
</span>        <span class="n">rr</span><span class="p">,</span> <span class="n">cc</span> <span class="o">=</span> <span class="n">skimage</span><span class="p">.</span><span class="n">draw</span><span class="p">.</span><span class="n">disk</span><span class="p">(</span><span class="n">center</span><span class="o">=</span><span class="p">(</span><span class="n">ry</span><span class="p">,</span> <span class="n">cx</span><span class="p">),</span> <span class="n">radius</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">image</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">2</span><span class="p">])</span>
        <span class="n">mask</span><span class="p">[</span><span class="n">rr</span><span class="p">,</span> <span class="n">cc</span><span class="p">]</span> <span class="o">=</span> <span class="bp">False</span>

<span class="c1"># apply the mask
</span><span class="n">image</span><span class="p">[</span><span class="n">mask</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>

<span class="c1"># display the result
</span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
</code></pre></div>    </div>

  </blockquote>
</blockquote>

<blockquote class="challenge">
  <h2 id="masking-a-96-well-plate-image-take-two-optional-not-included-in-timing">Masking a 96-well plate image, take two (optional, not included in timing)<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#masking-a-96-well-plate-image-take-two-optional-not-included-in-timing" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>

  <p>If you spent some time looking at the contents of
the <code class="language-plaintext highlighter-rouge">data/centers.txt</code> file from the previous challenge,
you may have noticed that the centres of each well in the image are very regular.
<em>Assuming</em> that the images are scanned in such a way that
the wells are always in the same place,
and that the image is perfectly oriented
(i.e., it does not slant one way or another),
we could produce our well plate mask without having to
read in the coordinates of the centres of each well.
Assume that the centre of the upper left well in the image is at
location cx = 91 and ry = 108, and that there are
70 pixels between each centre in the cx dimension and
72 pixels between each centre in the ry dimension.
Each well still has a radius of 16 pixels.
Write a Python program that produces the same output image as in the previous challenge,
but <em>without</em> having to read in the <code class="language-plaintext highlighter-rouge">centers.txt</code> file.
<em>Hint: use nested for loops.</em></p>

  <blockquote class="solution">
    <h2 id="solution-4">Solution<span class="fold-unfold glyphicon glyphicon-collapse-down"></span><a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#solution-4" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>

    <p style="display: none;">Here is a Python program that is able to create the masked image without
having to read in the <code class="language-plaintext highlighter-rouge">centers.txt</code> file.</p>

    <div class="language-python highlighter-rouge" style="display: none;"><div class="highlight"><pre class="highlight"><code><span class="c1"># read in original image
</span><span class="n">image</span> <span class="o">=</span> <span class="n">skimage</span><span class="p">.</span><span class="n">io</span><span class="p">.</span><span class="n">imread</span><span class="p">(</span><span class="n">fname</span><span class="o">=</span><span class="s">"data/wellplate-01.jpg"</span><span class="p">)</span>

<span class="c1"># create the mask image
</span><span class="n">mask</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">ones</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="n">image</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">2</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="s">"bool"</span><span class="p">)</span>

<span class="c1"># upper left well coordinates
</span><span class="n">cx0</span> <span class="o">=</span> <span class="mi">91</span>
<span class="n">ry0</span> <span class="o">=</span> <span class="mi">108</span>

<span class="c1"># spaces between wells
</span><span class="n">deltaCX</span> <span class="o">=</span> <span class="mi">70</span>
<span class="n">deltaRY</span> <span class="o">=</span> <span class="mi">72</span>

<span class="n">cx</span> <span class="o">=</span> <span class="n">cx0</span>
<span class="n">ry</span> <span class="o">=</span> <span class="n">ry0</span>

<span class="c1"># iterate each row and column
</span><span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">12</span><span class="p">):</span>
    <span class="c1"># reset cx to leftmost well in the row
</span>    <span class="n">cx</span> <span class="o">=</span> <span class="n">cx0</span>
    <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">8</span><span class="p">):</span>

        <span class="c1"># ... and drawing a circle on the mask
</span>        <span class="n">rr</span><span class="p">,</span> <span class="n">cc</span> <span class="o">=</span> <span class="n">skimage</span><span class="p">.</span><span class="n">draw</span><span class="p">.</span><span class="n">disk</span><span class="p">(</span><span class="n">center</span><span class="o">=</span><span class="p">(</span><span class="n">ry</span><span class="p">,</span> <span class="n">cx</span><span class="p">),</span> <span class="n">radius</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">image</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">2</span><span class="p">])</span>
        <span class="n">mask</span><span class="p">[</span><span class="n">rr</span><span class="p">,</span> <span class="n">cc</span><span class="p">]</span> <span class="o">=</span> <span class="bp">False</span>
        <span class="n">cx</span> <span class="o">+=</span> <span class="n">deltaCX</span>
    <span class="c1"># after one complete row, move to next row
</span>    <span class="n">ry</span> <span class="o">+=</span> <span class="n">deltaRY</span>

<span class="c1"># apply the mask
</span><span class="n">image</span><span class="p">[</span><span class="n">mask</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>

<span class="c1"># display the result
</span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
</code></pre></div>    </div>
  </blockquote>
</blockquote>

<blockquote class="keypoints">
  <h2 id="key-points-3">Key Points<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#key-points-3" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>
  <ul>
    
    <li><p>We can use the NumPy <code class="language-plaintext highlighter-rouge">zeros()</code> function to create a blank, black image.</p>
</li>
    
    <li><p>We can draw on skimage images with functions such as <code class="language-plaintext highlighter-rouge">skimage.draw.rectangle()</code>, <code class="language-plaintext highlighter-rouge">skimage.draw.disk()</code>, <code class="language-plaintext highlighter-rouge">skimage.draw.line()</code>, and more.</p>
</li>
    
    <li><p>The drawing functions return indices to pixels that can be set directly.</p>
</li>
    
  </ul>
</blockquote>

<hr>

<h1 id="creating-histograms" class="maintitle">Creating Histograms</h1>

<blockquote class="objectives">
  <h2 id="overview-4">Overview<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#overview-4" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>

  <div class="row">
    <div class="col-md-3">
      <strong>Teaching:</strong> 40 min
      <br>
      <strong>Exercises:</strong> 40 min
    </div>
    <div class="col-md-9">
      <strong>Questions</strong>
      <ul>
	
	<li><p>How can we create grayscale and colour histograms to understand the distribution of colour values in an image?</p>
</li>
	
      </ul>
    </div>
  </div>

  <div class="row">
    <div class="col-md-3">
    </div>
    <div class="col-md-9">
      <strong>Objectives</strong>
      <ul>
	
	<li><p>Explain what a histogram is.</p>
</li>
	
	<li><p>Load an image in grayscale format.</p>
</li>
	
	<li><p>Create and display grayscale and colour histograms for entire images.</p>
</li>
	
	<li><p>Create and display grayscale and colour histograms for certain areas of images, via masks.</p>
</li>
	
      </ul>
    </div>
  </div>

</blockquote>

<p>In this episode, we will learn how to use skimage functions to create and
display histograms for images.</p>

<h2 id="introduction-to-histograms">Introduction to Histograms<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#introduction-to-histograms" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>

<p>As it pertains to images, a <em>histogram</em> is a graphical representation showing
how frequently various colour values occur in the image.
We saw in
<a href="https://datacarpentry.org/image-processing/02-image-basics/index.html">the <em>Image Basics</em> episode</a>
that we could use a histogram to visualise
the differences in uncompressed and compressed image formats.
If your project involves detecting colour changes between images,
histograms will prove to be very useful,
and histograms are also quite handy as a preparatory step before performing
<a href="https://datacarpentry.org/image-processing/07-thresholding">thresholding</a>.</p>

<h2 id="grayscale-histograms">Grayscale Histograms<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#grayscale-histograms" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>

<p>We will start with grayscale images and histograms first,
and then move on to colour images.
We will use this image of a plant seedling as an example:
<img src="./Image Processing with Python_files/plant-seedling.jpg" alt="Plant seedling"></p>

<p>Here we load the image in grayscale instead of full colour, and display it:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">skimage.color</span>
<span class="kn">import</span> <span class="nn">skimage.io</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">widget</span>

<span class="c1"># read the image of a plant seedling as grayscale from the outset
</span><span class="n">image</span> <span class="o">=</span> <span class="n">skimage</span><span class="p">.</span><span class="n">io</span><span class="p">.</span><span class="n">imread</span><span class="p">(</span><span class="n">fname</span><span class="o">=</span><span class="s">"data/plant-seedling.jpg"</span><span class="p">,</span> <span class="n">as_gray</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="c1"># display the image
</span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s">"gray"</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="./Image Processing with Python_files/plant-seedling-grayscale.png" alt="Plant seedling"></p>

<p>In the program, we have a new import from <code class="language-plaintext highlighter-rouge">matplotlib</code>,
to gain access to the tools we will use to draw the histogram.
The statement</p>

<p><code class="language-plaintext highlighter-rouge">from matplotlib import pyplot as plt</code></p>

<p>loads up the <code class="language-plaintext highlighter-rouge">pyplot</code> library, and gives it a shorter name, <code class="language-plaintext highlighter-rouge">plt</code>.</p>

<p>Next, we use the <code class="language-plaintext highlighter-rouge">skimage.io.imread()</code> function to load our image.
The first parameter to <code class="language-plaintext highlighter-rouge">skimage.io.imread()</code> is the filename of the image.
The second parameter <code class="language-plaintext highlighter-rouge">as_gray</code> instructs the function to transform the image
into grayscale with a value range from 0 to 1 while loading the image.
We will keep working with images in the value range 0 to 1 in this lesson.
Remember that we can transform an image back to the range 0 to 255 with
the function <code class="language-plaintext highlighter-rouge">skimage.util.img_as_ubyte</code>.</p>

<p>Skimage does not provide a special function to compute histograms,
but we can use the function <code class="language-plaintext highlighter-rouge">np.histogram</code> instead:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># create the histogram
</span><span class="n">histogram</span><span class="p">,</span> <span class="n">bin_edges</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">histogram</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="nb">range</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
</code></pre></div></div>

<p>The parameter <code class="language-plaintext highlighter-rouge">bins</code> determines the number of “bins” to use for the histogram.
We pass in <code class="language-plaintext highlighter-rouge">256</code> because we want to see the pixel count for each of
the 256 possible values in the grayscale image.</p>

<p>The parameter <code class="language-plaintext highlighter-rouge">range</code> is the range of values each of the pixels in the image can have.
Here, we pass 0 and 1,
which is the value range of our input image after transforming it to grayscale.</p>

<p>The first output of the <code class="language-plaintext highlighter-rouge">np.histogram</code> function is a one-dimensional NumPy array,
with 256 rows and one column,
representing the number of pixels with the intensity value corresponding to the index.
I.e., the first number in the array is
the number of pixels found with intensity value 0,
and the final number in the array is
the number of pixels found with intensity value 255.
The second output of <code class="language-plaintext highlighter-rouge">np.histogram</code> is
an array with the bin edges and one column and 257 rows
(one more than the histogram itself).
There are no gaps between the bins, which means that the end of the first bin,
is the start of the second and so on.
For the last bin, the array also has to contain the stop,
so it has one more element, than the histogram.</p>

<p>Next, we turn our attention to displaying the histogram,
by taking advantage of the plotting facilities of the <code class="language-plaintext highlighter-rouge">matplotlib</code> library.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># configure and draw the histogram figure
</span><span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">"Grayscale Histogram"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">"grayscale value"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">"pixel count"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlim</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">])</span>  <span class="c1"># &lt;- named arguments do not work here
</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">bin_edges</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">histogram</span><span class="p">)</span>  <span class="c1"># &lt;- or here
</span></code></pre></div></div>

<p>We create the plot with <code class="language-plaintext highlighter-rouge">plt.figure()</code>,
then label the figure and the coordinate axes with <code class="language-plaintext highlighter-rouge">plt.title()</code>,
<code class="language-plaintext highlighter-rouge">plt.xlabel()</code>, and <code class="language-plaintext highlighter-rouge">plt.ylabel()</code> functions.
The last step in the preparation of the figure is to
set the limits on the values on the x-axis with
the <code class="language-plaintext highlighter-rouge">plt.xlim([0.0, 1.0])</code> function call.</p>

<blockquote class="callout">
  <h2 id="variable-length-argument-lists">Variable-length argument lists<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#variable-length-argument-lists" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>

  <p>Note that we cannot used named parameters for the
<code class="language-plaintext highlighter-rouge">plt.xlim()</code> or <code class="language-plaintext highlighter-rouge">plt.plot()</code> functions.
This is because these functions are defined to take an arbitrary number of
<em>unnamed</em> arguments.
The designers wrote the functions this way because they are very versatile,
and creating named parameters for all of the possible ways to use them
would be complicated.</p>
</blockquote>

<p>Finally, we create the histogram plot itself with
<code class="language-plaintext highlighter-rouge">plt.plot(bin_edges[0:-1], histogram)</code>.
We use the <strong>left</strong> bin edges as x-positions for the histogram values by
indexing the <code class="language-plaintext highlighter-rouge">bin_edges</code> array to ignore the last value
(the <strong>right</strong> edge of the last bin).
When we run the program on this image of a plant seedling,
it produces this histogram:</p>

<p><img src="./Image Processing with Python_files/plant-seedling-grayscale-histogram.png" alt="Plant seedling histogram"></p>

<blockquote class="callout">
  <h2 id="histograms-in-matplotlib">Histograms in matplotlib<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#histograms-in-matplotlib" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>

  <p>Matplotlib provides a dedicated function to compute and display histograms:
<code class="language-plaintext highlighter-rouge">plt.hist()</code>.
We will not use it in this lesson in order to understand how to
calculate histograms in more detail.
In practice, it is a good idea to use this function,
because it visualises histograms more appropriately than <code class="language-plaintext highlighter-rouge">plt.plot()</code>.
Here, you could use it by calling
<code class="language-plaintext highlighter-rouge">plt.hist(image.flatten(), bins=256, range=(0, 1))</code>
instead of
<code class="language-plaintext highlighter-rouge">np.histogram()</code> and <code class="language-plaintext highlighter-rouge">plt.plot()</code>
(<code class="language-plaintext highlighter-rouge">*.flatten()</code> is a numpy function that converts our two-dimensional
image into a one-dimensional array).</p>

</blockquote>

<blockquote class="challenge">
  <h2 id="using-a-mask-for-a-histogram-15-min">Using a mask for a histogram (15 min)<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#using-a-mask-for-a-histogram-15-min" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>

  <p>Looking at the histogram above,
you will notice that there is a large number of very dark pixels,
as indicated in the chart by the spike around the grayscale value 0.12.
That is not so surprising, since the original image is mostly black background.
What if we want to focus more closely on the leaf of the seedling?
That is where a mask enters the picture!</p>

  <p>First, hover over the plant seedling image with your mouse to determine the
<em>(x, y)</em> coordinates of a bounding box around the leaf of the seedling.
Then, using techniques from
<a href="https://datacarpentry.org/image-processing/04-drawing/index.html">the <em>Drawing and Bitwise Operations</em> episode</a>,
create a mask with a white rectangle covering that bounding box.</p>

  <p>After you have created the mask, apply it to the input image before passing
it to the <code class="language-plaintext highlighter-rouge">np.histogram</code> function.</p>

  <blockquote class="solution">
    <h2 id="solution">Solution<span class="fold-unfold glyphicon glyphicon-collapse-down"></span><a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#solution" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>
    <div class="language-python highlighter-rouge" style="display: none;"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">skimage.draw</span>

<span class="c1"># read the image as grayscale from the outset
</span><span class="n">image</span> <span class="o">=</span> <span class="n">skimage</span><span class="p">.</span><span class="n">io</span><span class="p">.</span><span class="n">imread</span><span class="p">(</span><span class="n">fname</span><span class="o">=</span><span class="s">"data/plant-seedling.jpg"</span><span class="p">,</span> <span class="n">as_gray</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="c1"># display the image
</span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s">"gray"</span><span class="p">)</span>

<span class="c1"># create mask here, using np.zeros() and skimage.draw.rectangle()
</span><span class="n">mask</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="n">image</span><span class="p">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s">"bool"</span><span class="p">)</span>
<span class="n">rr</span><span class="p">,</span> <span class="n">cc</span> <span class="o">=</span> <span class="n">skimage</span><span class="p">.</span><span class="n">draw</span><span class="p">.</span><span class="n">rectangle</span><span class="p">(</span><span class="n">start</span><span class="o">=</span><span class="p">(</span><span class="mi">199</span><span class="p">,</span> <span class="mi">410</span><span class="p">),</span> <span class="n">end</span><span class="o">=</span><span class="p">(</span><span class="mi">384</span><span class="p">,</span> <span class="mi">485</span><span class="p">))</span>
<span class="n">mask</span><span class="p">[</span><span class="n">rr</span><span class="p">,</span> <span class="n">cc</span><span class="p">]</span> <span class="o">=</span> <span class="bp">True</span>

<span class="c1"># display the mask
</span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">mask</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s">"gray"</span><span class="p">)</span>

<span class="c1"># mask the image and create the new histogram
</span><span class="n">histogram</span><span class="p">,</span> <span class="n">bin_edges</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">histogram</span><span class="p">(</span><span class="n">image</span><span class="p">[</span><span class="n">mask</span><span class="p">],</span> <span class="n">bins</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="nb">range</span><span class="o">=</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">))</span>

<span class="c1"># configure and draw the histogram figure
</span><span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">()</span>

<span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">"Grayscale Histogram"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">"grayscale value"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">"pixel count"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlim</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">])</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">bin_edges</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">histogram</span><span class="p">)</span>

</code></pre></div>    </div>

    <p style="display: none;">Your histogram of the masked area should look something like this:</p>

    <p style="display: none;"><img src="./Image Processing with Python_files/plant-seedling-grayscale-histogram-mask.png" alt="Grayscale histogram of masked area"></p>
  </blockquote>

</blockquote>

<h2 id="colour-histograms">Colour Histograms<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#colour-histograms" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>

<p>We can also create histograms for full colour images,
in addition to grayscale histograms.
We have seen colour histograms before,
in <a href="https://datacarpentry.org/image-processing/02-image-basics/index.html">the <em>Image Basics</em> episode</a>.
A program to create colour histograms starts in a familiar way:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># read original image, in full color
</span><span class="n">image</span> <span class="o">=</span> <span class="n">skimage</span><span class="p">.</span><span class="n">io</span><span class="p">.</span><span class="n">imread</span><span class="p">(</span><span class="n">fname</span><span class="o">=</span><span class="s">"data/plant-seedling.jpg"</span><span class="p">)</span>

<span class="c1"># display the image
</span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
</code></pre></div></div>

<p>We read the original image, now in full colour, and display it.</p>

<p>Next, we create the histogram, by calling the <code class="language-plaintext highlighter-rouge">np.histogram</code> function three
times, once for each of the channels.
We obtain the individual channels, by slicing the image along the last axis.
For example, we can obtain the red colour channel by calling
<code class="language-plaintext highlighter-rouge">r_chan = image[:, :, 0]</code>.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># tuple to select colors of each channel line
</span><span class="n">colors</span> <span class="o">=</span> <span class="p">(</span><span class="s">"red"</span><span class="p">,</span> <span class="s">"green"</span><span class="p">,</span> <span class="s">"blue"</span><span class="p">)</span>
<span class="n">channel_ids</span> <span class="o">=</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

<span class="c1"># create the histogram plot, with three lines, one for
# each color
</span><span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">256</span><span class="p">])</span>
<span class="k">for</span> <span class="n">channel_id</span><span class="p">,</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">channel_ids</span><span class="p">,</span> <span class="n">colors</span><span class="p">):</span>
    <span class="n">histogram</span><span class="p">,</span> <span class="n">bin_edges</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">histogram</span><span class="p">(</span>
        <span class="n">image</span><span class="p">[:,</span> <span class="p">:,</span> <span class="n">channel_id</span><span class="p">],</span> <span class="n">bins</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="nb">range</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">256</span><span class="p">)</span>
    <span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">bin_edges</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">histogram</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">c</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">"Color Histogram"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">"Color value"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">"Pixel count"</span><span class="p">)</span>
</code></pre></div></div>

<p>We will draw the histogram line for each channel in a different colour,
and so we create a tuple of the colours to use for the three lines with the</p>

<p><code class="language-plaintext highlighter-rouge">colors = ("red", "green", "blue")</code></p>

<p>line of code.
Then, we limit the range of the x-axis with the <code class="language-plaintext highlighter-rouge">plt.xlim()</code> function call.</p>

<p>Next, we use the <code class="language-plaintext highlighter-rouge">for</code> control structure to iterate through the three channels,
plotting an appropriately-coloured histogram line for each.
This may be new Python syntax for you,
so we will take a moment to discuss what is happening in the <code class="language-plaintext highlighter-rouge">for</code> statement.</p>

<p>The Python built-in <code class="language-plaintext highlighter-rouge">zip()</code> function takes a series of
one or more lists and returns an <em>iterator</em> of <em>tuples</em>,
where the first tuple contains the first element of each of the lists,
the second contains the second element of each of the lists, and so on.</p>

<blockquote class="callout">
  <h2 id="iterators-tuples-and-zip">Iterators, tuples, and <code class="language-plaintext highlighter-rouge">zip()</code><a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#iterators-tuples-and-zip" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>

  <p>In Python, an <em>iterator</em>, or an <em>iterable object</em>, is
something that can be iterated over with the <code class="language-plaintext highlighter-rouge">for</code> control structure.
A <em>tuple</em> is a sequence of objects, just like a list.
However, a tuple cannot be changed,
and a tuple is indicated by parentheses instead of square brackets.
The <code class="language-plaintext highlighter-rouge">zip()</code> function takes one or more iterable objects,
and returns an iterator of tuples consisting of
the corresponding ordinal objects from each parameter.</p>

  <p>For example, consider this small Python program:</p>

  <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">list1</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="n">list2</span> <span class="o">=</span> <span class="p">(</span><span class="s">"a"</span><span class="p">,</span> <span class="s">"b"</span><span class="p">,</span> <span class="s">"c"</span><span class="p">,</span> <span class="s">"d"</span><span class="p">,</span> <span class="s">"e"</span><span class="p">)</span>

<span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">list1</span><span class="p">,</span> <span class="n">list2</span><span class="p">):</span>
    <span class="k">print</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</code></pre></div>  </div>

  <p>Executing this program would produce the following output:</p>

  <div class="language-plaintext output highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(1, 'a')
(2, 'b')
(3, 'c')
(4, 'd')
(5, 'e')
</code></pre></div>  </div>
</blockquote>

<p>In our colour histogram program, we are using a tuple, <code class="language-plaintext highlighter-rouge">(channel_id, c)</code>,
as the <code class="language-plaintext highlighter-rouge">for</code> variable.
The first time through the loop, the <code class="language-plaintext highlighter-rouge">channel_id</code> variable takes the value <code class="language-plaintext highlighter-rouge">0</code>,
referring to the position of the red colour channel,
and the <code class="language-plaintext highlighter-rouge">c</code> variable contains the string <code class="language-plaintext highlighter-rouge">"red"</code>.
The second time through the loop the values are the green channels position and
<code class="language-plaintext highlighter-rouge">"green"</code>, and the third time they are the blue channel position and <code class="language-plaintext highlighter-rouge">"blue"</code>.</p>

<p>Inside the <code class="language-plaintext highlighter-rouge">for</code> loop, our code looks much like it did for the grayscale
example.
We calculate the histogram for the current channel with the</p>

<p><code class="language-plaintext highlighter-rouge">histogram, bin_edges = np.histogram(image[:, :, channel_id], bins=256, range=(0, 256))</code></p>

<p>function call,
and then add a histogram line of the correct colour to the plot with the</p>

<p><code class="language-plaintext highlighter-rouge">plt.plot(bin_edges[0:-1], histogram, color=c)</code></p>

<p>function call.
Note the use of our loop variables, <code class="language-plaintext highlighter-rouge">channel_id</code> and <code class="language-plaintext highlighter-rouge">c</code>.</p>

<p>Finally we label our axes and display the histogram, shown here:</p>

<p><img src="./Image Processing with Python_files/plant-seedling-colour-histogram.png" alt="Colour histogram"></p>

<blockquote class="challenge">
  <h2 id="colour-histogram-with-a-mask-25-min">Colour histogram with a mask (25 min)<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#colour-histogram-with-a-mask-25-min" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>

  <p>We can also apply a mask to the images we apply the colour histogram process to,
in the same way we did for grayscale histograms.
Consider this image of a well plate,
where various chemical sensors have been applied to water and
various concentrations of hydrochloric acid and sodium hydroxide:</p>

  <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># read the image
</span><span class="n">image</span> <span class="o">=</span> <span class="n">skimage</span><span class="p">.</span><span class="n">io</span><span class="p">.</span><span class="n">imread</span><span class="p">(</span><span class="n">fname</span><span class="o">=</span><span class="s">"data/wellplate-02.tif"</span><span class="p">)</span>

<span class="c1"># display the image
</span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
</code></pre></div>  </div>
  <p><img src="./Image Processing with Python_files/wellplate-02.jpg" alt="Well plate image"></p>

  <p>Suppose we are interested in the colour histogram of one of the sensors in the
well plate image,
specifically, the seventh well from the left in the topmost row,
which shows Erythrosin B reacting with water.</p>

  <p>Hover over the image with your mouse to find the centre of that well
and the radius (in pixels) of the well.
Then create a circular mask to select only the desired well.
Then, use that mask to apply the colour histogram operation to that well.</p>

  <p>Your masked image should look like this:</p>

  <p><img src="./Image Processing with Python_files/wellplate-02-masked.jpg" alt="Masked well plate"></p>

  <p>And, the program should produce a colour histogram that looks like this:</p>

  <p><img src="./Image Processing with Python_files/wellplate-02-histogram.png" alt="Well plate histogram"></p>

  <blockquote class="solution">
    <h2 id="solution-1">Solution<span class="fold-unfold glyphicon glyphicon-collapse-down"></span><a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#solution-1" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>

    <div class="language-python highlighter-rouge" style="display: none;"><div class="highlight"><pre class="highlight"><code><span class="c1"># create a circular mask to select the 7th well in the first row
</span><span class="n">mask</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="n">image</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">2</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="s">"bool"</span><span class="p">)</span>
<span class="n">circle</span> <span class="o">=</span> <span class="n">skimage</span><span class="p">.</span><span class="n">draw</span><span class="p">.</span><span class="n">disk</span><span class="p">(</span><span class="n">center</span><span class="o">=</span><span class="p">(</span><span class="mi">240</span><span class="p">,</span> <span class="mi">1053</span><span class="p">),</span> <span class="n">radius</span><span class="o">=</span><span class="mi">49</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">image</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">2</span><span class="p">])</span>
<span class="n">mask</span><span class="p">[</span><span class="n">circle</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>

<span class="c1"># just for display:
# make a copy of the image, call it masked_image, and
# use np.logical_not() and indexing to apply the mask to it
</span><span class="n">masked_img</span> <span class="o">=</span> <span class="n">image</span><span class="p">[:]</span>
<span class="n">masked_img</span><span class="p">[</span><span class="n">np</span><span class="p">.</span><span class="n">logical_not</span><span class="p">(</span><span class="n">mask</span><span class="p">)]</span> <span class="o">=</span> <span class="mi">0</span>

<span class="c1"># create a new figure and display masked_img, to verify the
# validity of your mask
</span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">masked_img</span><span class="p">)</span>

<span class="c1"># list to select colors of each channel line
</span><span class="n">colors</span> <span class="o">=</span> <span class="p">(</span><span class="s">"red"</span><span class="p">,</span> <span class="s">"green"</span><span class="p">,</span> <span class="s">"blue"</span><span class="p">)</span>
<span class="n">channel_ids</span> <span class="o">=</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

<span class="c1"># create the histogram plot, with three lines, one for
# each color
</span><span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">256</span><span class="p">])</span>
<span class="k">for</span> <span class="p">(</span><span class="n">channel_id</span><span class="p">,</span> <span class="n">c</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">channel_ids</span><span class="p">,</span> <span class="n">colors</span><span class="p">):</span>
    <span class="c1"># use your circular mask to apply the histogram
</span>    <span class="c1"># operation to the 7th well of the first row
</span>    <span class="n">histogram</span><span class="p">,</span> <span class="n">bin_edges</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">histogram</span><span class="p">(</span>
        <span class="n">image</span><span class="p">[:,</span> <span class="p">:,</span> <span class="n">channel_id</span><span class="p">][</span><span class="n">mask</span><span class="p">],</span> <span class="n">bins</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="nb">range</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">256</span><span class="p">)</span>
    <span class="p">)</span>

    <span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">histogram</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">c</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">"color value"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">"pixel count"</span><span class="p">)</span>

</code></pre></div>    </div>
  </blockquote>
</blockquote>

<blockquote class="keypoints">
  <h2 id="key-points-4">Key Points<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#key-points-4" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>
  <ul>
    
    <li><p>We can load images in grayscale by passing the <code class="language-plaintext highlighter-rouge">as_gray=True</code> parameter to the <code class="language-plaintext highlighter-rouge">skimage.io.imread()</code> function.</p>
</li>
    
    <li><p>We can create histograms of images with the <code class="language-plaintext highlighter-rouge">np.histogram</code> function.</p>
</li>
    
    <li><p>We can separate the RGB channels of an image using slicing operations.</p>
</li>
    
    <li><p>We can display histograms using the <code class="language-plaintext highlighter-rouge">matplotlib pyplot</code> <code class="language-plaintext highlighter-rouge">figure()</code>, <code class="language-plaintext highlighter-rouge">title()</code>, <code class="language-plaintext highlighter-rouge">xlabel()</code>, <code class="language-plaintext highlighter-rouge">ylabel()</code>, <code class="language-plaintext highlighter-rouge">xlim()</code>, <code class="language-plaintext highlighter-rouge">plot()</code>, and <code class="language-plaintext highlighter-rouge">show()</code> functions.</p>
</li>
    
  </ul>
</blockquote>

<hr>

<h1 id="blurring-images" class="maintitle">Blurring Images</h1>

<blockquote class="objectives">
  <h2 id="overview-5">Overview<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#overview-5" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>

  <div class="row">
    <div class="col-md-3">
      <strong>Teaching:</strong> 35 min
      <br>
      <strong>Exercises:</strong> 25 min
    </div>
    <div class="col-md-9">
      <strong>Questions</strong>
      <ul>
	
	<li><p>How can we apply a low-pass blurring filter to an image?</p>
</li>
	
      </ul>
    </div>
  </div>

  <div class="row">
    <div class="col-md-3">
    </div>
    <div class="col-md-9">
      <strong>Objectives</strong>
      <ul>
	
	<li><p>Explain why applying a low-pass blurring filter to an image is beneficial.</p>
</li>
	
	<li><p>Apply a Gaussian blur filter to an image using skimage.</p>
</li>
	
      </ul>
    </div>
  </div>

</blockquote>

<p>In this episode, we will learn how to use skimage functions to blur images.</p>

<p>When processing an image, we are often interested in identifying objects
represented within it so that we can perform some further analysis of these
objects e.g. by counting them, measuring their sizes, etc.
An important concept associated with the identification of objects in an image
is that of <em>edges</em>: the lines that represent a transition from one group of
similar pixels in the image to another different group.
One example of an edge is the pixels that represent
the boundaries of an object in an image,
where the background of the image ends and the object begins.</p>

<p>When we blur an image,
we make the colour transition from one side of an edge in the image to another
smooth rather than sudden.
The effect is to average out rapid changes in pixel intensity.
A blur is a very common operation we need to perform before other tasks such as
<a href="https://datacarpentry.org/image-processing/07-thresholding/index.html">thresholding</a>.
There are several different blurring functions in the <code class="language-plaintext highlighter-rouge">skimage.filters</code> module,
so we will focus on just one here, the <em>Gaussian blur</em>.</p>

<blockquote class="callout">
  <h2 id="filters">Filters<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#filters" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>

  <p>In the day-to-day, macroscopic world,
we have physical filters which separate out objects by size.
A filter with small holes allows only small objects through,
leaving larger objects behind.
This is a good analogy for image filters.
A high-pass filter will retain the smaller details in an image,
filtering out the larger ones.
A low-pass filter retains the larger features,
analogous to what’s left behind by a physical filter mesh.
<em>High-</em> and <em>low-</em>pass, here,
refer to high and low <em>spatial frequencies</em> in the image.
Details associated with high spatial frequencies are small,
a lot of these features would fit across an image.
Features associated with low spatial frequencies are large -
maybe a couple of big features per image.</p>

</blockquote>

<blockquote class="callout">
  <h2 id="blurring">Blurring<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#blurring" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>

  <p>Blurring is to make something less clear or distinct.
This could be interpreted quite broadly in the context of image analysis -
anything that reduces or distorts the detail of an image might apply.
Applying a low pass filter, which removes detail occurring at high spatial frequencies,
is perceived as a blurring effect.
A Gaussian blur is a filter that makes use of a Gaussian kernel.</p>

</blockquote>

<blockquote class="callout">
  <h2 id="kernels">Kernels<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#kernels" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>

  <p>A kernel can be used to implement a filter on an image.
A kernel, in this context,
is a small matrix which is combined with the image using
a mathematical technique: <em>convolution</em>.
Different sizes, shapes and contents of kernel produce different effects.
The kernel can be thought of as a little image in itself,
and will favour features of a similar size and shape in the main image.
On convolution with an image, a big, blobby kernel will retain
big, blobby, low spatial frequency features.</p>

</blockquote>

<h2 id="gaussian-blur">Gaussian blur<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#gaussian-blur" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>

<p>Consider this image of a cat,
in particular the area of the image outlined by the white square.</p>

<p><img src="./Image Processing with Python_files/cat.jpg" alt="Cat image"></p>

<p>Now, zoom in on the area of the cat’s eye, as shown in the left-hand image below.
When we apply a filter, we consider each pixel in the image, one at a time.
In this example, the pixel we are currently working on is highlighted in red,
as shown in the right-hand image.</p>

<p><img src="./Image Processing with Python_files/cat-eye-pixels.jpg" alt="Cat eye pixels"></p>

<p>When we apply a filter, we consider rectangular groups of pixels surrounding
each pixel in the image, in turn.
The <em>kernel</em> is another group of pixels (a separate matrix / small image),
of the same dimensions as the rectangular group of pixels in the image,
that moves along with the pixel being worked on by the filter.
The width and height of the kernel must be an odd number,
so that the pixel being worked on is always in its centre.
In the example shown above, the kernel is square, with a dimension of seven pixels.</p>

<p>To apply the kernel to the current pixel,
an average of the the colour values of the pixels surrounding it is calculated,
weighted by the values in the kernel.
In a Gaussian blur, the pixels nearest the centre of the kernel are
given more weight than those far away from the centre.
This averaging is done on a channel-by-channel basis,
and the average channel values become the new value for the pixel in
the filtered image.
Larger kernels have more values factored into the average, and this implies
that a larger kernel will blur the image more than a smaller kernel.</p>

<p>To get an idea of how this works,
consider this plot of the two-dimensional Gaussian function:</p>

<p><img src="./Image Processing with Python_files/gaussian-kernel.png" alt="2D Gaussian function"></p>

<p>Imagine that plot laid over the kernel for the Gaussian blur filter.
The height of the plot corresponds to the weight given to the underlying pixel
in the kernel.
I.e., the pixels close to the centre become more important to
the filtered pixel colour than the pixels close to the outer limits of the kernel.
The shape of the Gaussian function is controlled via its standard deviation,
or sigma.
A large sigma value results in a flatter shape,
while a smaller sigma value results in a more pronounced peak.
The mathematics involved in the Gaussian blur filter are not quite that simple,
but this explanation gives you the basic idea.</p>

<p>To illustrate the blur process,
consider the blue channel colour values from the seven-by-seven region
of the cat image above:</p>

<p><img src="./Image Processing with Python_files/cat-corner-blue.png" alt="Image corner pixels"></p>

<p>The filter is going to determine the new blue channel value for the centre
pixel – the one that currently has the value 86. The filter calculates a
weighted average of all the blue channel values in the kernel
giving higher weight to the pixels near the centre of the
kernel.</p>

<p><img src="./Image Processing with Python_files/combination.png" alt="Image multiplication"></p>

<p>This weighted average, the sum of the multiplications,
becomes the new value for the centre pixel (3, 3).
The same process would be used to determine the green and red channel values,
and then the kernel would be moved over to apply the filter to the
next pixel in the image.</p>

<blockquote class="callout">
  <h2 id="image-edges">Image edges<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#image-edges" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>

  <p>Something different needs to happen for pixels near the outer limits of the image,
since the kernel for the filter may be partially off the image.
For example, what happens when the filter is applied to
the upper-left pixel of the image?
Here are the blue channel pixel values for the upper-left pixel of the cat image,
again assuming a seven-by-seven kernel:</p>

  <div class="language-plaintext output highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  x   x   x   x   x   x   x
  x   x   x   x   x   x   x
  x   x   x   x   x   x   x
  x   x   x   4   5   9   2
  x   x   x   5   3   6   7
  x   x   x   6   5   7   8
  x   x   x   5   4   5   3
</code></pre></div>  </div>

  <p>The upper-left pixel is the one with value 4.
Since the pixel is at the upper-left corner,
there are no pixels underneath much of the kernel;
here, this is represented by x’s.
So, what does the filter do in that situation?</p>

  <p>The default mode is to fill in the <em>nearest</em> pixel value from the image.
For each of the missing x’s the image value closest to the x is used.
If we fill in a few of the missing pixels, you will see how this works:</p>

  <div class="language-plaintext output highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  x   x   x   4   x   x   x
  x   x   x   4   x   x   x
  x   x   x   4   x   x   x
  4   4   4   4   5   9   2
  x   x   x   5   3   6   7
  x   x   x   6   5   7   8
  x   x   x   5   4   5   3
</code></pre></div>  </div>

  <p>Another strategy to fill those missing values is
to <em>reflect</em> the pixels that are in the image to fill in for the pixels that
are missing from the kernel.</p>

  <div class="language-plaintext output highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  x   x   x   5   x   x   x
  x   x   x   6   x   x   x
  x   x   x   5   x   x   x
  2   9   5   4   5   9   2
  x   x   x   5   3   6   7
  x   x   x   6   5   7   8
  x   x   x   5   4   5   3
</code></pre></div>  </div>

  <p>A similar process would be used to fill in all of the other missing pixels from
the kernel. Other <em>border modes</em> are available; you can learn more about them
in <a href="https://scikit-image.org/docs/dev/user_guide">the skimage documentation</a>.</p>

</blockquote>

<p>This animation shows how the blur kernel moves along in the original image in
order to calculate the colour channel values for the blurred image.</p>

<p><img src="./Image Processing with Python_files/blur-demo.gif" alt="Blur demo animation"></p>

<p>skimage has built-in functions to perform blurring for us, so we do not have to
perform all of these mathematical operations ourselves. Let’s work through
an example of blurring an image with the skimage Gaussian blur function.</p>

<p>First, we load the image, and display it:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">skimage.io</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="nn">skimage.filters</span>
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">widget</span>

<span class="n">image</span> <span class="o">=</span> <span class="n">skimage</span><span class="p">.</span><span class="n">io</span><span class="p">.</span><span class="n">imread</span><span class="p">(</span><span class="n">fname</span><span class="o">=</span><span class="s">"data/gaussian-original.png"</span><span class="p">)</span>

<span class="c1"># display the image
</span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
</code></pre></div></div>
<p><img src="./Image Processing with Python_files/gaussian-original.png" alt="Original image"></p>

<p>Next, we apply the gaussian blur:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sigma</span> <span class="o">=</span> <span class="mf">3.0</span>

<span class="c1"># apply Gaussian blur, creating a new image
</span><span class="n">blurred</span> <span class="o">=</span> <span class="n">skimage</span><span class="p">.</span><span class="n">filters</span><span class="p">.</span><span class="n">gaussian</span><span class="p">(</span>
    <span class="n">image</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="p">(</span><span class="n">sigma</span><span class="p">,</span> <span class="n">sigma</span><span class="p">),</span> <span class="n">truncate</span><span class="o">=</span><span class="mf">3.5</span><span class="p">,</span> <span class="n">channel_axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</code></pre></div></div>

<p>The first two parameters to <code class="language-plaintext highlighter-rouge">skimage.filters.gaussian()</code> are the image to blur,
<code class="language-plaintext highlighter-rouge">image</code>, and a tuple defining the sigma to use in ry- and cx-direction,
<code class="language-plaintext highlighter-rouge">(sigma, sigma)</code>.
The third parameter <code class="language-plaintext highlighter-rouge">truncate</code> gives the radius of the kernel in terms of sigmas.
A Gaussian function is defined from -infinity to +infinity, but our kernel
(which must have a finite, smaller size) can only approximate the real function.
Therefore, we must choose a certain distance from the centre of the function
where we stop this approximation, and set the final size of our kernel.
In the above example, we set <code class="language-plaintext highlighter-rouge">truncate</code> to 3.5,
which means the kernel size will be 2 * sigma * 3.5.
For example, for a <code class="language-plaintext highlighter-rouge">sigma</code> of 1.0 the resulting kernel size would be 7,
while for a <code class="language-plaintext highlighter-rouge">sigma</code> of 2.0 the kernel size would be 14.
The default value for <code class="language-plaintext highlighter-rouge">truncate</code> in scikit-image is 4.0.</p>

<p>The last parameter to <code class="language-plaintext highlighter-rouge">skimage.filters.gaussian()</code> tells skimage
to interpret our image, that has three dimensions, as a multichannel colour image.</p>

<p>Finally, we display the blurred image:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># display blurred image
</span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">blurred</span><span class="p">)</span>
</code></pre></div></div>
<p><img src="./Image Processing with Python_files/gaussian-blurred.png" alt="Original image"></p>

<blockquote class="challenge">
  <h2 id="experimenting-with-sigma-values-10-min">Experimenting with sigma values (10 min)<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#experimenting-with-sigma-values-10-min" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>

  <p>The size and shape of the kernel used to blur an image can have a
significant effect on the result of the blurring and any downstream analysis
carried out on the blurred image.
The next two exercises ask you to experiment with the sigma values of the kernel,
which is a good way to develop your understanding of how the choice of kernel
can influence the result of blurring.</p>

  <p>First, try running the code above with a range of smaller and larger sigma values.
Generally speaking, what effect does the sigma value have on the
blurred image?</p>

  <blockquote class="solution">
    <h2 id="solution">Solution<span class="fold-unfold glyphicon glyphicon-collapse-down"></span><a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#solution" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>

    <p style="display: none;">Generally speaking, the larger the sigma value, the more blurry the result.
A larger sigma will tend to get rid of more noise in the image, which will
help for other operations we will cover soon, such as thresholding.
However, a larger sigma also tends to eliminate some of the detail from
the image. So, we must strike a balance with the sigma value used for
blur filters.</p>
  </blockquote>
</blockquote>

<blockquote class="challenge">
  <h2 id="experimenting-with-kernel-shape-10-min---optional-not-included-in-timing">Experimenting with kernel shape (10 min - optional, not included in timing)<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#experimenting-with-kernel-shape-10-min---optional-not-included-in-timing" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>

  <p>Now, what is the effect of applying an asymmetric kernel to blurring an image?
Try running the code above with different sigmas in the ry and cx direction.
For example, a sigma of 1.0 in the ry direction, and 6.0 in the cx direction.</p>

  <blockquote class="solution">
    <h2 id="solution-1">Solution<span class="fold-unfold glyphicon glyphicon-collapse-down"></span><a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#solution-1" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>

    <div class="language-python highlighter-rouge" style="display: none;"><div class="highlight"><pre class="highlight"><code><span class="c1"># apply Gaussian blur, with a sigma of 1.0 in the ry direction, and 6.0 in the cx direction
</span><span class="n">blurred</span> <span class="o">=</span> <span class="n">skimage</span><span class="p">.</span><span class="n">filters</span><span class="p">.</span><span class="n">gaussian</span><span class="p">(</span>
    <span class="n">image</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">6.0</span><span class="p">),</span> <span class="n">truncate</span><span class="o">=</span><span class="mf">3.5</span><span class="p">,</span> <span class="n">multichannel</span><span class="o">=</span><span class="bp">True</span>
<span class="p">)</span>

<span class="c1"># display blurred image
</span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">blurred</span><span class="p">)</span>
</code></pre></div>    </div>

    <p style="display: none;"><img src="./Image Processing with Python_files/rectangle-gaussian-blurred.png" alt="Rectangular kernel blurred image"></p>

    <p style="display: none;">These unequal sigma values produce a kernel that is rectangular instead of square.
The result is an image that is much more blurred in the x direction than the
y direction.
For most use cases, a uniform blurring effect is desirable and
this kind of asymmetric blurring should be avoided.
However, it can be helpful in specific circumstances e.g. when noise is present in
your image in a particular pattern or orientation, such as vertical lines,
or when you want to 
<a href="https://www.researchgate.net/publication/228567435_An_edge_detection_algorithm_based_on_rectangular_Gaussian_kernels_for_machine_vision_applications">remove uniform noise without blurring edges present in the image in a particular orientation</a>.</p>

  </blockquote>
</blockquote>

<h2 id="other-methods-of-blurring">Other methods of blurring<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#other-methods-of-blurring" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>

<p>The Gaussian blur is a way to apply a low-pass filter in skimage.
It is often used to remove Gaussian (i. e., random) noise from the image.
For other kinds of noise, e.g. “salt and pepper” or “static” noise, a
median filter is typically used.
See <a href="https://scikit-image.org/docs/dev/api/skimage.filters.html#module-skimage.filters">the <code class="language-plaintext highlighter-rouge">skimage.filters</code> documentation</a>
for a list of available filters.</p>

<blockquote class="keypoints">
  <h2 id="key-points-5">Key Points<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#key-points-5" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>
  <ul>
    
    <li><p>Applying a low-pass blurring filter smooths edges and removes noise from an image.</p>
</li>
    
    <li><p>Blurring is often used as a first step before we perform thresholding or edge detection.</p>
</li>
    
    <li><p>The Gaussian blur can be applied to an image with the <code class="language-plaintext highlighter-rouge">skimage.filters.gaussian()</code> function.</p>
</li>
    
    <li><p>Larger sigma values may remove more noise, but they will also remove detail from an image.</p>
</li>
    
  </ul>
</blockquote>

<hr>

<h1 id="thresholding" class="maintitle">Thresholding</h1>

<blockquote class="objectives">
  <h2 id="overview-6">Overview<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#overview-6" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>

  <div class="row">
    <div class="col-md-3">
      <strong>Teaching:</strong> 60 min
      <br>
      <strong>Exercises:</strong> 50 min
    </div>
    <div class="col-md-9">
      <strong>Questions</strong>
      <ul>
	
	<li><p>How can we use thresholding to produce a binary image?</p>
</li>
	
      </ul>
    </div>
  </div>

  <div class="row">
    <div class="col-md-3">
    </div>
    <div class="col-md-9">
      <strong>Objectives</strong>
      <ul>
	
	<li><p>Explain what thresholding is and how it can be used.</p>
</li>
	
	<li><p>Use histograms to determine appropriate threshold values to use for the thresholding process.</p>
</li>
	
	<li><p>Apply simple, fixed-level binary thresholding to an image.</p>
</li>
	
	<li><p>Explain the difference between using the operator <code class="language-plaintext highlighter-rouge">&gt;</code> or the operator <code class="language-plaintext highlighter-rouge">&lt;</code> to threshold an image represented by a numpy array.</p>
</li>
	
	<li><p>Describe the shape of a binary image produced by thresholding via <code class="language-plaintext highlighter-rouge">&gt;</code> or <code class="language-plaintext highlighter-rouge">&lt;</code>.</p>
</li>
	
	<li><p>Explain when Otsu’s method for automatic thresholding is appropriate.</p>
</li>
	
	<li><p>Apply automatic thresholding to an image using Otsu’s method.</p>
</li>
	
	<li><p>Use the <code class="language-plaintext highlighter-rouge">np.count_nonzero()</code> function to count the number of non-zero pixels in an image.</p>
</li>
	
      </ul>
    </div>
  </div>

</blockquote>

<p>In this episode, we will learn how to use skimage functions to apply
thresholding to an image.
Thresholding is a type of <em>image segmentation</em>,
where we change the pixels of an image to make the image easier to analyze.
In thresholding, we convert an image from colour or grayscale into
a <em>binary image</em>, i.e., one that is simply black and white.
Most frequently,
we use thresholding as a way to select areas of interest of an image,
while ignoring the parts we are not concerned with.
We have already done some simple thresholding,
in the “Manipulating pixels” section of
<a href="https://datacarpentry.org/image-processing/03-skimage-images/index.html">the <em>Image Representation in skimage</em> episode</a>.
In that case, we used a simple NumPy array manipulation to
separate the pixels belonging to the root system of a plant from the black background.
In this episode, we will learn how to use skimage functions to perform thresholding.
Then, we will use the masks returned by these functions to
select the parts of an image we are interested in.</p>

<h2 id="simple-thresholding">Simple thresholding<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#simple-thresholding" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>

<p>Consider the image <code class="language-plaintext highlighter-rouge">data/shapes-01.jpg</code> with a series of
crudely cut shapes set against a white background.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">glob</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="nn">skimage.io</span>
<span class="kn">import</span> <span class="nn">skimage.color</span>
<span class="kn">import</span> <span class="nn">skimage.filters</span>
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">widget</span>

<span class="c1"># load the image
</span><span class="n">image</span> <span class="o">=</span> <span class="n">skimage</span><span class="p">.</span><span class="n">io</span><span class="p">.</span><span class="n">imread</span><span class="p">(</span><span class="s">"data/shapes-01.jpg"</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
</code></pre></div></div>

<p class="image-with-shadow"><img src="./Image Processing with Python_files/shapes-01.jpg" alt="Image with geometric shapes on white background"></p>

<p>Now suppose we want to select only the shapes from the image.
In other words, we want to leave the pixels belonging to the shapes “on,”
while turning the rest of the pixels “off,”
by setting their colour channel values to zeros.
The skimage library has several different methods of thresholding.
We will start with the simplest version,
which involves an important step of human input.
Specifically, in this simple, <em>fixed-level thresholding</em>,
we have to provide a threshold value <code class="language-plaintext highlighter-rouge">t</code>.</p>

<p>The process works like this.
First, we will load the original image, convert it to grayscale,
and de-noise it as in <a href="https://datacarpentry.org/image-processing/06-blurring/index.html">the <em>Blurring Images</em> episode</a>.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># convert the image to grayscale
</span><span class="n">gray_image</span> <span class="o">=</span> <span class="n">skimage</span><span class="p">.</span><span class="n">color</span><span class="p">.</span><span class="n">rgb2gray</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>

<span class="c1"># blur the image to denoise
</span><span class="n">blurred_image</span> <span class="o">=</span> <span class="n">skimage</span><span class="p">.</span><span class="n">filters</span><span class="p">.</span><span class="n">gaussian</span><span class="p">(</span><span class="n">gray_image</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">blurred_image</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s">"gray"</span><span class="p">)</span>
</code></pre></div></div>

<p class="image-with-shadow"><img src="./Image Processing with Python_files/shapes-01-grayscale.png" alt="Grayscale image of the geometric shapes"></p>

<p>Next, we would like to apply the threshold <code class="language-plaintext highlighter-rouge">t</code> such that
pixels with grayscale values on one side of <code class="language-plaintext highlighter-rouge">t</code> will be turned “on”,
while pixels with grayscale values on the other side will be turned “off”.
How might we do that?
Remember that grayscale images contain pixel values in the range from 0 to 1,
so we are looking for a threshold <code class="language-plaintext highlighter-rouge">t</code> in the closed range [0.0, 1.0].
We see in the image that the geometric shapes are “darker” than
the white background but there is also some light gray noise on the background.
One way to determine a “good” value for <code class="language-plaintext highlighter-rouge">t</code> is
to look at the grayscale histogram of the image
and try to identify what grayscale ranges correspond to the shapes in the image
or the background.</p>

<p>The histogram for the shapes image shown above can be produced as in
<a href="https://datacarpentry.org/image-processing/05-creating-histograms/index.html">the <em>Creating Histograms</em> episode</a>.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># create a histogram of the blurred grayscale image
</span><span class="n">histogram</span><span class="p">,</span> <span class="n">bin_edges</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">histogram</span><span class="p">(</span><span class="n">blurred_image</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="nb">range</span><span class="o">=</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">))</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">bin_edges</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">histogram</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">"Grayscale Histogram"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">"grayscale value"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">"pixels"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="./Image Processing with Python_files/shapes-01-histogram.png" alt="Grayscale histogram of the geometric shapes image"></p>

<p>Since the image has a white background,
most of the pixels in the image are white.
This corresponds nicely to what we see in the histogram:
there is a peak near the value of 1.0.
If we want to select the shapes and not the background,
we want to turn off the white background pixels,
while leaving the pixels for the shapes turned on.
So, we should choose a value of <code class="language-plaintext highlighter-rouge">t</code> somewhere before the large peak and
turn pixels above that value “off”.
Let us choose <code class="language-plaintext highlighter-rouge">t=0.8</code>.</p>

<p>To apply the threshold <code class="language-plaintext highlighter-rouge">t</code>,
we can use the numpy comparison operators to create a mask.
Here, we want to turn “on” all pixels which have values smaller than the threshold,
so we use the less operator <code class="language-plaintext highlighter-rouge">&lt;</code> to compare the <code class="language-plaintext highlighter-rouge">blurred_image</code> to the threshold <code class="language-plaintext highlighter-rouge">t</code>.
The operator returns a mask, that we capture in the variable <code class="language-plaintext highlighter-rouge">binary_mask</code>.
It has only one channel, and each of its values is either 0 or 1.
The binary mask created by the thresholding operation can be shown with <code class="language-plaintext highlighter-rouge">plt.imshow</code>,
where the <code class="language-plaintext highlighter-rouge">False</code> entries are shown as black pixels
(0-valued) and the <code class="language-plaintext highlighter-rouge">True</code> entries are shown as white pixels
(1-valued).</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># create a mask based on the threshold
</span><span class="n">t</span> <span class="o">=</span> <span class="mf">0.8</span>
<span class="n">binary_mask</span> <span class="o">=</span> <span class="n">blurred_image</span> <span class="o">&lt;</span> <span class="n">t</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">binary_mask</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s">"gray"</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="./Image Processing with Python_files/shapes-01-mask.png" alt="Binary mask of the geometric shapes created by thresholding"></p>

<p>You can see that the areas where the shapes were in the original area are now white,
while the rest of the mask image is black.</p>

<blockquote class="callout">
  <h2 id="what-makes-a-good-threshold">What makes a good threshold?<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#what-makes-a-good-threshold" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>

  <p>As is often the case, the answer to this question is “it depends”.
In the example above, we could have just switched off all
the white background pixels by choosing <code class="language-plaintext highlighter-rouge">t=1.0</code>,
but this would leave us with some background noise in the mask image.
On the other hand, if we choose too low a value for the threshold,
we could lose some of the shapes that are too bright.
You can experiment with the threshold by re-running the above code lines with
different values for <code class="language-plaintext highlighter-rouge">t</code>.
In practice, it is a matter of domain knowledge and
experience to interpret the peaks in the histogram so to determine
an appropriate threshold.
The process often involves trial and error,
which is a drawback of the simple thresholding method.
Below we will introduce automatic thresholding,
which uses a quantitative, mathematical definition for a good threshold that
allows us to determine the value of <code class="language-plaintext highlighter-rouge">t</code> automatically.
It is worth noting that the principle for simple and automatic thresholding
can also be used for images with pixel ranges other than [0.0, 1.0].
For example, we could perform thresholding on pixel intensity values
in the range [0, 255] as we have already seen in
<a href="https://datacarpentry.org/image-processing/03-skimage-images/index.html">the <em>Image Representation in skimage</em> episode</a>.</p>
</blockquote>

<p>We can now apply the <code class="language-plaintext highlighter-rouge">binary_mask</code> to the original coloured image as we
have learned in <a href="https://datacarpentry.org/image-processing/04-drawing/index.html">the <em>Drawing and Bitwise Operations</em> episode</a>.
What we are left with is only the coloured shapes from the original.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># use the binary_mask to select the "interesting" part of the image
</span><span class="n">selection</span> <span class="o">=</span> <span class="n">image</span><span class="p">.</span><span class="n">copy</span><span class="p">()</span>
<span class="n">selection</span><span class="p">[</span><span class="o">~</span><span class="n">binary_mask</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">selection</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="./Image Processing with Python_files/shapes-01-selected.png" alt="Selected shapes after applying binary mask"></p>

<blockquote class="challenge">
  <h2 id="more-practice-with-simple-thresholding-15-min">More practice with simple thresholding (15 min)<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#more-practice-with-simple-thresholding-15-min" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>

  <p>Now, it is your turn to practice. Suppose we want to use simple thresholding
to select only the coloured shapes (in this particular case we consider grayish to be a colour, too) from the image <code class="language-plaintext highlighter-rouge">data/shapes-02.jpg</code>:</p>

  <p><img src="./Image Processing with Python_files/shapes-02.jpg" alt="Another image with geometric shapes on white background"></p>

  <p>First, plot the grayscale histogram as in the <a href="https://datacarpentry.org/image-processing/05-creating-histograms/">Creating
Histogram</a> episode and
examine the distribution of grayscale values in the image. What do
you think would be a good value for the threshold <code class="language-plaintext highlighter-rouge">t</code>?</p>

  <blockquote class="solution">
    <h2 id="solution">Solution<span class="fold-unfold glyphicon glyphicon-collapse-down"></span><a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#solution" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>

    <p style="display: none;">The histogram for the <code class="language-plaintext highlighter-rouge">data/shapes-02.jpg</code> image can be shown with</p>

    <div class="language-python highlighter-rouge" style="display: none;"><div class="highlight"><pre class="highlight"><code><span class="n">gray_image</span> <span class="o">=</span> <span class="n">skimage</span><span class="p">.</span><span class="n">io</span><span class="p">.</span><span class="n">imread</span><span class="p">(</span><span class="s">"data/shapes-02.jpg"</span><span class="p">,</span> <span class="n">as_gray</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">histogram</span><span class="p">,</span> <span class="n">bin_edges</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">histogram</span><span class="p">(</span><span class="n">gray_image</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="nb">range</span><span class="o">=</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">))</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">bin_edges</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">histogram</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">"Graylevel histogram"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">"gray value"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">"pixel count"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span>
</code></pre></div>    </div>

    <p style="display: none;"><img src="./Image Processing with Python_files/shapes-02-histogram.png" alt="Grayscale histogram of the second geometric shapes image"></p>

    <p style="display: none;">We can see a large spike around 0.3, and a smaller spike around 0.7. The
spike near 0.3 represents the darker background, so it seems like a value
close to <code class="language-plaintext highlighter-rouge">t=0.5</code> would be a good choice.</p>
  </blockquote>

  <p>Next, create a mask to turn the pixels above the threshold <code class="language-plaintext highlighter-rouge">t</code> on
and pixels below the threshold <code class="language-plaintext highlighter-rouge">t</code> off. Note that unlike the image
with a white background we used above, here the peak for the
background colour is at a lower gray level than the
shapes. Therefore, change the comparison operator less <code class="language-plaintext highlighter-rouge">&lt;</code> to
greater <code class="language-plaintext highlighter-rouge">&gt;</code> to create the appropriate mask. Then apply the mask to
the image and view the thresholded image. If everything works as it
should, your output should show only the coloured shapes on a black
background.</p>
  <blockquote class="solution">
    <h2 id="solution-1">Solution<span class="fold-unfold glyphicon glyphicon-collapse-down"></span><a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#solution-1" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>

    <p style="display: none;">Here are the commands to create and view the binary mask</p>
    <div class="language-python highlighter-rouge" style="display: none;"><div class="highlight"><pre class="highlight"><code><span class="n">t</span> <span class="o">=</span> <span class="mf">0.5</span>
<span class="n">binary_mask</span> <span class="o">=</span> <span class="n">gray_image</span> <span class="o">&gt;</span> <span class="n">t</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">binary_mask</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s">"gray"</span><span class="p">)</span>
</code></pre></div>    </div>

    <p style="display: none;"><img src="./Image Processing with Python_files/shapes-02-mask.png" alt="Binary mask created by thresholding the second geometric shapes image"></p>

    <p style="display: none;">And here are the commands to apply the mask and view the thresholded image</p>
    <div class="language-python highlighter-rouge" style="display: none;"><div class="highlight"><pre class="highlight"><code><span class="n">image</span> <span class="o">=</span> <span class="n">skimage</span><span class="p">.</span><span class="n">io</span><span class="p">.</span><span class="n">imread</span><span class="p">(</span><span class="s">"data/shapes-02.jpg"</span><span class="p">)</span>
<span class="n">selection</span> <span class="o">=</span> <span class="n">image</span><span class="p">.</span><span class="n">copy</span><span class="p">()</span>
<span class="n">selection</span><span class="p">[</span><span class="o">~</span><span class="n">binary_mask</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">selection</span><span class="p">)</span>
</code></pre></div>    </div>

    <p style="display: none;"><img src="./Image Processing with Python_files/shapes-02-selected.png" alt="Selected shapes after applying binary mask to the second geometric shapes image"></p>

  </blockquote>
</blockquote>

<h2 id="automatic-thresholding">Automatic thresholding<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#automatic-thresholding" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>

<p>The downside of the simple thresholding technique is that we have to
make an educated guess about the threshold <code class="language-plaintext highlighter-rouge">t</code> by inspecting the histogram.
There are also <em>automatic thresholding</em> methods that can determine
the threshold automatically for us.
One such method is <em><a href="https://en.wikipedia.org/wiki/Otsu%27s_method">Otsu’s method</a></em>.
It is particularly useful for situations where the grayscale histogram of an image
has two peaks that correspond to background and objects of interest.</p>

<blockquote class="callout">
  <h2 id="denoising-an-image-before-thresholding">Denoising an image before thresholding<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#denoising-an-image-before-thresholding" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>

  <p>In practice, it is often necessary to denoise the image before
thresholding, which can be done with one of the methods from
<a href="https://datacarpentry.org/image-processing/06-blurring/index.html">the <em>Blurring Images</em> episode</a>.</p>
</blockquote>

<p>Consider the image <code class="language-plaintext highlighter-rouge">data/maize-root-cluster.jpg</code> of a maize root system which
we have seen before in
<a href="https://datacarpentry.org/image-processing/03-skimage-images/index.html">the <em>Image Representation in skimage</em> episode</a>.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">image</span> <span class="o">=</span> <span class="n">skimage</span><span class="p">.</span><span class="n">io</span><span class="p">.</span><span class="n">imread</span><span class="p">(</span><span class="n">fname</span><span class="o">=</span><span class="s">"data/maize-root-cluster.jpg"</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="./Image Processing with Python_files/maize-root-cluster.jpg" alt="Image of a maize root"></p>

<p>We use Gaussian blur with a sigma of 1.0 to denoise the root image.
Let us look at the grayscale histogram of the denoised image.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># convert the image to grayscale
</span><span class="n">gray_image</span> <span class="o">=</span> <span class="n">skimage</span><span class="p">.</span><span class="n">color</span><span class="p">.</span><span class="n">rgb2gray</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>

<span class="c1"># blur the image to denoise
</span><span class="n">blurred_image</span> <span class="o">=</span> <span class="n">skimage</span><span class="p">.</span><span class="n">filters</span><span class="p">.</span><span class="n">gaussian</span><span class="p">(</span><span class="n">gray_image</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>

<span class="c1"># show the histogram of the blurred image
</span><span class="n">histogram</span><span class="p">,</span> <span class="n">bin_edges</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">histogram</span><span class="p">(</span><span class="n">blurred_image</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="nb">range</span><span class="o">=</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">))</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">bin_edges</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">histogram</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">"Graylevel histogram"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">"gray value"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">"pixel count"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="./Image Processing with Python_files/maize-root-cluster-histogram.png" alt="Grayscale histogram of the maize root image"></p>

<p>The histogram has a significant peak around 0.2, and a second,
smaller peak very near 1.0.
Thus, this image is a good candidate for thresholding with Otsu’s method.
The mathematical details of how this works are complicated (see
<a href="https://scikit-image.org/docs/dev/api/skimage.filters.html#threshold-otsu">the skimage documentation</a>
if you are interested),
but the outcome is that Otsu’s method finds a threshold value between
the two peaks of a grayscale histogram.</p>

<p>The <code class="language-plaintext highlighter-rouge">skimage.filters.threshold_otsu()</code> function can be used to determine
the threshold automatically via Otsu’s method.
Then numpy comparison operators can be used to apply it as before.
Here are the Python commands to determine the threshold <code class="language-plaintext highlighter-rouge">t</code> with Otsu’s method.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># perform automatic thresholding
</span><span class="n">t</span> <span class="o">=</span> <span class="n">skimage</span><span class="p">.</span><span class="n">filters</span><span class="p">.</span><span class="n">threshold_otsu</span><span class="p">(</span><span class="n">blurred_image</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Found automatic threshold t = {}."</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">t</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-plaintext output highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Found automatic threshold t = 0.4172454549881862.
</code></pre></div></div>

<p>For this root image and a Gaussian blur with the chosen sigma of 1.0,
the computed threshold value is 0.42.
No we can create a binary mask with the comparison operator <code class="language-plaintext highlighter-rouge">&gt;</code>.
As we have seen before, pixels above the threshold value will be turned on,
those below the threshold will be turned off.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># create a binary mask with the threshold found by Otsu's method
</span><span class="n">binary_mask</span> <span class="o">=</span> <span class="n">blurred_image</span> <span class="o">&gt;</span> <span class="n">t</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">binary_mask</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s">"gray"</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="./Image Processing with Python_files/maize-root-cluster-mask.png" alt="Binary mask of the maize root system"></p>

<p>Finally, we use the mask to select the foreground:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># apply the binary mask to select the foreground
</span><span class="n">selection</span> <span class="o">=</span> <span class="n">image</span><span class="p">.</span><span class="n">copy</span><span class="p">()</span>
<span class="n">selection</span><span class="p">[</span><span class="o">~</span><span class="n">binary_mask</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">selection</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="./Image Processing with Python_files/maize-root-cluster-selected.png" alt="Masked selection of the maize root system"></p>

<h2 id="application-measuring-root-mass">Application: measuring root mass<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#application-measuring-root-mass" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>

<p>Let us now turn to an application where we can apply thresholding and
other techniques we have learned to this point.
Consider these four maize root system images,
which you can find in the files
<code class="language-plaintext highlighter-rouge">data/trial-016.jpg</code>,
<code class="language-plaintext highlighter-rouge">data/trial-020.jpg</code>,
<code class="language-plaintext highlighter-rouge">data/trial-216.jpg</code>,
and <code class="language-plaintext highlighter-rouge">data/trial-293.jpg</code>.</p>

<p><img src="./Image Processing with Python_files/four-maize-roots.jpg" alt="Four images of maize roots"></p>

<p>Suppose we are interested in the amount of plant material in each image,
and in particular how that amount changes from image to image.
Perhaps the images represent the growth of the plant over time,
or perhaps the images show four different maize varieties at the
same phase of their growth.
The question we would like to answer is, “how much root mass is in each image?”</p>

<p>We will first construct a Python program to measure this value for a single image.
Our strategy will be this:</p>

<ol>
  <li>Read the image, converting it to grayscale as it is read. For this
application we do not need the colour image.</li>
  <li>Blur the image.</li>
  <li>Use Otsu’s method of thresholding to create a binary image, where
the pixels that were part of the maize plant are white, and everything
else is black.</li>
  <li>Save the binary image so it can be examined later.</li>
  <li>Count the white pixels in the binary image, and divide by the
number of pixels in the image. This ratio will be a measure of the
root mass of the plant in the image.</li>
  <li>Output the name of the image processed and the root mass ratio.</li>
</ol>

<p>Our intent is to perform these steps and produce the numeric result -
a measure of the root mass in the image -
without human intervention.
Implementing the steps within a Python function will
enable us to call this function for different images.</p>

<p>Here is a Python function that implements this root-mass-measuring strategy.
Since the function is intended to produce numeric output without human interaction,
it does not display any of the images.
Almost all of the commands should be familiar, and in fact,
it may seem simpler than the code we have worked on thus far,
because we are not displaying any of the images.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">measure_root_mass</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>

    <span class="c1"># read the original image, converting to grayscale on the fly
</span>    <span class="n">image</span> <span class="o">=</span> <span class="n">skimage</span><span class="p">.</span><span class="n">io</span><span class="p">.</span><span class="n">imread</span><span class="p">(</span><span class="n">fname</span><span class="o">=</span><span class="n">filename</span><span class="p">,</span> <span class="n">as_gray</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

    <span class="c1"># blur before thresholding
</span>    <span class="n">blurred_image</span> <span class="o">=</span> <span class="n">skimage</span><span class="p">.</span><span class="n">filters</span><span class="p">.</span><span class="n">gaussian</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="n">sigma</span><span class="p">)</span>

    <span class="c1"># perform automatic thresholding to produce a binary image
</span>    <span class="n">t</span> <span class="o">=</span> <span class="n">skimage</span><span class="p">.</span><span class="n">filters</span><span class="p">.</span><span class="n">threshold_otsu</span><span class="p">(</span><span class="n">blurred_image</span><span class="p">)</span>
    <span class="n">binary_mask</span> <span class="o">=</span> <span class="n">blurred_image</span> <span class="o">&gt;</span> <span class="n">t</span>

    <span class="c1"># determine root mass ratio
</span>    <span class="n">rootPixels</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">count_nonzero</span><span class="p">(</span><span class="n">binary_mask</span><span class="p">)</span>
    <span class="n">w</span> <span class="o">=</span> <span class="n">binary_mask</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">h</span> <span class="o">=</span> <span class="n">binary_mask</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">density</span> <span class="o">=</span> <span class="n">rootPixels</span> <span class="o">/</span> <span class="p">(</span><span class="n">w</span> <span class="o">*</span> <span class="n">h</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">density</span>
</code></pre></div></div>

<p>The function begins with reading the orignal image from the file <code class="language-plaintext highlighter-rouge">filename</code>.
We use <code class="language-plaintext highlighter-rouge">skimage.io.imread</code> with the optional argument <code class="language-plaintext highlighter-rouge">as_gray=True</code> to
automatically convert it to grayscale.
Next, the grayscale image is blurred with a Gaussian filter with
the value of <code class="language-plaintext highlighter-rouge">sigma</code> that is passed to the function.
Then we determine the threshold <code class="language-plaintext highlighter-rouge">t</code> with Otsu’s method and
create a binary mask just as we did in the previous section.
Up to this point, everything should be familiar.</p>

<p>The final part of the function determines the root mass ratio in the image.
Recall that in the <code class="language-plaintext highlighter-rouge">binary_mask</code>, every pixel has either a value of
zero (black/background) or one (white/foreground).
We want to count the number of white pixels,
which can be accomplished with a call to the numpy function <code class="language-plaintext highlighter-rouge">np.count_nonzero</code>.
Then we determine the width and height of the image by using
the elements of <code class="language-plaintext highlighter-rouge">binary_mask.shape</code>
(that is, the dimensions of the numpy array that stores the image).
Finally, the density ratio is calculated by dividing the number of white pixels
by the total number of pixels <code class="language-plaintext highlighter-rouge">w*h</code> in the image.
The function returns then root density of the image.</p>

<p>We can call this function with any filename and
provide a sigma value for the blurring.
If no sigma value is provided, the default value 1.0 will be used.
For example, for the file <code class="language-plaintext highlighter-rouge">data/trial-016.jpg</code> and a sigma value of 1.5,
we would call the function like this:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">measure_root_mass</span><span class="p">(</span><span class="n">filename</span><span class="o">=</span><span class="s">"data/trial-016.jpg"</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">1.5</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext output highlighter-rouge"><div class="highlight"><pre class="highlight"><code>0.0482436835106383`
</code></pre></div></div>

<p>Now we can use the function to process the series of four images shown above.
In a real-world scientific situation, there might be dozens, hundreds,
or even thousands of images to process.
To save us the tedium of calling the function for each image by hand,
we can write a loop that processes all files automatically.
The following code block assumes that the files are located in the same directory
and the filenames all start with the <strong>trial-</strong> prefix and
end with the <strong>.jpg</strong> suffix.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">all_files</span> <span class="o">=</span> <span class="n">glob</span><span class="p">.</span><span class="n">glob</span><span class="p">(</span><span class="s">"data/trial-*.jpg"</span><span class="p">)</span>
<span class="k">for</span> <span class="n">filename</span> <span class="ow">in</span> <span class="n">all_files</span><span class="p">:</span>
    <span class="n">density</span> <span class="o">=</span> <span class="n">measure_root_mass</span><span class="p">(</span><span class="n">filename</span><span class="o">=</span><span class="n">filename</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">1.5</span><span class="p">)</span>
    <span class="c1"># output in format suitable for .csv
</span>    <span class="k">print</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="n">density</span><span class="p">,</span> <span class="n">sep</span><span class="o">=</span><span class="s">","</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext output highlighter-rouge"><div class="highlight"><pre class="highlight"><code>data/trial-016.jpg,0.0482436835106383
data/trial-020.jpg,0.06346941489361702
data/trial-216.jpg,0.14073969414893617
data/trial-293.jpg,0.13607895611702128
</code></pre></div></div>

<blockquote class="challenge">
  <h2 id="ignoring-more-of-the-images--brainstorming-10-min">Ignoring more of the images – brainstorming (10 min)<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#ignoring-more-of-the-images--brainstorming-10-min" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>

  <p>Let us take a closer look at the binary masks produced by the <code class="language-plaintext highlighter-rouge">measure_root_mass</code> function.</p>

  <p><img src="./Image Processing with Python_files/four-maize-roots-binary.jpg" alt="Binary masks of the four maize root images"></p>

  <p>You may have noticed in the section on automatic thresholding that
the thresholded image does include regions of the image aside of the
plant root: the numbered labels and the white circles in each image
are preserved during the thresholding, because their grayscale
values are above the threshold.
Therefore, our calculated root mass ratios include the white pixels
of the label and white circle that are not part of the plant root.
Those extra pixels affect how accurate the root mass calculation is!</p>

  <p>How might we remove the labels and circles before calculating the ratio,
so that our results are more accurate?
Think about some options given what we have learned so far.</p>

  <blockquote class="solution">
    <h2 id="solution-2">Solution<span class="fold-unfold glyphicon glyphicon-collapse-down"></span><a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#solution-2" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>

    <p style="display: none;">One approach we might take is to try to completely mask out a region
from each image, particularly,
the area containing the white circle and the numbered label.
If we had coordinates for a rectangular area on the image
that contained the circle and the label,
we could mask the area out easily by using techniques we learned in
<a href="https://datacarpentry.org/image-processing/04-drawing/index.html">the <em>Drawing and Bitwise Operations</em> episode</a>.</p>

    <p style="display: none;">However, a closer inspection of the binary images raises some issues with
that approach.
Since the roots are not always constrained to a certain area in the image,
and since the circles and labels are in different locations each time,
we would have difficulties coming up with a single rectangle that would
work for <em>every</em> image.
We could create a different masking rectangle for each image,
but that is not a practicable approach
if we have hundreds or thousands of images to process.</p>

    <p style="display: none;">Another approach we could take is
to apply two thresholding steps to the image.
Look at the graylevel histogram of the file <code class="language-plaintext highlighter-rouge">data/trial-016.jpg</code> shown
above again:
Notice the peak near 1.0?
Recall that a grayscale value of 1.0 corresponds to white pixels:
the peak corresponds to the white label and circle.
So, we could use simple binary thresholding to mask the white circle and
label from the image,
and then we could use Otsu’s method to select the pixels in
the plant portion of the image.</p>

    <p style="display: none;">Note that most of this extra work in processing the image could have been
avoided during the experimental design stage,
with some careful consideration of how the resulting images would be used.
For example, all of the following measures could have made the images easier
to process, by helping us predict and/or detect where the label is in the image
and subsequently mask it from further processing:</p>

    <ul style="display: none;">
      <li>Using labels with a consistent size and shape</li>
      <li>Placing all the labels in the same position, relative to the sample</li>
      <li>Using a non-white label, with non-black writing</li>
    </ul>

  </blockquote>
</blockquote>

<blockquote class="challenge">
  <h2 id="ignoring-more-of-the-images--implementation-30-min---optional-not-included-in-timing">Ignoring more of the images – implementation (30 min - optional, not included in timing)<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#ignoring-more-of-the-images--implementation-30-min---optional-not-included-in-timing" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>

  <p>Implement an enhanced version of the function <code class="language-plaintext highlighter-rouge">measure_root_mass</code>
that applies simple binary thresholding to remove the white circle
and label from the image before applying Otsu’s method.</p>

  <blockquote class="solution">
    <h2 id="solution-3">Solution<span class="fold-unfold glyphicon glyphicon-collapse-down"></span><a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#solution-3" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>

    <p style="display: none;">We can apply a simple binary thresholding with a threshold
<code class="language-plaintext highlighter-rouge">t=0.95</code> to remove the label and circle from the image. We use the
binary mask to set the pixels in the blurred image to zero
(black).</p>

    <div class="language-python highlighter-rouge" style="display: none;"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">enhanced_root_mass</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="n">sigma</span><span class="p">):</span>

    <span class="c1"># read the original image, converting to grayscale on the fly
</span>    <span class="n">image</span> <span class="o">=</span> <span class="n">skimage</span><span class="p">.</span><span class="n">io</span><span class="p">.</span><span class="n">imread</span><span class="p">(</span><span class="n">fname</span><span class="o">=</span><span class="n">filename</span><span class="p">,</span> <span class="n">as_gray</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

    <span class="c1"># blur before thresholding
</span>    <span class="n">blurred_image</span> <span class="o">=</span> <span class="n">skimage</span><span class="p">.</span><span class="n">filters</span><span class="p">.</span><span class="n">gaussian</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="n">sigma</span><span class="p">)</span>

    <span class="c1"># perform binary thresholding to mask the white label and circle
</span>    <span class="n">binary_mask</span> <span class="o">=</span> <span class="n">blurred_image</span> <span class="o">&lt;</span> <span class="mf">0.95</span>
    <span class="c1"># use the mask to remove the circle and label from the blurred image
</span>    <span class="n">blurred_image</span><span class="p">[</span><span class="o">~</span><span class="n">binary_mask</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="c1"># perform automatic thresholding to produce a binary image
</span>    <span class="n">t</span> <span class="o">=</span> <span class="n">skimage</span><span class="p">.</span><span class="n">filters</span><span class="p">.</span><span class="n">threshold_otsu</span><span class="p">(</span><span class="n">blurred_image</span><span class="p">)</span>
    <span class="n">binary_mask</span> <span class="o">=</span> <span class="n">blurred_image</span> <span class="o">&gt;</span> <span class="n">t</span>

    <span class="c1"># determine root mass ratio
</span>    <span class="n">rootPixels</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">count_nonzero</span><span class="p">(</span><span class="n">binary_mask</span><span class="p">)</span>
    <span class="n">w</span> <span class="o">=</span> <span class="n">binary_mask</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">h</span> <span class="o">=</span> <span class="n">binary_mask</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">density</span> <span class="o">=</span> <span class="n">rootPixels</span> <span class="o">/</span> <span class="p">(</span><span class="n">w</span> <span class="o">*</span> <span class="n">h</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">density</span>

<span class="n">all_files</span> <span class="o">=</span> <span class="n">glob</span><span class="p">.</span><span class="n">glob</span><span class="p">(</span><span class="s">"data/trial-*.jpg"</span><span class="p">)</span>
<span class="k">for</span> <span class="n">filename</span> <span class="ow">in</span> <span class="n">all_files</span><span class="p">:</span>
    <span class="n">density</span> <span class="o">=</span> <span class="n">enhanced_root_mass</span><span class="p">(</span><span class="n">filename</span><span class="o">=</span><span class="n">filename</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">1.5</span><span class="p">)</span>
    <span class="c1"># output in format suitable for .csv
</span>    <span class="k">print</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="n">density</span><span class="p">,</span> <span class="n">sep</span><span class="o">=</span><span class="s">","</span><span class="p">)</span>
</code></pre></div>    </div>

    <p style="display: none;">The output of the improved program does illustrate that the white circles
and labels were skewing our root mass ratios:</p>

    <div class="language-plaintext output highlighter-rouge" style="display: none;"><div class="highlight"><pre class="highlight"><code>data/trial-016.jpg,0.045935837765957444
data/trial-020.jpg,0.058800033244680854
data/trial-216.jpg,0.13705003324468085
data/trial-293.jpg,0.13164461436170213
</code></pre></div>    </div>

    <p style="display: none;">Here are the binary images produced by the additional thresholding.
Note that we have not completely removed the offending white pixels.
Outlines still remain.
However, we have reduced the number of extraneous pixels,
which should make the output more accurate.</p>

    <p style="display: none;"><img src="./Image Processing with Python_files/four-maize-roots-binary-improved.jpg" alt="Improved binary masks of the four maize root images"></p>

  </blockquote>
</blockquote>

<blockquote class="challenge">
  <h2 id="thresholding-a-bacteria-colony-image-15-min">Thresholding a bacteria colony image (15 min)<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#thresholding-a-bacteria-colony-image-15-min" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>

  <p>In the images directory <code class="language-plaintext highlighter-rouge">data/</code>, you will find an image named <code class="language-plaintext highlighter-rouge">colonies-01.tif</code>.</p>

  <p><img src="./Image Processing with Python_files/colonies-01.jpg" alt="Image of bacteria colonies in a petri dish"></p>

  <p>This is one of the images you will be working with in the
morphometric challenge at the end of the workshop.</p>

  <ol>
    <li>Plot and inspect the grayscale histogram of the image to
determine a good threshold value for the image.</li>
    <li>Create a binary mask that leaves the pixels in the bacteria
colonies “on” while turning the rest of the pixels in the image
“off”.</li>
  </ol>

  <blockquote class="solution">
    <h2 id="solution-4">Solution<span class="fold-unfold glyphicon glyphicon-collapse-down"></span><a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#solution-4" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>
    <p style="display: none;">Here is the code to create the grayscale histogram:</p>
    <div class="language-python highlighter-rouge" style="display: none;"><div class="highlight"><pre class="highlight"><code><span class="n">image</span> <span class="o">=</span> <span class="n">skimage</span><span class="p">.</span><span class="n">io</span><span class="p">.</span><span class="n">imread</span><span class="p">(</span><span class="n">fname</span><span class="o">=</span><span class="s">"data/colonies-01.tif"</span><span class="p">)</span>
<span class="n">gray_image</span> <span class="o">=</span> <span class="n">skimage</span><span class="p">.</span><span class="n">color</span><span class="p">.</span><span class="n">rgb2gray</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
<span class="n">blurred_image</span> <span class="o">=</span> <span class="n">skimage</span><span class="p">.</span><span class="n">filters</span><span class="p">.</span><span class="n">gaussian</span><span class="p">(</span><span class="n">gray_image</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
<span class="n">histogram</span><span class="p">,</span> <span class="n">bin_edges</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">histogram</span><span class="p">(</span><span class="n">blurred_image</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="nb">range</span><span class="o">=</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">))</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">bin_edges</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">histogram</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">"Graylevel histogram"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">"gray value"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">"pixel count"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span>
</code></pre></div>    </div>

    <p style="display: none;"><img src="./Image Processing with Python_files/colonies-01-histogram.png" alt="Grayscale histogram of the bacteria colonies image"></p>

    <p style="display: none;">The peak near one corresponds to the white image background,
and the broader peak around 0.5 corresponds to the yellow/brown
culture medium in the dish.
The small peak near zero is what we are after: the dark bacteria colonies.
A reasonable choice thus might be to leave pixels below <code class="language-plaintext highlighter-rouge">t=0.2</code> on.</p>

    <p style="display: none;">Here is the code to create and show the binarized image using the
<code class="language-plaintext highlighter-rouge">&lt;</code> operator with a threshold <code class="language-plaintext highlighter-rouge">t=0.2</code>:</p>

    <div class="language-python highlighter-rouge" style="display: none;"><div class="highlight"><pre class="highlight"><code><span class="n">t</span> <span class="o">=</span> <span class="mf">0.2</span>
<span class="n">binary_mask</span> <span class="o">=</span> <span class="n">blurred_image</span> <span class="o">&lt;</span> <span class="n">t</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">binary_mask</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s">"gray"</span><span class="p">)</span>
</code></pre></div>    </div>

    <p style="display: none;"><img src="./Image Processing with Python_files/colonies-01-mask.png" alt="Binary mask of the bacteria colonies image"></p>

    <p style="display: none;">When you experiment with the threshold a bit, you can see that in
particular the size of the bacteria colony near the edge of the
dish in the top right is affected by the choice of the threshold.</p>
  </blockquote>
</blockquote>

<blockquote class="keypoints">
  <h2 id="key-points-6">Key Points<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#key-points-6" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>
  <ul>
    
    <li><p>Thresholding produces a binary image, where all pixels with intensities above (or below) a threshold value are turned on, while all other pixels are turned off.</p>
</li>
    
    <li><p>The binary images produced by thresholding are held in two-dimensional NumPy arrays, since they have only one colour value channel. They are boolean, hence they contain the values 0 (off) and 1 (on).</p>
</li>
    
    <li><p>Thresholding can be used to create masks that select only the interesting parts of an image, or as the first step before edge detection or finding contours.</p>
</li>
    
  </ul>
</blockquote>

<hr>

<h1 id="connected-component-analysis" class="maintitle">Connected Component Analysis</h1>

<blockquote class="objectives">
  <h2 id="overview-7">Overview<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#overview-7" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>

  <div class="row">
    <div class="col-md-3">
      <strong>Teaching:</strong> 70 min
      <br>
      <strong>Exercises:</strong> 55 min
    </div>
    <div class="col-md-9">
      <strong>Questions</strong>
      <ul>
	
	<li><p>How to extract separate objects from an image and describe these objects quantitatively.</p>
</li>
	
      </ul>
    </div>
  </div>

  <div class="row">
    <div class="col-md-3">
    </div>
    <div class="col-md-9">
      <strong>Objectives</strong>
      <ul>
	
	<li><p>Understand the term object in the context of images.</p>
</li>
	
	<li><p>Learn about pixel connectivity.</p>
</li>
	
	<li><p>Learn how Connected Component Analysis (CCA) works.</p>
</li>
	
	<li><p>Use CCA to produce an image that highlights every object in a different colour.</p>
</li>
	
	<li><p>Characterise each object with numbers that describe its appearance.</p>
</li>
	
      </ul>
    </div>
  </div>

</blockquote>

<h2 id="objects">Objects<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#objects" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>

<p>In <a href="https://datacarpentry.org/image-processing/07-thresholding/index.html">the <em>Thresholding</em> episode</a>
we have covered dividing an image into foreground and background pixels.
In the shapes example image,
we considered the coloured shapes as foreground <em>objects</em> on a white background.</p>

<p class="image-with-shadow"><img src="./Image Processing with Python_files/shapes-01.jpg" alt="Original shapes image"></p>

<p>In thresholding we went from the original image to this version:</p>

<p><img src="./Image Processing with Python_files/shapes-01-mask.png" alt="Mask created by thresholding"></p>

<p>Here, we created a mask that only highlights the parts of the image
that we find interesting, the <em>objects</em>.
All objects have pixel value of <code class="language-plaintext highlighter-rouge">True</code> while the background pixels are <code class="language-plaintext highlighter-rouge">False</code>.</p>

<p>By looking at the mask image,
one can count the objects that are present in the image (7).
But how did we actually do that,
how did we decide which lump of pixels constitutes a single object?</p>

<!-- TODO: Group exercise: given sheep of paper with grids of 0's and
1's, how to identify which pixels belong to an object, find a rule for
each pixel to determine in which object it is -->

<h2 id="pixel-neighborhoods">Pixel Neighborhoods<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#pixel-neighborhoods" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>

<p>In order to decide which pixels belong to the same object,
one can exploit their neighborhood:
pixels that are directly next to each other
and belong to the foreground class can be considered to belong to the same object.</p>

<p>Let’s discuss the concept of pixel neighborhoods in more detail.
Consider the following mask “image” with 8 rows, and 8 columns.
Note that for brevity,
<code class="language-plaintext highlighter-rouge">0</code> is used to represent <code class="language-plaintext highlighter-rouge">False</code> (background) and <code class="language-plaintext highlighter-rouge">1</code> to represent <code class="language-plaintext highlighter-rouge">True</code> (foreground).</p>

<div class="language-plaintext output highlighter-rouge"><div class="highlight"><pre class="highlight"><code>0 0 0 0 0 0 0 0
0 1 1 0 0 0 0 0
0 1 1 0 0 0 0 0
0 0 0 1 1 1 0 0
0 0 0 1 1 1 1 0
0 0 0 0 0 0 0 0
</code></pre></div></div>

<p>The pixels are organised in a rectangular grid.
In order to understand pixel neighborhoods
we will introduce the concept of “jumps” between pixels.
The jumps follow two rules:
First rule is that one jump is only allowed along the column, or the row.
Diagonal jumps are not allowed.
So, from a centre pixel, denoted with <code class="language-plaintext highlighter-rouge">o</code>,
only the pixels indicated with an <code class="language-plaintext highlighter-rouge">x</code> are reachable:</p>

<div class="language-plaintext output highlighter-rouge"><div class="highlight"><pre class="highlight"><code>- x -
x o x
- x -
</code></pre></div></div>

<p>The pixels on the diagonal (from <code class="language-plaintext highlighter-rouge">o</code>) are not reachable with a single jump,
which is denoted by the <code class="language-plaintext highlighter-rouge">-</code>.
The pixels reachable with a single jump form the <strong>1-jump</strong> neighborhood.</p>

<p>The second rule states that in a sequence of jumps,
one may only jump in row and column direction once -&gt; they have to be <em>orthogonal</em>.
An example of a sequence of orthogonal jumps is shown below.
Starting from <code class="language-plaintext highlighter-rouge">o</code> the first jump goes along the row to the right.
The second jump then goes along the column direction up.
After this,
the sequence cannot be continued as a jump has already been made
in both row and column direction.</p>

<div class="language-plaintext output highlighter-rouge"><div class="highlight"><pre class="highlight"><code>- - 2
- o 1
- - -
</code></pre></div></div>

<p>All pixels reachable with one, or two jumps form the <strong>2-jump</strong> neighborhood.
The grid below illustrates the pixels reachable from
the centre pixel <code class="language-plaintext highlighter-rouge">o</code> with a single jump, highlighted with a <code class="language-plaintext highlighter-rouge">1</code>,
and the pixels reachable with 2 jumps with a <code class="language-plaintext highlighter-rouge">2</code>.</p>

<div class="language-plaintext output highlighter-rouge"><div class="highlight"><pre class="highlight"><code>2 1 2
1 o 1
2 1 2
</code></pre></div></div>

<p>We want to revisit our example image mask from above and apply
the two different neighborhood rules.
With a single jump connectivity for each pixel, we get two resulting objects,
highlighted in the image with <code class="language-plaintext highlighter-rouge">1</code>’s and <code class="language-plaintext highlighter-rouge">2</code>’s.</p>

<div class="language-plaintext output highlighter-rouge"><div class="highlight"><pre class="highlight"><code>0 0 0 0 0 0 0 0
0 1 1 0 0 0 0 0
0 1 1 0 0 0 0 0
0 0 0 2 2 2 0 0
0 0 0 2 2 2 2 0
0 0 0 0 0 0 0 0
</code></pre></div></div>

<p>In the 1-jump version,
only pixels that have direct neighbors along rows or columns are considered connected.
Diagonal connections are not included in the 1-jump neighborhood.
With two jumps, however, we only get a single object because pixels are also
considered connected along the diagonals.</p>

<div class="language-plaintext output highlighter-rouge"><div class="highlight"><pre class="highlight"><code>0 0 0 0 0 0 0 0
0 1 1 0 0 0 0 0
0 1 1 0 0 0 0 0
0 0 0 1 1 1 0 0
0 0 0 1 1 1 1 0
0 0 0 0 0 0 0 0
</code></pre></div></div>

<blockquote class="challenge">
  <h2 id="object-counting-optional-not-included-in-timing">Object counting (optional, not included in timing)<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#object-counting-optional-not-included-in-timing" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>

  <p>How many objects with 1 orthogonal jump, how many with 2 orthogonal jumps?</p>

  <div class="language-plaintext output highlighter-rouge"><div class="highlight"><pre class="highlight"><code>0 0 0 0 0 0 0 0
0 1 0 0 0 1 1 0
0 0 1 0 0 0 0 0
0 1 0 1 1 1 0 0
0 1 0 1 1 0 0 0
0 0 0 0 0 0 0 0
</code></pre></div>  </div>

  <p>1 jump</p>

  <p>a) 1
b) 5
c) 2</p>

  <blockquote class="solution">
    <h2 id="solution">Solution<span class="fold-unfold glyphicon glyphicon-collapse-down"></span><a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#solution" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>
    <p style="display: none;">b) 5</p>
  </blockquote>

  <p>2 jumps</p>

  <p>a) 2
b) 3
c) 5</p>

  <blockquote class="solution">
    <h2 id="solution-1">Solution<span class="fold-unfold glyphicon glyphicon-collapse-down"></span><a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#solution-1" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>
    <p style="display: none;">a) 2</p>
  </blockquote>
</blockquote>

<blockquote class="callout">
  <h2 id="jumps-and-neighborhoods">Jumps and neighborhoods<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#jumps-and-neighborhoods" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>

  <p>We have just introduced how you can reach different neighboring
pixels by performing one or more orthogonal jumps. We have used the
terms 1-jump and 2-jump neighborhood. There is also a different way
of referring to these neighborhoods: the 4- and 8-neighborhood.
With a single jump you can reach four pixels from a given starting
pixel. Hence, the 1-jump neighborhood corresponds to the
4-neighborhood. When two orthogonal jumps are allowed, eight pixels
can be reached, so the 2-jump neighborhood corresponds to the
8-neighborhood.</p>
</blockquote>

<h2 id="connected-component-analysis">Connected Component Analysis<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#connected-component-analysis" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>

<p>In order to find the objects in an image, we want to employ an
operation that is called Connected Component Analysis (CCA).
This operation takes a binary image as an input.
Usually, the <code class="language-plaintext highlighter-rouge">False</code> value in this image is associated with background pixels,
and the <code class="language-plaintext highlighter-rouge">True</code> value indicates foreground, or object pixels.
Such an image can be produced, e.g., with thresholding.
Given a thresholded image,
the connected component analysis produces a new <em>labeled</em> image with integer pixel values.
Pixels with the same value, belong to the same object.
Skimage provides connected component analysis in the function <code class="language-plaintext highlighter-rouge">skimage.measure.label()</code>.
Let us add this function to the already familiar steps of thresholding an image.
Here we define a reusable Python function <code class="language-plaintext highlighter-rouge">connected_components</code>:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="nn">skimage.io</span>
<span class="kn">import</span> <span class="nn">skimage.color</span>
<span class="kn">import</span> <span class="nn">skimage.filters</span>
<span class="kn">import</span> <span class="nn">skimage.measure</span>

<span class="k">def</span> <span class="nf">connected_components</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">t</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">connectivity</span><span class="o">=</span><span class="mi">2</span><span class="p">):</span>
    <span class="c1"># load the image
</span>    <span class="n">image</span> <span class="o">=</span> <span class="n">skimage</span><span class="p">.</span><span class="n">io</span><span class="p">.</span><span class="n">imread</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span>
    <span class="c1"># convert the image to grayscale
</span>    <span class="n">gray_image</span> <span class="o">=</span> <span class="n">skimage</span><span class="p">.</span><span class="n">color</span><span class="p">.</span><span class="n">rgb2gray</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
    <span class="c1"># denoise the image with a Gaussian filter
</span>    <span class="n">blurred_image</span> <span class="o">=</span> <span class="n">skimage</span><span class="p">.</span><span class="n">filters</span><span class="p">.</span><span class="n">gaussian</span><span class="p">(</span><span class="n">gray_image</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="n">sigma</span><span class="p">)</span>
    <span class="c1"># mask the image according to threshold
</span>    <span class="n">binary_mask</span> <span class="o">=</span> <span class="n">blurred_image</span> <span class="o">&lt;</span> <span class="n">t</span>
    <span class="c1"># perform connected component analysis
</span>    <span class="n">labeled_image</span><span class="p">,</span> <span class="n">count</span> <span class="o">=</span> <span class="n">skimage</span><span class="p">.</span><span class="n">measure</span><span class="p">.</span><span class="n">label</span><span class="p">(</span><span class="n">binary_mask</span><span class="p">,</span>
                                                 <span class="n">connectivity</span><span class="o">=</span><span class="n">connectivity</span><span class="p">,</span> <span class="n">return_num</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">labeled_image</span><span class="p">,</span> <span class="n">count</span>
</code></pre></div></div>

<p>Note the new import of <code class="language-plaintext highlighter-rouge">skimage.measure</code> in order to use the
<code class="language-plaintext highlighter-rouge">skimage.measure.label</code> function that performs the CCA.
The first four lines of code are familiar from
<a href="https://datacarpentry.org/image-processing/07-thresholding/index.html">the <em>Thresholding</em> episode</a>.</p>

<!-- Note: shapes image: with sigma=2.0, threshold=0.9 -> 11 objects; with sigma=5 -> 8 objects -->

<p>Then we call the <code class="language-plaintext highlighter-rouge">skimage.measure.label</code> function.
This function has one positional argument where we pass the <code class="language-plaintext highlighter-rouge">binary_mask</code>,
i.e., the binary image to work on.
With the optional argument <code class="language-plaintext highlighter-rouge">connectivity</code>,
we specify the neighborhood in units of orthogonal jumps.
For example,
by setting <code class="language-plaintext highlighter-rouge">connectivity=2</code> we will consider the 2-jump neighborhood introduced above.
The function returns a <code class="language-plaintext highlighter-rouge">labeled_image</code> where each pixel has
a unique value corresponding to the object it belongs to.
In addition, we pass the optional parameter <code class="language-plaintext highlighter-rouge">return_num=True</code> to return
the maximum label index as <code class="language-plaintext highlighter-rouge">count</code>.</p>

<blockquote class="callout">
  <h2 id="optional-parameters-and-return-values">Optional parameters and return values<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#optional-parameters-and-return-values" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>

  <p>The optional parameter <code class="language-plaintext highlighter-rouge">return_num</code> changes the data type that is
returned by the function <code class="language-plaintext highlighter-rouge">skimage.measure.label</code>.
The number of labels is only returned if <code class="language-plaintext highlighter-rouge">return_num</code> is <em>True</em>.
Otherwise, the function only returns the labeled image.
This means that we have to pay attention when assigning
the return value to a variable.
If we omit the optional parameter <code class="language-plaintext highlighter-rouge">return_num</code> or pass <code class="language-plaintext highlighter-rouge">return_num=False</code>,
we can call the function as</p>

  <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">labeled_image</span> <span class="o">=</span> <span class="n">skimage</span><span class="p">.</span><span class="n">measure</span><span class="p">.</span><span class="n">label</span><span class="p">(</span><span class="n">binary_mask</span><span class="p">)</span>
</code></pre></div>  </div>

  <p>If we pass <code class="language-plaintext highlighter-rouge">return_num=True</code>, the function returns a tuple and we
can assign it as</p>

  <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">labeled_image</span><span class="p">,</span> <span class="n">count</span> <span class="o">=</span> <span class="n">skimage</span><span class="p">.</span><span class="n">measure</span><span class="p">.</span><span class="n">label</span><span class="p">(</span><span class="n">binary_mask</span><span class="p">,</span> <span class="n">return_num</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div>  </div>

  <p>If we used the same assignment as in the first case,
the variable <code class="language-plaintext highlighter-rouge">labeled_image</code> would become a tuple,
in which <code class="language-plaintext highlighter-rouge">labeled_image[0]</code> is the image
and <code class="language-plaintext highlighter-rouge">labeled_image[1]</code> is the number of labels.
This could cause confusion if we assume that <code class="language-plaintext highlighter-rouge">labeled_image</code>
only contains the image and pass it to other functions.
If you get an
<code class="language-plaintext highlighter-rouge">AttributeError: 'tuple' object has no attribute 'shape'</code>
or similar,  check if you have assigned the return values consistently
with the optional parameters.</p>
</blockquote>

<p>We can call the above function <code class="language-plaintext highlighter-rouge">connected_components</code> and
display the labeled image like so:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">labeled_image</span><span class="p">,</span> <span class="n">count</span> <span class="o">=</span> <span class="n">connected_components</span><span class="p">(</span><span class="n">filename</span><span class="o">=</span><span class="s">"data/shapes-01.jpg"</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">t</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">connectivity</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">labeled_image</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">axis</span><span class="p">(</span><span class="s">"off"</span><span class="p">);</span>
</code></pre></div></div>

<blockquote class="solution">
  <h2 id="color-mappings">Color mappings<span class="fold-unfold glyphicon glyphicon-collapse-down"></span><a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#color-mappings" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>

  <p style="display: none;">Here you might get a warning
<code class="language-plaintext highlighter-rouge">UserWarning: Low image data range; displaying image with stretched contrast.</code>
or just see an all black image
(Note: this behavior might change in future versions or
not occur with a different image viewer).</p>

  <p style="display: none;">What went wrong?
When you hover over the black image,
the pixel values are shown as numbers in the lower corner of the viewer.
You can see that some pixels have values different from <code class="language-plaintext highlighter-rouge">0</code>,
so they are not actually pure black.
Let’s find out more by examining <code class="language-plaintext highlighter-rouge">labeled_image</code>.
Properties that might be interesting in this context are <code class="language-plaintext highlighter-rouge">dtype</code>,
the minimum and maximum value.
We can print them with the following lines:</p>

  <div class="language-python highlighter-rouge" style="display: none;"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="s">"dtype:"</span><span class="p">,</span> <span class="n">labeled_image</span><span class="p">.</span><span class="n">dtype</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"min:"</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="nb">min</span><span class="p">(</span><span class="n">labeled_image</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s">"max:"</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="nb">max</span><span class="p">(</span><span class="n">labeled_image</span><span class="p">))</span>
</code></pre></div>  </div>

  <p style="display: none;">Examining the output can give us a clue why the image appears black.</p>

  <div class="language-plaintext output highlighter-rouge" style="display: none;"><div class="highlight"><pre class="highlight"><code>dtype: int32
min: 0
max: 11
</code></pre></div>  </div>

  <p style="display: none;">The <code class="language-plaintext highlighter-rouge">dtype</code> of <code class="language-plaintext highlighter-rouge">labeled_image</code> is <code class="language-plaintext highlighter-rouge">int64</code>.
This means that values in this image range from <code class="language-plaintext highlighter-rouge">-2 ** 63</code> to <code class="language-plaintext highlighter-rouge">2 ** 63 - 1</code>.
Those are really big numbers.
From this available space we only use the range from <code class="language-plaintext highlighter-rouge">0</code> to <code class="language-plaintext highlighter-rouge">11</code>.
When showing this image in the viewer,
it squeezes the complete range into 256 gray values.
Therefore, the range of our numbers does not produce any visible change.</p>

  <p style="display: none;">Fortunately, the skimage library has tools to cope with this situation.</p>
</blockquote>

<p>We can use the function <code class="language-plaintext highlighter-rouge">skimage.color.label2rgb()</code>
to convert the colours in the image
(recall that we already used the <code class="language-plaintext highlighter-rouge">skimage.color.rgb2gray()</code> function
to convert to grayscale).
With <code class="language-plaintext highlighter-rouge">skimage.color.label2rgb()</code>,
all objects are coloured according to a list of colours that can be customised.
We can use the following commands to convert and show the image:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># convert the label image to color image
</span><span class="n">colored_label_image</span> <span class="o">=</span> <span class="n">skimage</span><span class="p">.</span><span class="n">color</span><span class="p">.</span><span class="n">label2rgb</span><span class="p">(</span><span class="n">labeled_image</span><span class="p">,</span> <span class="n">bg_label</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">colored_label_image</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">axis</span><span class="p">(</span><span class="s">"off"</span><span class="p">);</span>
</code></pre></div></div>

<p><img src="./Image Processing with Python_files/shapes-01-labeled.png" alt="Labeled objects"></p>

<blockquote class="challenge">
  <h2 id="how-many-objects-are-in-that-image-15-min">How many objects are in that image (15 min)<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#how-many-objects-are-in-that-image-15-min" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>

  <p>Now, it is your turn to practice.
Using the function <code class="language-plaintext highlighter-rouge">connected_components</code>,
find two ways of printing out the number of objects found in the image.</p>

  <p>What number of objects would you expect to get?</p>

  <p>How does changing the <code class="language-plaintext highlighter-rouge">sigma</code> and <code class="language-plaintext highlighter-rouge">threshold</code> values influence the result?</p>

  <blockquote class="solution">
    <h2 id="solution-2">Solution<span class="fold-unfold glyphicon glyphicon-collapse-down"></span><a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#solution-2" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>

    <p style="display: none;">As you might have guessed, the return value <code class="language-plaintext highlighter-rouge">count</code> already
contains the number of found images. So it can simply be printed
with</p>

    <div class="language-python highlighter-rouge" style="display: none;"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="s">"Found"</span><span class="p">,</span> <span class="n">count</span><span class="p">,</span> <span class="s">"objects in the image."</span><span class="p">)</span>
</code></pre></div>    </div>

    <p style="display: none;">But there is also a way to obtain the number of found objects from
the labeled image itself.
Recall that all pixels that belong to a single object
are assigned the same integer value.
The connected component algorithm produces consecutive numbers.
The background gets the value <code class="language-plaintext highlighter-rouge">0</code>,
the first object gets the value <code class="language-plaintext highlighter-rouge">1</code>,
the second object the value <code class="language-plaintext highlighter-rouge">2</code>, and so on.
This means that by finding the object with the maximum value,
we also know how many objects there are in the image.
We can thus use the <code class="language-plaintext highlighter-rouge">np.max</code> function from Numpy to
find the maximum value that equals the number of found objects:</p>

    <div class="language-python highlighter-rouge" style="display: none;"><div class="highlight"><pre class="highlight"><code><span class="n">num_objects</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nb">max</span><span class="p">(</span><span class="n">labeled_image</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Found"</span><span class="p">,</span> <span class="n">num_objects</span><span class="p">,</span> <span class="s">"objects in the image."</span><span class="p">)</span>
</code></pre></div>    </div>

    <p style="display: none;">Invoking the function with <code class="language-plaintext highlighter-rouge">sigma=2.0</code>, and <code class="language-plaintext highlighter-rouge">threshold=0.9</code>,
both methods will print</p>

    <div class="language-plaintext output highlighter-rouge" style="display: none;"><div class="highlight"><pre class="highlight"><code>Found 11 objects in the image.
</code></pre></div>    </div>

    <p style="display: none;">Lowering the threshold will result in fewer objects.
The higher the threshold is set, the more objects are found.
More and more background noise gets picked up as objects.
Larger sigmas produce binary masks with less noise and hence
a smaller number of objects.
Setting sigma too high bears the danger of merging objects.</p>
  </blockquote>
</blockquote>

<p>You might wonder why the connected component analysis with <code class="language-plaintext highlighter-rouge">sigma=2.0</code>,
and <code class="language-plaintext highlighter-rouge">threshold=0.9</code> finds 11 objects, whereas we would expect only 7 objects.
Where are the four additional objects?
With a bit of detective work, we can spot some small objects in the image,
for example, near the left border.</p>

<p><img src="./Image Processing with Python_files/shapes-01-cca-detail.png" alt="shapes-01.jpg mask detail"></p>

<p>For us it is clear that these small spots are artifacts and
not objects we are interested in.
But how can we tell the computer?
One way to calibrate the algorithm is to adjust the parameters for
blurring (<code class="language-plaintext highlighter-rouge">sigma</code>) and thresholding (<code class="language-plaintext highlighter-rouge">t</code>),
but you may have noticed during the above exercise that
it is quite hard to find a combination that produces the right output number.
In some cases, background noise gets picked up as an object.
And with other parameters,
some of the foreground objects get broken up or disappear completely.
Therefore, we need other criteria to describe desired properties of the objects
that are found.</p>

<h2 id="morphometrics---describe-object-features-with-numbers">Morphometrics - Describe object features with numbers<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#morphometrics---describe-object-features-with-numbers" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>

<p>Morphometrics is concerned with the quantitative analysis of objects and
considers properties such as size and shape.
For the example of the images with the shapes,
our intuition tells us that the objects should be of a certain size or area.
So we could use a minimum area as a criterion for when an object should be detected.
To apply such a criterion,
we need a way to calculate the area of objects found by connected components.
Recall how we determined the root mass in
<a href="https://datacarpentry.org/image-processing/07-thresholding/index.html">the <em>Thresholding</em> episode</a>
by counting the pixels in the binary mask.
But here we want to calculate the area of several objects in the labeled image.
The skimage library provides the function <code class="language-plaintext highlighter-rouge">skimage.measure.regionprops</code>
to measure the properties of labeled regions.
It returns a list of <code class="language-plaintext highlighter-rouge">RegionProperties</code> that describe each connected region in the images.
The properties can be accessed using the attributes of the <code class="language-plaintext highlighter-rouge">RegionProperties</code> data type.
Here we will use the properties <code class="language-plaintext highlighter-rouge">"area"</code> and <code class="language-plaintext highlighter-rouge">"label"</code>.
You can explore the skimage documentation to learn about other properties available.</p>

<p>We can get a list of areas of the labeled objects as follows:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># compute object features and extract object areas
</span><span class="n">object_features</span> <span class="o">=</span> <span class="n">skimage</span><span class="p">.</span><span class="n">measure</span><span class="p">.</span><span class="n">regionprops</span><span class="p">(</span><span class="n">labeled_image</span><span class="p">)</span>
<span class="n">object_areas</span> <span class="o">=</span> <span class="p">[</span><span class="n">objf</span><span class="p">[</span><span class="s">"area"</span><span class="p">]</span> <span class="k">for</span> <span class="n">objf</span> <span class="ow">in</span> <span class="n">object_features</span><span class="p">]</span>
<span class="n">object_areas</span>
</code></pre></div></div>

<p>This will produce the output</p>

<div class="language-plaintext output highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[318542, 1, 523204, 496613, 517331, 143, 256215, 1, 68, 338784, 265755]
</code></pre></div></div>

<blockquote class="challenge">
  <h2 id="plot-a-histogram-of-the-object-area-distribution-10-min">Plot a histogram of the object area distribution (10 min)<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#plot-a-histogram-of-the-object-area-distribution-10-min" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>

  <p>Similar to how we determined a “good” threshold in
<a href="https://datacarpentry.org/image-processing/07-thresholding/index.html">the <em>Thresholding</em> episode</a>,
it is often helpful to inspect the histogram of an object property.
For example, we want to look at the distribution of the object areas.</p>

  <ol>
    <li>Create and examine a <a href="https://datacarpentry.org/image-processing/05-creating-histograms">histogram</a>
of the object areas obtained with <code class="language-plaintext highlighter-rouge">skimage.measure.regionprops</code>.</li>
    <li>What does the histogram tell you about the objects?</li>
  </ol>

  <blockquote class="solution">
    <h2 id="solution-3">Solution<span class="fold-unfold glyphicon glyphicon-collapse-down"></span><a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#solution-3" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>

    <p style="display: none;">The histogram can be plotted with</p>
    <div class="language-python highlighter-rouge" style="display: none;"><div class="highlight"><pre class="highlight"><code><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">hist</span><span class="p">(</span><span class="n">object_areas</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">"Area (pixels)"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">"Number of objects"</span><span class="p">);</span>
</code></pre></div>    </div>

    <p style="display: none;"><img src="./Image Processing with Python_files/shapes-01-areas-histogram.png" alt="Histogram of object areas"></p>

    <p style="display: none;">The histogram shows the number of objects (vertical axis)
whose area is within a certain range (horizontal axis).
The height of the bars in the histogram indicates
the prevalence of objects with a certain area.
The whole histogram tells us about the distribution of object sizes in the image.
It is often possible to identify gaps between groups of bars
(or peaks if we draw the histogram as a continuous curve)
that tell us about certain groups in the image.</p>

    <p style="display: none;">In this example, we can see that there are four small objects that
contain less than 50000 pixels.
Then there is a group of four (1+1+2) objects in
the range between 200000 and 400000,
and three objects with a size around 500000.
For our object count, we might want to disregard the small objects as artifacts,
i.e, we want to ignore the leftmost bar of the histogram.
We could use a threshold of 50000 as the minimum area to count.
In fact, the <code class="language-plaintext highlighter-rouge">object_areas</code> list already tells us that
there are fewer than 200 pixels in these objects.
Therefore, it is reasonable to require a minimum area of at least 200 pixels
for a detected object.
In practice, finding the “right” threshold can be tricky and
usually involves an educated guess based on domain knowledge.</p>
  </blockquote>
</blockquote>

<blockquote class="challenge">
  <h2 id="filter-objects-by-area-10-min">Filter objects by area (10 min)<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#filter-objects-by-area-10-min" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>

  <p>Now we would like to use a minimum area criterion to obtain a more
accurate count of the objects in the image.</p>

  <ol>
    <li>Find a way to calculate the number of objects by only counting
objects above a certain area.</li>
  </ol>

  <blockquote class="solution">
    <h2 id="solution-4">Solution<span class="fold-unfold glyphicon glyphicon-collapse-down"></span><a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#solution-4" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>

    <p style="display: none;">One way to count only objects above a certain area is to first
create a list of those objects, and then take the length of that
list as the object count. This can be done as follows:</p>

    <div class="language-python highlighter-rouge" style="display: none;"><div class="highlight"><pre class="highlight"><code><span class="n">min_area</span> <span class="o">=</span> <span class="mi">200</span>
<span class="n">large_objects</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">objf</span> <span class="ow">in</span> <span class="n">object_features</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">objf</span><span class="p">[</span><span class="s">"area"</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">min_area</span><span class="p">:</span>
        <span class="n">large_objects</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">objf</span><span class="p">[</span><span class="s">"label"</span><span class="p">])</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Found"</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">large_objects</span><span class="p">),</span> <span class="s">"objects!"</span><span class="p">)</span>
</code></pre></div>    </div>

    <p style="display: none;">Another option is to use Numpy arrays to create the list of large objects.
We first create an array <code class="language-plaintext highlighter-rouge">object_areas</code> containing the object areas,
and an array <code class="language-plaintext highlighter-rouge">object_labels</code> containing the object labels.
The labels of the objects are also returned by <code class="language-plaintext highlighter-rouge">skimage.measure.regionprops</code>.
We have already seen that we can create boolean arrays using comparison operators.
Here we can use <code class="language-plaintext highlighter-rouge">object_areas &gt; min_area</code>
to produce an array that has the same dimension as <code class="language-plaintext highlighter-rouge">object_labels</code>.
It can then used to select the labels of objects whose area is
greater than <code class="language-plaintext highlighter-rouge">min_area</code> by indexing:</p>

    <div class="language-python highlighter-rouge" style="display: none;"><div class="highlight"><pre class="highlight"><code><span class="n">object_areas</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="n">objf</span><span class="p">[</span><span class="s">"area"</span><span class="p">]</span> <span class="k">for</span> <span class="n">objf</span> <span class="ow">in</span> <span class="n">object_features</span><span class="p">])</span>
<span class="n">object_labels</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="n">objf</span><span class="p">[</span><span class="s">"label"</span><span class="p">]</span> <span class="k">for</span> <span class="n">objf</span> <span class="ow">in</span> <span class="n">object_features</span><span class="p">])</span>
<span class="n">large_objects</span> <span class="o">=</span> <span class="n">object_labels</span><span class="p">[</span><span class="n">object_areas</span> <span class="o">&gt;</span> <span class="n">min_area</span><span class="p">]</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Found"</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">large_objects</span><span class="p">),</span> <span class="s">"objects!"</span><span class="p">)</span>
</code></pre></div>    </div>

    <p style="display: none;">The advantage of using Numpy arrays is that
<code class="language-plaintext highlighter-rouge">for</code> loops and <code class="language-plaintext highlighter-rouge">if</code> statements in Python can be slow,
and in practice the first approach may not be feasible
if the image contains a large number of objects.
In that case, Numpy array functions turn out to be very useful because
they are much faster.</p>

    <p style="display: none;">In this example, we can also use the <code class="language-plaintext highlighter-rouge">np.count_nonzero</code> function
that we have seen earlier together with the <code class="language-plaintext highlighter-rouge">&gt;</code> operator to count
the objects whose area is above <code class="language-plaintext highlighter-rouge">min_area</code>.</p>

    <div class="language-python highlighter-rouge" style="display: none;"><div class="highlight"><pre class="highlight"><code><span class="n">n</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">count_nonzero</span><span class="p">(</span><span class="n">object_areas</span> <span class="o">&gt;</span> <span class="n">min_area</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Found"</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="s">"objects!"</span><span class="p">)</span>
</code></pre></div>    </div>

    <p style="display: none;">For all three alternatives, the output is the same and gives the
expected count of 7 objects.</p>
  </blockquote>
</blockquote>

<blockquote class="callout">
  <h2 id="using-functions-from-numpy-and-other-python-packages">Using functions from Numpy and other Python packages<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#using-functions-from-numpy-and-other-python-packages" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>
  <p>Functions from Python packages such as Numpy are often more efficient and
require less code to write.
It is a good idea to browse the reference pages of <code class="language-plaintext highlighter-rouge">numpy</code> and <code class="language-plaintext highlighter-rouge">skimage</code> to
look for an availabe function that can solve a given task.</p>
</blockquote>

<blockquote class="challenge">
  <h2 id="remove-small-objects-20-min">Remove small objects (20 min)<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#remove-small-objects-20-min" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>

  <p>We might also want to exclude (mask) the small objects when plotting
the labeled image.</p>

  <ol>
    <li>Enhance the <code class="language-plaintext highlighter-rouge">connected_components</code> function such that
it automatically removes objects that are below a certain area that is
passed to the function as an optional parameter.</li>
  </ol>

  <blockquote class="solution">
    <h2 id="solution-5">Solution<span class="fold-unfold glyphicon glyphicon-collapse-down"></span><a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#solution-5" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>

    <p style="display: none;">To remove the small objects from the labeled image,
we change the value of all pixels that belong to the small objects to
the background label 0.
One way to do this is to loop over all objects and
set the pixels that match the label of the object to 0.</p>

    <div class="language-python highlighter-rouge" style="display: none;"><div class="highlight"><pre class="highlight"><code><span class="k">for</span> <span class="n">object_id</span><span class="p">,</span> <span class="n">objf</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">object_features</span><span class="p">,</span> <span class="n">start</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">objf</span><span class="p">[</span><span class="s">"area"</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">min_area</span><span class="p">:</span>
        <span class="n">labeled_image</span><span class="p">[</span><span class="n">labeled_image</span> <span class="o">==</span> <span class="n">objf</span><span class="p">[</span><span class="s">"label"</span><span class="p">]]</span> <span class="o">=</span> <span class="mi">0</span>
</code></pre></div>    </div>

    <p style="display: none;">Here Numpy functions can also be used to eliminate
<code class="language-plaintext highlighter-rouge">for</code> loops and <code class="language-plaintext highlighter-rouge">if</code> statements.
Like above, we can create an array of the small object labels with
the comparison <code class="language-plaintext highlighter-rouge">object_areas &lt; min_area</code>.
We can use another Numpy function, <code class="language-plaintext highlighter-rouge">np.isin</code>,
to set the pixels of all small objects to 0.
<code class="language-plaintext highlighter-rouge">np.isin</code> takes two arrays and returns a boolean array with values
<code class="language-plaintext highlighter-rouge">True</code> if the entry of the first array is found in the second array,
and <code class="language-plaintext highlighter-rouge">False</code> otherwise.
This array can then be used to index the <code class="language-plaintext highlighter-rouge">labeled_image</code> and
set the entries that belong to small objects to <code class="language-plaintext highlighter-rouge">0</code>.</p>

    <div class="language-python highlighter-rouge" style="display: none;"><div class="highlight"><pre class="highlight"><code><span class="n">object_areas</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="n">objf</span><span class="p">[</span><span class="s">"area"</span><span class="p">]</span> <span class="k">for</span> <span class="n">objf</span> <span class="ow">in</span> <span class="n">object_features</span><span class="p">])</span>
<span class="n">object_labels</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="n">objf</span><span class="p">[</span><span class="s">"label"</span><span class="p">]</span> <span class="k">for</span> <span class="n">objf</span> <span class="ow">in</span> <span class="n">object_features</span><span class="p">])</span>
<span class="n">small_objects</span> <span class="o">=</span> <span class="n">object_labels</span><span class="p">[</span><span class="n">object_areas</span> <span class="o">&lt;</span> <span class="n">min_area</span><span class="p">]</span>
<span class="n">labeled_image</span><span class="p">[</span><span class="n">np</span><span class="p">.</span><span class="n">isin</span><span class="p">(</span><span class="n">labeled_image</span><span class="p">,</span><span class="n">small_objects</span><span class="p">)]</span> <span class="o">=</span> <span class="mi">0</span>
</code></pre></div>    </div>

    <p style="display: none;">An even more elegant way to remove small objects from the image is
to leverage the <code class="language-plaintext highlighter-rouge">skimage.morphology</code> module.
It provides a function <code class="language-plaintext highlighter-rouge">skimage.morphology.remove_small_objects</code> that
does exactly what we are looking for.
It can be applied to a binary image and
returns a mask in which all objects smaller than <code class="language-plaintext highlighter-rouge">min_area</code> are excluded,
i.e, their pixel values are set to <code class="language-plaintext highlighter-rouge">False</code>.
We can then apply <code class="language-plaintext highlighter-rouge">skimage.measure.label</code> to the masked image:</p>

    <div class="language-python highlighter-rouge" style="display: none;"><div class="highlight"><pre class="highlight"><code><span class="n">object_mask</span> <span class="o">=</span> <span class="n">skimage</span><span class="p">.</span><span class="n">morphology</span><span class="p">.</span><span class="n">remove_small_objects</span><span class="p">(</span><span class="n">binary_mask</span><span class="p">,</span><span class="n">min_area</span><span class="p">)</span>
<span class="n">labeled_image</span><span class="p">,</span> <span class="n">n</span> <span class="o">=</span> <span class="n">skimage</span><span class="p">.</span><span class="n">measure</span><span class="p">.</span><span class="n">label</span><span class="p">(</span><span class="n">object_mask</span><span class="p">,</span>
                                         <span class="n">connectivity</span><span class="o">=</span><span class="n">connectivity</span><span class="p">,</span> <span class="n">return_num</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div>    </div>

    <p style="display: none;">Using the <code class="language-plaintext highlighter-rouge">skimage</code> features, we can implement
the <code class="language-plaintext highlighter-rouge">enhanced_connected_component</code> as follows:</p>

    <div class="language-python highlighter-rouge" style="display: none;"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">enhanced_connected_components</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">t</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">connectivity</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">min_area</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
    <span class="n">image</span> <span class="o">=</span> <span class="n">skimage</span><span class="p">.</span><span class="n">io</span><span class="p">.</span><span class="n">imread</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span>
    <span class="n">gray_image</span> <span class="o">=</span> <span class="n">skimage</span><span class="p">.</span><span class="n">color</span><span class="p">.</span><span class="n">rgb2gray</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
    <span class="n">blurred_image</span> <span class="o">=</span> <span class="n">skimage</span><span class="p">.</span><span class="n">filters</span><span class="p">.</span><span class="n">gaussian</span><span class="p">(</span><span class="n">gray_image</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="n">sigma</span><span class="p">)</span>
    <span class="n">binary_mask</span> <span class="o">=</span> <span class="n">blurred_image</span> <span class="o">&lt;</span> <span class="n">t</span>
    <span class="n">object_mask</span> <span class="o">=</span> <span class="n">skimage</span><span class="p">.</span><span class="n">morphology</span><span class="p">.</span><span class="n">remove_small_objects</span><span class="p">(</span><span class="n">binary_mask</span><span class="p">,</span><span class="n">min_area</span><span class="p">)</span>
    <span class="n">labeled_image</span><span class="p">,</span> <span class="n">count</span> <span class="o">=</span> <span class="n">skimage</span><span class="p">.</span><span class="n">measure</span><span class="p">.</span><span class="n">label</span><span class="p">(</span><span class="n">object_mask</span><span class="p">,</span>
                                                 <span class="n">connectivity</span><span class="o">=</span><span class="n">connectivity</span><span class="p">,</span> <span class="n">return_num</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">labeled_image</span><span class="p">,</span> <span class="n">count</span>
</code></pre></div>    </div>

    <p style="display: none;">We can now call the function with a chosen <code class="language-plaintext highlighter-rouge">min_area</code> and
display the resulting labeled image:</p>

    <div class="language-python highlighter-rouge" style="display: none;"><div class="highlight"><pre class="highlight"><code><span class="n">labeled_image</span><span class="p">,</span> <span class="n">count</span> <span class="o">=</span> <span class="n">enhanced_connected_components</span><span class="p">(</span><span class="n">filename</span><span class="o">=</span><span class="s">"data/shapes-01.jpg"</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">t</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span>
                                                     <span class="n">connectivity</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">min_area</span><span class="o">=</span><span class="n">min_area</span><span class="p">)</span>
<span class="n">colored_label_image</span> <span class="o">=</span> <span class="n">skimage</span><span class="p">.</span><span class="n">color</span><span class="p">.</span><span class="n">label2rgb</span><span class="p">(</span><span class="n">labeled_image</span><span class="p">,</span> <span class="n">bg_label</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">colored_label_image</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">axis</span><span class="p">(</span><span class="s">"off"</span><span class="p">);</span>

<span class="k">print</span><span class="p">(</span><span class="s">"Found"</span><span class="p">,</span> <span class="n">count</span><span class="p">,</span> <span class="s">"objects in the image."</span><span class="p">)</span>
</code></pre></div>    </div>

    <p style="display: none;"><img src="./Image Processing with Python_files/shapes-01-filtered-objects.png" alt="Objects filtered by area"></p>

    <div class="language-plaintext output highlighter-rouge" style="display: none;"><div class="highlight"><pre class="highlight"><code>Found 7 objects in the image.
</code></pre></div>    </div>

    <p style="display: none;">Note that the small objects are “gone” and we obtain the correct
number of 7 objects in the image.</p>
  </blockquote>
</blockquote>

<blockquote class="challenge">
  <h2 id="colour-objects-by-area-optional-not-included-in-timing">Colour objects by area (optional, not included in timing)<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#colour-objects-by-area-optional-not-included-in-timing" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>

  <p>Finally, we would like to display the image with the objects coloured
according to the magnitude of their area.
In practice, this can be used with other properties to give
visual cues of the object properties.</p>

  <blockquote class="solution">
    <h2 id="solution-6">Solution<span class="fold-unfold glyphicon glyphicon-collapse-down"></span><a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#solution-6" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>

    <p style="display: none;">We already know how to get the areas of the objects from the <code class="language-plaintext highlighter-rouge">regionprops</code>.
We just need to insert a zero area value for the background
(to colour it like a zero size object).
The background is also labeled <code class="language-plaintext highlighter-rouge">0</code> in the <code class="language-plaintext highlighter-rouge">labeled_image</code>,
so we insert the zero area value in front of the first element of
<code class="language-plaintext highlighter-rouge">object_areas</code> with <code class="language-plaintext highlighter-rouge">np.insert</code>.
Then we can create a <code class="language-plaintext highlighter-rouge">colored_area_image</code> where we assign each pixel value
the area by indexing the <code class="language-plaintext highlighter-rouge">object_areas</code> with the label values in <code class="language-plaintext highlighter-rouge">labeled_image</code>.</p>

    <div class="language-python highlighter-rouge" style="display: none;"><div class="highlight"><pre class="highlight"><code><span class="n">object_areas</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="n">objf</span><span class="p">[</span><span class="s">"area"</span><span class="p">]</span> <span class="k">for</span> <span class="n">objf</span> <span class="ow">in</span> <span class="n">skimage</span><span class="p">.</span><span class="n">measure</span><span class="p">.</span><span class="n">regionprops</span><span class="p">(</span><span class="n">labeled_image</span><span class="p">)])</span>
<span class="n">object_areas</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">insert</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="n">object_areas</span><span class="p">)</span>
<span class="n">colored_area_image</span> <span class="o">=</span> <span class="n">object_areas</span><span class="p">[</span><span class="n">labeled_image</span><span class="p">]</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">im</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">colored_area_image</span><span class="p">)</span>
<span class="n">cbar</span> <span class="o">=</span> <span class="n">fig</span><span class="p">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">im</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">shrink</span><span class="o">=</span><span class="mf">0.85</span><span class="p">)</span>
<span class="n">cbar</span><span class="p">.</span><span class="n">ax</span><span class="p">.</span><span class="n">set_title</span><span class="p">(</span><span class="s">"Area"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">axis</span><span class="p">(</span><span class="s">"off"</span><span class="p">);</span>
</code></pre></div>    </div>

    <p style="display: none;"><img src="./Image Processing with Python_files/shapes-01-objects-coloured-by-area.png" alt="Objects colored by area"></p>

    <blockquote class="callout" style="display: none;">
      <p>You may have noticed that in the solution, we have used the
<code class="language-plaintext highlighter-rouge">labeled_image</code> to index the array <code class="language-plaintext highlighter-rouge">object_areas</code>. This is an
example of <a href="https://numpy.org/doc/stable/user/basics.indexing.html#advanced-indexing">advanced indexing in
Numpy</a>
The result is an array of the same shape as the <code class="language-plaintext highlighter-rouge">labeled_image</code>
whose pixel values are selected from <code class="language-plaintext highlighter-rouge">object_areas</code> according to
the object label. Hence the objects will be colored by area when
the result is displayed. Note that advanced indexing with an
integer array works slightly different than the indexing with a
Boolean array that we have used for masking. While Boolean array
indexing returns only the entries corresponding to the <code class="language-plaintext highlighter-rouge">True</code>
values of the index, integer array indexing returns an array
with the same shape as the index. You can read more about advanced
indexing in the <a href="https://numpy.org/doc/stable/user/basics.indexing.html#advanced-indexing">Numpy
documentation</a>.</p>
    </blockquote>
  </blockquote>
</blockquote>

<blockquote class="keypoints">
  <h2 id="key-points-7">Key Points<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#key-points-7" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>
  <ul>
    
    <li><p>We can use <code class="language-plaintext highlighter-rouge">skimage.measure.label</code> to find and label connected objects in an image.</p>
</li>
    
    <li><p>We can use <code class="language-plaintext highlighter-rouge">skimage.measure.regionprops</code> to measure properties of labeled objects.</p>
</li>
    
    <li><p>We can use <code class="language-plaintext highlighter-rouge">skimage.morphology.remove_small_objects</code> to mask small objects and remove artifacts from an image.</p>
</li>
    
    <li><p>We can display the labeled image to view the objects coloured by label.</p>
</li>
    
  </ul>
</blockquote>

<hr>

<h1 id="capstone-challenge" class="maintitle">Capstone Challenge</h1>

<blockquote class="objectives">
  <h2 id="overview-8">Overview<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#overview-8" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>

  <div class="row">
    <div class="col-md-3">
      <strong>Teaching:</strong> 10 min
      <br>
      <strong>Exercises:</strong> 40 min
    </div>
    <div class="col-md-9">
      <strong>Questions</strong>
      <ul>
	
	<li><p>How can we automatically count bacterial colonies with image analysis?</p>
</li>
	
      </ul>
    </div>
  </div>

  <div class="row">
    <div class="col-md-3">
    </div>
    <div class="col-md-9">
      <strong>Objectives</strong>
      <ul>
	
	<li><p>Bring together everything you’ve learnt so far to count bacterial colonies in 3 images.</p>
</li>
	
      </ul>
    </div>
  </div>

</blockquote>

<p>In this episode, we will provide a final challenge for you to attempt,
based on all the skills you have acquired so far.
This challenge will be related to the shape of objects in images (<em>morphometrics</em>).</p>

<h2 id="morphometrics-bacteria-colony-counting">Morphometrics: Bacteria Colony Counting<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#morphometrics-bacteria-colony-counting" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>

<p>As mentioned in <a href="https://datacarpentry.org/image-processing/01-introduction/index.html">the workshop introduction</a>,
your morphometric challenge is to determine how many bacteria colonies are in
each of these images:</p>

<p><img src="./Image Processing with Python_files/colonies-01.jpg" alt="Colony image 1"></p>

<p><img src="./Image Processing with Python_files/colonies-02.jpg" alt="Colony image 2"></p>

<p><img src="./Image Processing with Python_files/colonies-03.jpg" alt="Colony image 3"></p>

<p>The image files can be found at
<code class="language-plaintext highlighter-rouge">data/colonies-01.tif</code>,
<code class="language-plaintext highlighter-rouge">data/colonies-02.tif</code>,
and <code class="language-plaintext highlighter-rouge">data/colonies-03.tif</code>.</p>

<blockquote class="challenge">
  <h2 id="morphometrics-for-bacterial-colonies">Morphometrics for bacterial colonies<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#morphometrics-for-bacterial-colonies" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>

  <p>Write a Python program that uses skimage to
count the number of bacteria colonies in each image,
and for each, produce a new image that highlights the colonies.
The image should look similar to this one:</p>

  <p><img src="./Image Processing with Python_files/colonies-01-summary.png" alt="Sample morphometric output"></p>

  <p>Additionally, print out the number of colonies for each image.</p>

  <p>Use what you have learnt about <a href="https://datacarpentry.org/image-processing/05-creating-histograms/index.html">histograms</a>,
<a href="https://datacarpentry.org/image-processing/07-thresholding/index.html">thresholding</a> and
<a href="https://datacarpentry.org/image-processing/08-connected-components/index.html">connected component analysis</a>.
Try to put your code into a re-usable function,
so that it can be applied easily to any image file.</p>

  <blockquote class="solution">
    <h2 id="solution">Solution<span class="fold-unfold glyphicon glyphicon-collapse-down"></span><a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#solution" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>

    <p style="display: none;">First, let’s work through the process for one image:</p>
    <div class="language-python highlighter-rouge" style="display: none;"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">skimage.filters</span>
<span class="kn">import</span> <span class="nn">skimage.color</span>
<span class="kn">import</span> <span class="nn">skimage.io</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">widget</span>

<span class="n">bacteria_image</span> <span class="o">=</span> <span class="n">skimage</span><span class="p">.</span><span class="n">io</span><span class="p">.</span><span class="n">imread</span><span class="p">(</span><span class="n">fname</span><span class="o">=</span><span class="s">"data/colonies-01.tif"</span><span class="p">)</span>

<span class="c1"># display the image
</span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">bacteria_image</span><span class="p">)</span>
</code></pre></div>    </div>

    <p style="display: none;"><img src="./Image Processing with Python_files/colonies-01.jpg" alt="Colony image 1"></p>

    <p style="display: none;">Next, we need to threshold the image to create a mask that covers only
the dark bacterial colonies.
This is easier using a grayscale image, so we convert it here:</p>

    <div class="language-python highlighter-rouge" style="display: none;"><div class="highlight"><pre class="highlight"><code><span class="n">gray_bacteria</span> <span class="o">=</span> <span class="n">skimage</span><span class="p">.</span><span class="n">color</span><span class="p">.</span><span class="n">rgb2gray</span><span class="p">(</span><span class="n">bacteria_image</span><span class="p">)</span>

<span class="c1"># display the gray image
</span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">gray_bacteria</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s">"gray"</span><span class="p">)</span>
</code></pre></div>    </div>

    <p style="display: none;"><img src="./Image Processing with Python_files/colonies-01-gray.png" alt="Gray Colonies"></p>

    <p style="display: none;">Next, we blur the image and create a histogram:</p>

    <div class="language-python highlighter-rouge" style="display: none;"><div class="highlight"><pre class="highlight"><code><span class="n">blurred_image</span> <span class="o">=</span> <span class="n">skimage</span><span class="p">.</span><span class="n">filters</span><span class="p">.</span><span class="n">gaussian</span><span class="p">(</span><span class="n">gray_bacteria</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
<span class="n">histogram</span><span class="p">,</span> <span class="n">bin_edges</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">histogram</span><span class="p">(</span><span class="n">blurred_image</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="nb">range</span><span class="o">=</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">))</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">bin_edges</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">histogram</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">"Graylevel histogram"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">"gray value"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">"pixel count"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span>
</code></pre></div>    </div>

    <p style="display: none;"><img src="./Image Processing with Python_files/colonies-01-histogram.png" alt="Histogram image"></p>

    <p style="display: none;">In this histogram, we see three peaks -
the left one (i.e. the darkest pixels) is our colonies,
the central peak is the yellow/brown culture medium in the dish,
and the right one (i.e. the brightest pixels) is the white image background.
Therefore, we choose a threshold that selects the small left peak:</p>

    <div class="language-python highlighter-rouge" style="display: none;"><div class="highlight"><pre class="highlight"><code><span class="n">mask</span> <span class="o">=</span> <span class="n">blurred_image</span> <span class="o">&lt;</span> <span class="mf">0.2</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">mask</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s">"gray"</span><span class="p">)</span>
</code></pre></div>    </div>

    <p style="display: none;"><img src="./Image Processing with Python_files/colonies-01-mask.png" alt="Colony mask image"></p>

    <p style="display: none;">This mask shows us where the colonies are in the image -
but how can we count how many there are?
This requires connected component analysis:</p>

    <div class="language-python highlighter-rouge" style="display: none;"><div class="highlight"><pre class="highlight"><code><span class="n">labeled_image</span><span class="p">,</span> <span class="n">count</span> <span class="o">=</span> <span class="n">skimage</span><span class="p">.</span><span class="n">measure</span><span class="p">.</span><span class="n">label</span><span class="p">(</span><span class="n">mask</span><span class="p">,</span> <span class="n">return_num</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">count</span><span class="p">)</span>
</code></pre></div>    </div>

    <p style="display: none;">Finally, we create the summary image of the coloured colonies on top of
the grayscale image:</p>

    <div class="language-python highlighter-rouge" style="display: none;"><div class="highlight"><pre class="highlight"><code><span class="c1"># color each of the colonies a different color
</span><span class="n">colored_label_image</span> <span class="o">=</span> <span class="n">skimage</span><span class="p">.</span><span class="n">color</span><span class="p">.</span><span class="n">label2rgb</span><span class="p">(</span><span class="n">labeled_image</span><span class="p">,</span> <span class="n">bg_label</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="c1"># give our grayscale image rgb channels, so we can add the colored colonies
</span><span class="n">summary_image</span> <span class="o">=</span> <span class="n">skimage</span><span class="p">.</span><span class="n">color</span><span class="p">.</span><span class="n">gray2rgb</span><span class="p">(</span><span class="n">gray_bacteria</span><span class="p">)</span>
<span class="n">summary_image</span><span class="p">[</span><span class="n">mask</span><span class="p">]</span> <span class="o">=</span> <span class="n">colored_label_image</span><span class="p">[</span><span class="n">mask</span><span class="p">]</span>

<span class="c1"># plot overlay
</span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">summary_image</span><span class="p">)</span>
</code></pre></div>    </div>

    <p style="display: none;"><img src="./Image Processing with Python_files/colonies-01-summary.png" alt="Sample morphometric output"></p>

    <p style="display: none;">Now that we’ve completed the task for one image,
we need to repeat this for the remaining two images.
This is a good point to collect the lines above into a re-usable function:</p>

    <div class="language-python highlighter-rouge" style="display: none;"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">count_colonies</span><span class="p">(</span><span class="n">image_filename</span><span class="p">):</span>
    <span class="n">bacteria_image</span> <span class="o">=</span> <span class="n">skimage</span><span class="p">.</span><span class="n">io</span><span class="p">.</span><span class="n">imread</span><span class="p">(</span><span class="n">image_filename</span><span class="p">)</span>
    <span class="n">gray_bacteria</span> <span class="o">=</span> <span class="n">skimage</span><span class="p">.</span><span class="n">color</span><span class="p">.</span><span class="n">rgb2gray</span><span class="p">(</span><span class="n">bacteria_image</span><span class="p">)</span>
    <span class="n">blurred_image</span> <span class="o">=</span> <span class="n">skimage</span><span class="p">.</span><span class="n">filters</span><span class="p">.</span><span class="n">gaussian</span><span class="p">(</span><span class="n">gray_bacteria</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
    <span class="n">mask</span> <span class="o">=</span> <span class="n">blurred_image</span> <span class="o">&lt;</span> <span class="mf">0.2</span>
    <span class="n">labeled_image</span><span class="p">,</span> <span class="n">count</span> <span class="o">=</span> <span class="n">skimage</span><span class="p">.</span><span class="n">measure</span><span class="p">.</span><span class="n">label</span><span class="p">(</span><span class="n">mask</span><span class="p">,</span> <span class="n">return_num</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"There are </span><span class="si">{</span><span class="n">count</span><span class="si">}</span><span class="s"> colonies in </span><span class="si">{</span><span class="n">image_filename</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>

    <span class="n">colored_label_image</span> <span class="o">=</span> <span class="n">skimage</span><span class="p">.</span><span class="n">color</span><span class="p">.</span><span class="n">label2rgb</span><span class="p">(</span><span class="n">labeled_image</span><span class="p">,</span> <span class="n">bg_label</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">summary_image</span> <span class="o">=</span> <span class="n">skimage</span><span class="p">.</span><span class="n">color</span><span class="p">.</span><span class="n">gray2rgb</span><span class="p">(</span><span class="n">gray_bacteria</span><span class="p">)</span>
    <span class="n">summary_image</span><span class="p">[</span><span class="n">mask</span><span class="p">]</span> <span class="o">=</span> <span class="n">colored_label_image</span><span class="p">[</span><span class="n">mask</span><span class="p">]</span>
    <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">()</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">summary_image</span><span class="p">)</span>
</code></pre></div>    </div>

    <p style="display: none;">Now we can easily do this analysis on all the images via a for loop:</p>

    <div class="language-python highlighter-rouge" style="display: none;"><div class="highlight"><pre class="highlight"><code><span class="k">for</span> <span class="n">image_filename</span> <span class="ow">in</span> <span class="p">[</span><span class="s">"data/colonies-01.tif"</span><span class="p">,</span> <span class="s">"data/colonies-02.tif"</span><span class="p">,</span> <span class="s">"data/colonies-03.tif"</span><span class="p">]:</span>
    <span class="n">count_colonies</span><span class="p">(</span><span class="n">image_filename</span><span class="o">=</span><span class="n">image_filename</span><span class="p">)</span>
</code></pre></div>    </div>

    <p style="display: none;"><img src="./Image Processing with Python_files/colonies-01-summary.png" alt="Colony 1 output">
<img src="./Image Processing with Python_files/colonies-02-summary.png" alt="Colony 2 output">
<img src="./Image Processing with Python_files/colonies-03-summary.png" alt="Colony 3 output"></p>

    <p style="display: none;">You’ll notice that for the images with more colonies, the results aren’t perfect.
For example, some small colonies are missing,
and there are likely some small black spots being labelled incorrectly as colonies.
You could expand this solution to, for example,
use an automatically determined threshold for each image,
which may fit each better.
Also, you could filter out colonies below a certain size
(as we did in <a href="https://datacarpentry.org/image-processing/08-connected-components/index.html">the <em>Connected Component Analysis</em> episode</a>).
You’ll also see that some touching colonies are merged into one big colony.
This could be fixed with more complicated segmentation methods
(outside of the scope of this lesson) like
<a href="https://scikit-image.org/docs/dev/auto_examples/segmentation/plot_watershed.html">watershed</a>.</p>
  </blockquote>
</blockquote>

<blockquote class="keypoints">
  <h2 id="key-points-8">Key Points<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="https://datacarpentry.org/image-processing/aio/index.html#key-points-8" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>
  <ul>
    
    <li><p>Using thresholding, connected component analysis and other tools we can automatically segment images of bacterial colonies.</p>
</li>
    
    <li><p>These methods are useful for many scientific problems, especially those involving morphometrics.</p>
</li>
    
  </ul>
</blockquote>

<hr>


</article>


      
      






<footer>
  <hr>
  <div class="row">
    <div class="col-md-6 license" id="license-info" align="left">
	
	Licensed under <a href="https://creativecommons.org/licenses/by/4.0/">CC-BY 4.0</a> 2018–2022
	by <a href="https://carpentries.org/">The Carpentries</a>
        <br>
        Licensed under <a href="https://creativecommons.org/licenses/by/4.0/">CC-BY 4.0</a> 2016–2018
	by <a href="https://datacarpentry.org/">Data Carpentry</a>
	
    </div>
    <div class="col-md-6 help-links" align="right">
	
	<a href="https://github.com/datacarpentry/image-processing/edit/gh-pages/aio.md" data-checker-ignore="">Edit on GitHub</a>
	
	/
	<a href="https://github.com/datacarpentry/image-processing/blob/gh-pages/CONTRIBUTING.md" data-checker-ignore="">Contributing</a>
	/
	<a href="https://github.com/datacarpentry/image-processing/">Source</a>
	/
	<a href="https://github.com/datacarpentry/image-processing/blob/gh-pages/CITATION" data-checker-ignore="">Cite</a>
	/
	<a href="mailto:team@carpentries.org">Contact</a>
    </div>
  </div>
  <p class="text-muted text-right">
    <small><i>Using <a href="https://github.com/carpentries/carpentries-theme/">The Carpentries theme</a> — Site last built on: 2022-09-14 18:27:43 +0000.</i></small>
  </p>
</footer>

      
    </div>
    
<script async="" src="./Image Processing with Python_files/matomo.js.download"></script><script src="./Image Processing with Python_files/jquery.min.js.download"></script>
<script src="./Image Processing with Python_files/bootstrap.min.js.download"></script>
<script src="./Image Processing with Python_files/lesson.js.download"></script>


<!-- Matomo -->
<script>
  var _paq = window._paq = window._paq || [];
  /* tracker methods like "setCustomDimension" should be called before "trackPageView" */
  _paq.push(["setDocumentTitle", document.domain + "/" + document.title]);
  _paq.push(["setDomains", ["*.lessons.carpentries.org","*.datacarpentry.github.io","*.datacarpentry.org","*.librarycarpentry.github.io","*.librarycarpentry.org","*.swcarpentry.github.io"]]);
  _paq.push(["setDoNotTrack", true]);
  _paq.push(["disableCookies"]);
  _paq.push(['trackPageView']);
  _paq.push(['enableLinkTracking']);
  (function() {
    var u="https://carpentries.matomo.cloud/";
    _paq.push(['setTrackerUrl', u+'matomo.php']);
    _paq.push(['setSiteId', '1']);
    var d=document, g=d.createElement('script'), s=d.getElementsByTagName('script')[0];
    g.async=true; g.src='//cdn.matomo.cloud/carpentries.matomo.cloud/matomo.js'; s.parentNode.insertBefore(g,s);
  })();
</script>
<!-- End Matomo Code -->


<script src="./Image Processing with Python_files/anchor.min.js.download"></script>
<script>
    anchors.add();
</script>

  

</body><grammarly-desktop-integration data-grammarly-shadow-root="true"></grammarly-desktop-integration></html>